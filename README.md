<div align="center">

# Some Stars

â­ <a href="https://luohongkun.com/"  target="_blank">LuoHongkun</a>çš„staråˆ—è¡¨ï¼Œæ¯6å°æ—¶è‡ªåŠ¨æ›´æ–°,å‚è€ƒé“¾æ¥-><a href="https://linux.do/t/topic/115143"  target="_blank">github staråˆ—è¡¨è‡ªåŠ¨æ›´æ–°</a> â­

</div><br>

## Table of Contents

*   [Python](#python)
*   [C++](#c)
*   [miscellaneous](#miscellaneous)
*   [Jupyter Notebook](#jupyter-notebook)
*   [TypeScript](#typescript)
*   [Clojure](#clojure)
*   [SCSS](#scss)
*   [C](#c-1)
*   [CSS](#css)
*   [Makefile](#makefile)
*   [Java](#java)
*   [Go](#go)
*   [Vim Script](#vim-script)
*   [MATLAB](#matlab)
*   [C#](#c-2)
*   [JavaScript](#javascript)

## Python

*   [GradientSpaces/LoopSplat](https://github.com/GradientSpaces/LoopSplat) - LoopSplat: Loop Closure by Registering 3D Gaussian Splats

*   [zhaofuq/LOD-3DGS](https://github.com/zhaofuq/LOD-3DGS) - LetsGo: Large-Scale Garage Modeling and Rendering via LiDAR-Assisted Gaussian

*   [hjr37/CP-SLAM](https://github.com/hjr37/CP-SLAM) - CP-SLAM: Collaborative Neural Point-based SLAM

*   [cvg/nicer-slam](https://github.com/cvg/nicer-slam) - \[3DV'24 Best Paper Honorable Mention] NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM

*   [lpiccinelli-eth/UniDepth](https://github.com/lpiccinelli-eth/UniDepth) - Universal Monocular Metric Depth Estimation

*   [JeongminB/E-D3DGS](https://github.com/JeongminB/E-D3DGS) - \[ECCV 2024] Official repository for "Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian Splatting"

*   [spla-tam/SplaTAM](https://github.com/spla-tam/SplaTAM) - SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM (CVPR 2024)

*   [sparolab/solid](https://github.com/sparolab/solid) - (RA-L 2024) This repository is the official code for Narrowing your FOV with SOLiD: Spatially Organized and Lightweight Global Descriptor for FOV-constrained LiDAR Place Recognition.

*   [IPNL-POLYU/UrbanNavDataset](https://github.com/IPNL-POLYU/UrbanNavDataset) - UrbanNav:An Open-sourced Multisensory Dataset for Benchmarking Positioning Algorithms Designed for Urban Areas

*   [YuxueYang1204/TrimGS](https://github.com/YuxueYang1204/TrimGS) - Trim 3D Gaussian Splatting for Accurate Geometry Representation

*   [open-mmlab/mmtracking](https://github.com/open-mmlab/mmtracking) - OpenMMLab Video Perception Toolbox. It supports Video Object Detection (VID), Multiple Object Tracking (MOT), Single Object Tracking (SOT), Video Instance Segmentation (VIS) with a unified framework.

*   [huggingface/transformers](https://github.com/huggingface/transformers) - ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.

*   [openai/openai-python](https://github.com/openai/openai-python) - The official Python library for the OpenAI API

*   [llmbev/talk2bev](https://github.com/llmbev/talk2bev) - Talk2BEV: Language-Enhanced Bird's Eye View Maps (Accepted to ICRA'24)

*   [liuyuan-pal/SyncDreamer](https://github.com/liuyuan-pal/SyncDreamer) - \[ICLR 2024 Spotlight] SyncDreamer: Generating Multiview-consistent Images from a Single-view Image

*   [fudan-zvg/4d-gaussian-splatting](https://github.com/fudan-zvg/4d-gaussian-splatting) - \[ICLR 2024] Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting

*   [eriksandstroem/Loopy-SLAM](https://github.com/eriksandstroem/Loopy-SLAM) -

*   [qinzheng93/GeoTransformer](https://github.com/qinzheng93/GeoTransformer) - \[CVPR2022] Geometric Transformer for Fast and Robust Point Cloud Registration

*   [yanyan-li/GeoGaussian](https://github.com/yanyan-li/GeoGaussian) - GeoGaussian: Geometry-aware Gaussian Splatting for Scene Rendering

*   [Parskatt/DeDoDe](https://github.com/Parskatt/DeDoDe) - \[3DV 2024 Oral] DeDoDe ğŸ¶ Detect, Don't Describe --- Describe, Don't Detect, for Local Feature Matching

*   [ericzzj1989/BALF](https://github.com/ericzzj1989/BALF) -

*   [lyakaap/NetVLAD-pytorch](https://github.com/lyakaap/NetVLAD-pytorch) - PyTorch implementation of NetVLAD & Online Hardest Triplet Loss.

*   [meta-llama/llama-agentic-system](https://github.com/meta-llama/llama-agentic-system) - Agentic components of the Llama Stack APIs

*   [xiaobiaodu/DreamCar](https://github.com/xiaobiaodu/DreamCar) -

*   [nianticlabs/acezero](https://github.com/nianticlabs/acezero) - \[ECCV 2024 - Oral] ACE0 is a learning-based structure-from-motion approach that estimates camera parameters of sets of images by learning a multi-view consistent, implicit scene representation.

*   [meta-llama/llama-models](https://github.com/meta-llama/llama-models) - Utilities intended for use with Llama models.

*   [cs230-stanford/cs230-code-examples](https://github.com/cs230-stanford/cs230-code-examples) - Code examples in pyTorch and Tensorflow for CS230

*   [ddbourgin/numpy-ml](https://github.com/ddbourgin/numpy-ml) - Machine learning, in numpy

*   [lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch) - Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch

*   [tarashakhurana/4d-occ-forecasting](https://github.com/tarashakhurana/4d-occ-forecasting) - CVPR 2023: Official code for \`Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting'

*   [uoip/stereo\_msckf](https://github.com/uoip/stereo_msckf) - Python implementation of Multi-State Constraint Kalman Filter (MSCKF) for Vision-aided Inertial Navigation.

*   [fundamentalvision/BEVFormer](https://github.com/fundamentalvision/BEVFormer) - \[ECCV 2022] This is the official implementation of BEVFormer, a camera-only framework for autonomous driving perception, e.g., 3D object detection and semantic map segmentation.

*   [NVlabs/FB-BEV](https://github.com/NVlabs/FB-BEV) - Official PyTorch implementation of FB-BEV & FB-OCC - Forward-backward view transformation for vision-centric autonomous driving perception

*   [OpenDriveLab/OccNet](https://github.com/OpenDriveLab/OccNet) - \[ICCV 2023] OccNet: Scene as Occupancy

*   [Tsinghua-MARS-Lab/Occ3D](https://github.com/Tsinghua-MARS-Lab/Occ3D) -

*   [MCG-NJU/SparseOcc](https://github.com/MCG-NJU/SparseOcc) - \[ECCV 2024] Fully Sparse 3D Occupancy Prediction & RayIoU Evaluation Metric

*   [VISION-SJTU/SparseOcc](https://github.com/VISION-SJTU/SparseOcc) - Official implementation for 'SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction' (CVPR 2024)

*   [weiyithu/SurroundOcc](https://github.com/weiyithu/SurroundOcc) - \[ICCV 2023] SurroundOcc: Multi-camera 3D Occupancy Prediction for Autonomous Driving

*   [autonomousvision/occupancy\_networks](https://github.com/autonomousvision/occupancy_networks) - This repository contains the code for the paper "Occupancy Networks - Learning 3D Reconstruction in Function Space"

*   [SY-007-Research/3dgs\_render\_python](https://github.com/SY-007-Research/3dgs_render_python) -

*   [Ferry-Li/SI-SOD](https://github.com/Ferry-Li/SI-SOD) - ICML2024: Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection

*   [Ferry-Li/SI\_Metric](https://github.com/Ferry-Li/SI_Metric) - A portable computation of Size-Invariant Metrics for ICML2024: Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection

*   [autonomousvision/mip-splatting](https://github.com/autonomousvision/mip-splatting) - \[CVPR'24 Best Student Paper] Mip-Splatting: Alias-free 3D Gaussian Splatting

*   [Vincentqyw/image-matching-webui](https://github.com/Vincentqyw/image-matching-webui) - ğŸ¤— image matching toolbox webui

*   [LiheYoung/Depth-Anything](https://github.com/LiheYoung/Depth-Anything) - \[CVPR 2024] Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data. Foundation Model for Monocular Depth Estimation

*   [microsoft/graphrag](https://github.com/microsoft/graphrag) - A modular graph-based Retrieval-Augmented Generation (RAG) system

*   [rvp-group/vbr-devkit](https://github.com/rvp-group/vbr-devkit) - Visual Benchmark in Rome Development Kit

*   [utiasSTARS/pykitti](https://github.com/utiasSTARS/pykitti) - Python tools for working with KITTI data.

*   [TQTQliu/MVSGaussian](https://github.com/TQTQliu/MVSGaussian) - \[ECCV 2024] MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo

*   [buaacyw/MeshAnything](https://github.com/buaacyw/MeshAnything) - From anything to mesh like human artists. Official impl. of "MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers"

*   [swc-17/SparseDrive](https://github.com/swc-17/SparseDrive) - SparseDrive: End-to-End Autonomous Driving via Sparse Scene Representation

*   [minghanqin/LangSplat](https://github.com/minghanqin/LangSplat) - Official implementation of the paper "LangSplat: 3D Language Gaussian Splatting" \[CVPR2024 Highlight]

*   [Xinyu-Yi/TransPose](https://github.com/Xinyu-Yi/TransPose) - A real-time motion capture system that estimates poses and global translations using only 6 inertial measurement units

*   [Awesome3DGS/3D-Gaussian-Splatting-Papers](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers) - 3Dé«˜æ–¯è®ºæ–‡ï¼ŒæŒç»­æ›´æ–°ï¼Œæ¬¢è¿äº¤æµè®¨è®ºã€‚

*   [JonathonLuiten/Dynamic3DGaussians](https://github.com/JonathonLuiten/Dynamic3DGaussians) -

*   [cvg/glue-factory](https://github.com/cvg/glue-factory) - Training library for local feature detection and matching

*   [cvg/LightGlue](https://github.com/cvg/LightGlue) - LightGlue: Local Feature Matching at Light Speed (ICCV 2023)

*   [muskie82/MonoGS](https://github.com/muskie82/MonoGS) - \[CVPR'24 Highlight & Best Demo Award] Gaussian Splatting SLAM

*   [lukas-blecher/LaTeX-OCR](https://github.com/lukas-blecher/LaTeX-OCR) - pix2tex: Using a ViT to convert images of equations into LaTeX code.

*   [tjiiv-cprg/EPro-PnP](https://github.com/tjiiv-cprg/EPro-PnP) - \[CVPR 2022 Oral, Best Student Paper] EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation

*   [ChiWeiHsiao/DeepVO-pytorch](https://github.com/ChiWeiHsiao/DeepVO-pytorch) - PyTorch Implementation of DeepVO

*   [cvg/nice-slam](https://github.com/cvg/nice-slam) - \[CVPR'22] NICE-SLAM: Neural Implicit Scalable Encoding for SLAM

*   [yanyan-li/SLAM-BOOK](https://github.com/yanyan-li/SLAM-BOOK) - è¿™æ˜¯ä¸€æœ¬å…³äºSLAMçš„ä¹¦ç¨¿ï¼Œå¸Œæœ›èƒ½æ¸…æ¥šçš„ä»‹ç»SLAMç³»ç»Ÿä¸­çš„ä½¿ç”¨çš„å‡ ä½•æ–¹æ³•å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚ä¹¦ç¨¿æœ€ååº”è¯¥ä¼šè¾¾åˆ°200é¡µå·¦å³ï¼Œä¹¦ç¨¿æ¯ç« å¯¹åº”çš„ä»£ç ä¹Ÿä¼šè¢«æ•´ç†å‡ºæ¥ã€‚

*   [Shiaoming/Python-VO](https://github.com/Shiaoming/Python-VO) - A simple python implemented frame-by-frame visual odometry with SuperPoint feature detector and SuperGlue feature matcher.

*   [openxrlab/xrdslam](https://github.com/openxrlab/xrdslam) - Platform for Deep Learning based SLAM

*   [simondlevy/TinyEKF](https://github.com/simondlevy/TinyEKF) - Lightweight C/C++ Extended Kalman Filter with Python for prototyping

*   [meta-llama/llama3](https://github.com/meta-llama/llama3) - The official Meta Llama 3 GitHub site

*   [binary-husky/gpt\_academic](https://github.com/binary-husky/gpt_academic) - ä¸ºGPT/GLMç­‰LLMå¤§è¯­è¨€æ¨¡å‹æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒchatglm3ç­‰æœ¬åœ°æ¨¡å‹ã€‚æ¥å…¥é€šä¹‰åƒé—®, deepseekcoder, è®¯é£æ˜Ÿç«, æ–‡å¿ƒä¸€è¨€, llama2, rwkv, claude2, mossç­‰ã€‚

*   [aipixel/GPS-Gaussian](https://github.com/aipixel/GPS-Gaussian) - \[CVPR 2024 Highlight] The official repo for â€œGPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesisâ€

*   [JiuSan-WesternRegion/KF-GINS-PyVersion](https://github.com/JiuSan-WesternRegion/KF-GINS-PyVersion) - A python version of the KF-GINS

*   [graphdeco-inria/gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting) - Original reference implementation of "3D Gaussian Splatting for Real-Time Radiance Field Rendering"

*   [ToniRV/NeRF-SLAM](https://github.com/ToniRV/NeRF-SLAM) - NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields. https://arxiv.org/abs/2210.13641   +   Sigma-Fusion: Probabilistic Volumetric Fusion for Dense Monocular SLAM  https://arxiv.org/abs/2210.01276

*   [electech6/NeRF-Based-SLAM-Incredible-Insights](https://github.com/electech6/NeRF-Based-SLAM-Incredible-Insights) -

## C++

*   [i3tyc/AdaptSLAM](https://github.com/i3tyc/AdaptSLAM) - AdaptSLAM: Edge-Assisted Adaptive SLAM with Resource Constraints via Uncertainty Minimization

*   [Zhefan-Xu/onboard\_detector](https://github.com/Zhefan-Xu/onboard_detector) - \[IEEE RA-L'24] Dynamic Obstacle Detection and Tracking (DODT) algorithm for Autonomous Robots (C++/ROS)

*   [nkliuhui/sync\_gps\_lidar\_imu\_cam](https://github.com/nkliuhui/sync_gps_lidar_imu_cam) - lidar-imu-cam-GPSæ—¶é—´æˆ³ç¡¬ä»¶åŒæ­¥æ–¹æ¡ˆ

*   [tum-vision/lsd\_slam](https://github.com/tum-vision/lsd_slam) - LSD-SLAM

*   [yutongwangBIT/GOReloc](https://github.com/yutongwangBIT/GOReloc) -

*   [HeYijia/VINS-Course](https://github.com/HeYijia/VINS-Course) - VINS-Mono code without Ceres or ROS

*   [SainingZhang/UC-GS](https://github.com/SainingZhang/UC-GS) - \[BMVC 2024 ] Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty

*   [AndreasArendt/OpenRTK](https://github.com/AndreasArendt/OpenRTK) - Open Source precise GNSS Software

*   [PetWorm/LARVIO](https://github.com/PetWorm/LARVIO) - A lightweight, accurate and robust monocular visual inertial odometry based on Multi-State Constraint Kalman Filter.

*   [ManiiXu/VINS-Mono-Learning](https://github.com/ManiiXu/VINS-Mono-Learning) - VINS-Monoä»£ç æ³¨é‡Šï¼Œä»…ä¾›å­¦ä¹ 

*   [sair-lab/AirSLAM](https://github.com/sair-lab/AirSLAM) - ğŸš€ AirVO upgrades to AirSLAM ğŸš€

*   [city-super/Octree-GS](https://github.com/city-super/Octree-GS) - Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians

*   [CG050523/PPP-Navigation](https://github.com/CG050523/PPP-Navigation) - ä¼ªè·å•ç‚¹å®šä½ç¨‹åºå®ç°ï¼Œä»…å­¦ä¹ ä½¿ç”¨

*   [Alex-Beh/yolov5\_ros](https://github.com/Alex-Beh/yolov5_ros) -

*   [VIS4ROB-lab/ccm\_slam](https://github.com/VIS4ROB-lab/ccm_slam) - CCM-SLAM: Robust and Efficient Centralized Collaborative Monocular SLAM for Robotic Teams

*   [microsoft/Azure-Kinect-Sensor-SDK](https://github.com/microsoft/Azure-Kinect-Sensor-SDK) - A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device.

*   [yanyan-li/PlanarSLAM](https://github.com/yanyan-li/PlanarSLAM) - A RGB-D SLAM system for structural scenes, which makes use of point-line-plane features and the Manhattan World assumption.

*   [STAR-Center/VINS-RGBD](https://github.com/STAR-Center/VINS-RGBD) -

*   [TixiaoShan/LIO-SAM](https://github.com/TixiaoShan/LIO-SAM) - LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping

*   [TixiaoShan/LVI-SAM](https://github.com/TixiaoShan/LVI-SAM) - LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping

*   [danping/CoSLAM](https://github.com/danping/CoSLAM) - CoSLAM is a visual SLAM software that aims to use multiple freely moving cameras to simultaneously compute their egomotion and the 3D map of the surrounding scenes in a highly dynamic environment.

*   [google/or-tools](https://github.com/google/or-tools) - Google's Operations Research tools:

*   [JakobEngel/dso](https://github.com/JakobEngel/dso) - Direct Sparse Odometry

*   [AnswerDotAI/gpu.cpp](https://github.com/AnswerDotAI/gpu.cpp) - A lightweight library for portable low-level GPU computation using WebGPU.

*   [ethz-asl/wavemap](https://github.com/ethz-asl/wavemap) - Fast, efficient and accurate multi-resolution, multi-sensor 3D occupancy mapping

*   [RonaldSun/VI-Stereo-DSO](https://github.com/RonaldSun/VI-Stereo-DSO) - Direct sparse odometry combined with stereo cameras and IMU

*   [GREAT-WHU/GREAT-iKalibr](https://github.com/GREAT-WHU/GREAT-iKalibr) -

*   [MIT-SPARK/Kimera-RPGO](https://github.com/MIT-SPARK/Kimera-RPGO) - Robust Pose Graph Optimization

*   [lian-yue0515/MM-LINS](https://github.com/lian-yue0515/MM-LINS) - a Multi-Map LiDAR-Inertial System for Over-Degraded Environments

*   [engcang/vins-application](https://github.com/engcang/vins-application) - VINS-Fusion, VINS-Fisheye, OpenVINS, EnVIO, ROVIO, S-MSCKF, ORB-SLAM2, NVIDIA Elbrus application of different sets of cameras and imu on different board including desktop and Jetson boards

*   [floatlazer/semantic\_slam](https://github.com/floatlazer/semantic_slam) - Real time semantic slam in ROS with a hand held RGB-D camera

*   [koide3/gtsam\_points](https://github.com/koide3/gtsam_points) - A collection of GTSAM factors and optimizers for point cloud SLAM

*   [BaowenZ/RaDe-GS](https://github.com/BaowenZ/RaDe-GS) - RaDe-GS: Rasterizing Depth in Gaussian Splatting

*   [Unsigned-Long/iKalibr](https://github.com/Unsigned-Long/iKalibr) - iKalibr: Unified Targetless Spatiotemporal Calibration for Resilient Integrated Inertial Systems

*   [emiliofidalgo/ibow-lcd](https://github.com/emiliofidalgo/ibow-lcd) - Appearance-based Loop Closure Detection using Incremental Bags of Binary Words

*   [bxh1/VIDO-SLAM](https://github.com/bxh1/VIDO-SLAM) - VIDO-SLAM is a  Visual Inertial SLAM system for dynamic environments, and it can  also estimate dynamic objects motion and track objects.

*   [url-kaist/dynaVINS](https://github.com/url-kaist/dynaVINS) - DynaVINS : A Visual-Inertial SLAM for Dynamic Environments

*   [MAVIS-SLAM/OpenMAVIS](https://github.com/MAVIS-SLAM/OpenMAVIS) - An open-source implementation of MAVIS-SLAM.

*   [linyicheng1/OpenSLAM-Notes](https://github.com/linyicheng1/OpenSLAM-Notes) - ä¸ªäººå¯¹ç›®å‰è¾ƒä¸ºæˆç†Ÿçš„è§†è§‰/æ¿€å…‰SLAMç®—æ³•è¿›è¡Œçš„æ³¨é‡Šä»¥åŠè§£è¯»æ–‡ä»¶

*   [guisoares9/VINS-Fusion](https://github.com/guisoares9/VINS-Fusion) - OpenCV 4, ROS Noetic, and Ceres adaptation of VINS-Fusion. An optimization-based multi-sensor state estimator

*   [cyp4x141/VINS-Fusion-noetic-Opencv4](https://github.com/cyp4x141/VINS-Fusion-noetic-Opencv4) - VINS-Fusion for opencv4 + noetic +ubuntu20.04

*   [shanpenghui/ORB\_SLAM3\_Fixed](https://github.com/shanpenghui/ORB_SLAM3_Fixed) - Optimized ORBSLAM3 to run on TUM/EuRoc/KITTI dataset

*   [karanchawla/GPS\_IMU\_Kalman\_Filter](https://github.com/karanchawla/GPS_IMU_Kalman_Filter) - Fusing GPS, IMU and Encoder sensors for accurate state estimation.

*   [yuefanhao/SuperPoint-SuperGlue-TensorRT](https://github.com/yuefanhao/SuperPoint-SuperGlue-TensorRT) - SuperPoint and SuperGlue with TensorRT. Deploy with C++.

*   [kajo-kurisu/D\_VINS](https://github.com/kajo-kurisu/D_VINS) - Merge superpointã€lightglueã€MixVPR into VINS-FUSION for loop closure with TensorRT

*   [HeYijia/PL-VIO](https://github.com/HeYijia/PL-VIO) - monocular visual inertial system with point and line features

*   [openxrlab/xrslam](https://github.com/openxrlab/xrslam) - OpenXRLab Visual-inertial SLAM Toolbox and Benchmark

*   [KumarRobotics/msckf\_vio](https://github.com/KumarRobotics/msckf_vio) - Robust Stereo Visual Inertial Odometry for Fast Autonomous Flight

*   [i2Nav-WHU/IC-GVINS](https://github.com/i2Nav-WHU/IC-GVINS) - A Robust, Real-time, INS-Centric GNSS-Visual-Inertial Navigation System

*   [ydsf16/imu\_gps\_localization](https://github.com/ydsf16/imu_gps_localization) - Using error-state Kalman filter to fuse the IMU and GPS data for localization.

*   [cnqiangfu/PL-VINS](https://github.com/cnqiangfu/PL-VINS) - PL-VINS: Real-Time Monocular Visual-Inertial SLAM with Point and Line Features

*   [microsoft/onnxruntime](https://github.com/microsoft/onnxruntime) - ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator

*   [HKUST-Aerial-Robotics/VINS-Mono](https://github.com/HKUST-Aerial-Robotics/VINS-Mono) - A Robust and Versatile Monocular Visual-Inertial State Estimator

*   [ethz-asl/ethzasl\_msf](https://github.com/ethz-asl/ethzasl_msf) - MSF - Modular framework for multi sensor fusion based on an Extended Kalman Filter (EKF)

*   [zm0612/eskf-gps-imu-fusion](https://github.com/zm0612/eskf-gps-imu-fusion) - è¯¯å·®çŠ¶æ€å¡å°”æ›¼ESKFæ»¤æ³¢å™¨èåˆGPSå’ŒIMUï¼Œå®ç°æ›´é«˜ç²¾åº¦çš„å®šä½

*   [Ewenwan/MVision](https://github.com/Ewenwan/MVision) - æœºå™¨äººè§†è§‰ ç§»åŠ¨æœºå™¨äºº VS-SLAM ORB-SLAM2 æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ yolov3 è¡Œä¸ºæ£€æµ‹ opencv  PCL æœºå™¨å­¦ä¹  æ— äººé©¾é©¶

*   [raulmur/ORB\_SLAM2](https://github.com/raulmur/ORB_SLAM2) - Real-Time SLAM for Monocular, Stereo and RGB-D Cameras, with Loop Detection and Relocalization Capabilities

*   [ivipsourcecode/DS-SLAM](https://github.com/ivipsourcecode/DS-SLAM) -

*   [ceres-solver/ceres-solver](https://github.com/ceres-solver/ceres-solver) - A large scale non-linear optimization library

*   [shazraz/Extended-Kalman-Filter](https://github.com/shazraz/Extended-Kalman-Filter) - Implementation of an EKF in C++

*   [rpng/open\_vins](https://github.com/rpng/open_vins) - An open source platform for visual-inertial navigation research.

*   [Ewenwan/ORB\_SLAM2\_SSD\_Semantic](https://github.com/Ewenwan/ORB_SLAM2_SSD_Semantic) - åŠ¨æ€è¯­ä¹‰SLAM ç›®æ ‡æ£€æµ‹+VSLAM+å…‰æµ/å¤šè§†è§’å‡ ä½•åŠ¨æ€ç‰©ä½“æ£€æµ‹+octomapåœ°å›¾+ç›®æ ‡æ•°æ®åº“

*   [KennyWGH/VINS-Fusion-Understood](https://github.com/KennyWGH/VINS-Fusion-Understood) - å®Œå…¨å¯ç†è§£çš„VINS-Fusionï¼š1.ä»£ç é£æ ¼é‡æ„ã€2.å…¨é‡é è°±æ³¨é‡Šã€3.ä»£ç å³æ–‡æ¡£ã€4.å¿ å®äºåŸä»£ç ï¼›5.ROSè§£è€¦ã€6.çŠ¶æ€é‡å¯è§†åŒ–ã€7.æ—¥å¿—ç³»ç»Ÿã€‚

*   [hmartiro/kalman-cpp](https://github.com/hmartiro/kalman-cpp) - Basic Kalman filter implementation in C++ using Eigen

*   [HITSZ-NRSL/Dynamic-VINS](https://github.com/HITSZ-NRSL/Dynamic-VINS) - \[RA-L 2022] RGB-D Inertial Odometry for a Resource-restricted Robot in Dynamic Environments

*   [i2Nav-WHU/OB\_GINS](https://github.com/i2Nav-WHU/OB_GINS) - An Optimization-Based GNSS/INS Integrated Navigation System

*   [i2Nav-WHU/KF-GINS](https://github.com/i2Nav-WHU/KF-GINS) - An EKF-Based GNSS/INS Integrated Navigation System

*   [mherb/kalman](https://github.com/mherb/kalman) - Header-only C++11 Kalman Filtering Library (EKF, UKF) based on Eigen3

*   [bytedance/SchurVINS](https://github.com/bytedance/SchurVINS) - \[CVPR2024] SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System

*   [halajun/VDO\_SLAM](https://github.com/halajun/VDO_SLAM) - VDO-SLAM: A Visual Dynamic Object-aware SLAM System

*   [Unsigned-Long/RIs-Calib](https://github.com/Unsigned-Long/RIs-Calib) - a continuous-time-based multi-radar multi-imu spatiotemporal calibrator

## miscellaneous

*   [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) - Master programming by recreating your favorite technologies from scratch.

*   [hku-mars/FAST-LIVO2](https://github.com/hku-mars/FAST-LIVO2) - FAST-LIVO2: Fast, Direct LiDAR-Inertial-Visual Odometry

*   [StevenCui/VIO-Doc](https://github.com/StevenCui/VIO-Doc) - ä¸»æµVIOè®ºæ–‡æ¨å¯¼åŠä»£ç è§£æ

*   [ericzzj1989/Awesome-Image-Matching](https://github.com/ericzzj1989/Awesome-Image-Matching) -

*   [luohongk/SuperVINS](https://github.com/luohongk/SuperVINS) - A visual-inertial SLAM framework integrated deep learning features

*   [miss-mumu/developer2gwy](https://github.com/miss-mumu/developer2gwy) - å…¬åŠ¡å‘˜ä»å…¥é—¨åˆ°ä¸Šå²¸ï¼Œæœ€ä½³ç¨‹åºå‘˜å…¬è€ƒå®è·µæ•™ç¨‹

*   [0voice/expert\_readed\_books](https://github.com/0voice/expert_readed_books) - 2021å¹´æœ€æ–°æ€»ç»“ï¼Œæ¨èå·¥ç¨‹å¸ˆåˆé€‚è¯»æœ¬ï¼Œè®¡ç®—æœºç§‘å­¦ï¼Œè½¯ä»¶æŠ€æœ¯ï¼Œåˆ›ä¸šï¼Œæ€æƒ³ç±»ï¼Œæ•°å­¦ç±»ï¼Œäººç‰©ä¼ è®°ä¹¦ç±

*   [jianzongwu/Awesome-Open-Vocabulary](https://github.com/jianzongwu/Awesome-Open-Vocabulary) - (TPAMI 2024) A Survey on Open Vocabulary Learning

*   [ViewFormerOcc/ViewFormer-Occ](https://github.com/ViewFormerOcc/ViewFormer-Occ) - \[ECCV 2024] ViewFormer: Exploring Spatiotemporal Modeling for Multi-View 3D Occupancy Perception via View-Guided Transformers

*   [lvchuandong/Awesome-Multi-Camera-3D-Occupancy-Prediction](https://github.com/lvchuandong/Awesome-Multi-Camera-3D-Occupancy-Prediction) - Awesome papers and code about Multi-Camera 3D Occupancy Prediction, such as TPVFormer, SurroundOcc, PanoOcc, OccFormer, FB-OCC, SelfOcc, COTR, SparseOcc. In this repository, you will see the latest 3D occupancy prediction papers and code.

*   [eriksandstroem/Splat-SLAM](https://github.com/eriksandstroem/Splat-SLAM) -

*   [bdvisl/DriveInsight](https://github.com/bdvisl/DriveInsight) -

*   [pubsys/ReviewSystem](https://github.com/pubsys/ReviewSystem) - å®¡ç¨¿ç³»ç»Ÿçš„è‡ªè¿°

*   [huang-yh/GaussianFormer](https://github.com/huang-yh/GaussianFormer) - \[ECCV 2024] Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction

*   [weisongwen/UrbanNavDataset](https://github.com/weisongwen/UrbanNavDataset) - UrbanNav: anÂ Open-Sourcing Localization Data Collected in Asian Urban Canyons, Including Tokyo and Hong Kong

*   [datawhalechina/pumpkin-book](https://github.com/datawhalechina/pumpkin-book) - ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼ˆè¥¿ç“œä¹¦ï¼‰å…¬å¼è¯¦è§£

*   [pengsida/learning\_research](https://github.com/pengsida/learning_research) - æœ¬äººçš„ç§‘ç ”ç»éªŒ

*   [zzzzxxxx111/SLslam](https://github.com/zzzzxxxx111/SLslam) -

*   [amusi/Deep-Learning-Interview-Book](https://github.com/amusi/Deep-Learning-Interview-Book) - æ·±åº¦å­¦ä¹ é¢è¯•å®å…¸ï¼ˆå«æ•°å­¦ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†å’ŒSLAMç­‰æ–¹å‘ï¼‰

*   [IRMVLab/SNI-SLAM](https://github.com/IRMVLab/SNI-SLAM) - \[CVPR'24] SNI-SLAM: Semantic Neural Implicit SLAM

*   [cbamls/AI\_Tutorial](https://github.com/cbamls/AI_Tutorial) - ç²¾é€‰æœºå™¨å­¦ä¹ ï¼ŒNLPï¼Œå›¾åƒè¯†åˆ«ï¼Œ æ·±åº¦å­¦ä¹ ç­‰äººå·¥æ™ºèƒ½é¢†åŸŸå­¦ä¹ èµ„æ–™ï¼Œæœç´¢ï¼Œæ¨èï¼Œå¹¿å‘Šç³»ç»Ÿæ¶æ„åŠç®—æ³•æŠ€æœ¯èµ„æ–™æ•´ç†ã€‚ç®—æ³•å¤§ç‰›ç¬”è®°æ±‡æ€»

*   [MrNeRF/awesome-3D-gaussian-splatting](https://github.com/MrNeRF/awesome-3D-gaussian-splatting) - Curated list of papers and resources focused on 3D Gaussian Splatting, intended to keep pace with the anticipated surge of research in the coming months.

*   [DoongLi/awesome-Implicit-NeRF-SLAM](https://github.com/DoongLi/awesome-Implicit-NeRF-SLAM) - A comprehensive list of Implicit Representations, NeRF and 3D Gaussian Splatting papers relating to SLAM/Robotics domain, including papers, videos, codes, and related websites

## Jupyter Notebook

*   [datawhalechina/leedl-tutorial](https://github.com/datawhalechina/leedl-tutorial) - ã€Šæå®æ¯…æ·±åº¦å­¦ä¹ æ•™ç¨‹ã€‹ï¼ˆæå®æ¯…è€å¸ˆæ¨èğŸ‘ï¼Œè‹¹æœä¹¦ğŸï¼‰ï¼ŒPDFä¸‹è½½åœ°å€ï¼šhttps://github.com/datawhalechina/leedl-tutorial/releases

*   [Fafa-DL/Lhy\_Machine\_Learning](https://github.com/Fafa-DL/Lhy_Machine_Learning) - æå®æ¯…2021/2022/2023æ˜¥å­£æœºå™¨å­¦ä¹ è¯¾ç¨‹è¯¾ä»¶åŠä½œä¸š

*   [yubaoliu/RDS-SLAM](https://github.com/yubaoliu/RDS-SLAM) - DS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods

*   [SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist) - The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery ğŸ§‘â€ğŸ”¬

*   [datawhalechina/self-llm](https://github.com/datawhalechina/self-llm) - ã€Šå¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—ã€‹åŸºäºLinuxç¯å¢ƒå¿«é€Ÿéƒ¨ç½²å¼€æºå¤§æ¨¡å‹ï¼Œæ›´é€‚åˆä¸­å›½å®å®çš„éƒ¨ç½²æ•™ç¨‹

*   [facebookresearch/segment-anything-2](https://github.com/facebookresearch/segment-anything-2) - The repository provides code for running inference with the Meta Segment Anything Model 2 (SAM 2), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.

*   [hustvl/4DGaussians](https://github.com/hustvl/4DGaussians) - \[CVPR 2024] 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering

*   [heucoder/ML-DL\_book](https://github.com/heucoder/ML-DL_book) - æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ä¸€äº›ä¸ªäººè®¤ä¸ºä¸é”™çš„ä¹¦ç±ã€‚

*   [verlab/accelerated\_features](https://github.com/verlab/accelerated_features) - Implementation of XFeat (CVPR 2024). Do you need robust and fast local feature extraction? You are in the right place!

*   [rpautrat/SuperPoint](https://github.com/rpautrat/SuperPoint) - Efficient neural feature detector and descriptor

*   [rlabbe/Kalman-and-Bayesian-Filters-in-Python](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python) - Kalman Filter book using Jupyter Notebook. Focuses on building intuition and experience, not formal proofs.  Includes Kalman filters,extended Kalman filters, unscented Kalman filters, particle filters, and more. All exercises include solutions.

## TypeScript

*   [ocsjs/ocsjs](https://github.com/ocsjs/ocsjs) - OCS ç½‘è¯¾åŠ©æ‰‹ï¼Œåˆ·è¯¾è„šæœ¬ï¼Œç½‘è¯¾è„šæœ¬ï¼Œå¸®åŠ©å¤§å­¦ç”Ÿè§£å†³ç½‘è¯¾éš¾é¢˜ï¼Œæ”¯æŒã€è¶…æ˜Ÿå­¦ä¹ é€šã€‘ã€çŸ¥é“æ™ºæ…§æ ‘ã€‘ã€èŒæ•™äº‘ã€‘ã€æ™ºæ…§èŒæ•™ã€‘ã€ä¸­å›½å¤§å­¦MOOCã€‘ç­‰ç½‘è¯¾  ï¼Œ å¯ä»¥åœ¨ è„šæœ¬çŒ« ä»¥åŠ æ²¹çŒ´ ç­‰å¼€æºè„šæœ¬ç®¡ç†å™¨ä¸‹è¿è¡Œã€‚

*   [immich-app/immich](https://github.com/immich-app/immich) - High performance self-hosted photo and video management solution.

*   [clash-verge-rev/clash-verge-rev](https://github.com/clash-verge-rev/clash-verge-rev) - Continuation of Clash Verge - A Clash Meta GUI based on Tauri (Windows, MacOS, Linux)

## Clojure

*   [tonsky/FiraCode](https://github.com/tonsky/FiraCode) - Free monospaced font with programming ligatures

## SCSS

*   [mcdviral/mcdviral.github.io](https://github.com/mcdviral/mcdviral.github.io) -

## C

*   [0voice/algorithm-structure](https://github.com/0voice/algorithm-structure) - 2021å¹´æœ€æ–°æ€»ç»“ 500ä¸ªå¸¸ç”¨æ•°æ®ç»“æ„ï¼Œç®—æ³•ï¼Œç®—æ³•å¯¼è®ºï¼Œé¢è¯•å¸¸ç”¨ï¼Œå¤§å‚é«˜çº§å·¥ç¨‹å¸ˆæ•´ç†æ€»ç»“

*   [kevin2431/Traj-LO](https://github.com/kevin2431/Traj-LO) - \[RA-L 2024] In Defense of LiDAR-Only Odometry Using an Effective Continuous-Time Trajectory

*   [rtklibexplorer/RTKLIB](https://github.com/rtklibexplorer/RTKLIB) - A version of RTKLIB optimized for low cost GNSS receivers, especially u-blox receivers.  It is based on RTKLIB 2.4.3 and is kept reasonably closely synced to that branch.  This software is provided â€œAS ISâ€ without any warranties of any kind so please be careful, especially if using it in any kind of real-time application.

*   [tomojitakasu/RTKLIB](https://github.com/tomojitakasu/RTKLIB) -

*   [MichaelBeechan/PPP-RTK](https://github.com/MichaelBeechan/PPP-RTK) - SPPã€RTDã€PPPã€RTKã€PPP-RTKã€RAIMã€ARAIM et al

## CSS

*   [Maserhe/VScode-Markdown-theme-Maserhe](https://github.com/Maserhe/VScode-Markdown-theme-Maserhe) - vscode è‡ªå®šä¹‰Markdownæ’ç‰ˆé£æ ¼ï¼Œä»¥åŠä»£ç å—æ ·å¼é£æ ¼ã€‚

*   [wzzheng/GaussianFormer](https://github.com/wzzheng/GaussianFormer) - Project Page for GaussianFormer

## Makefile

*   [kahowang/FAST\_LIO\_SAM](https://github.com/kahowang/FAST_LIO_SAM) - Front\_end : fastlio2  Back\_end : lio\_sam

## Java

*   [krahets/hello-algo](https://github.com/krahets/hello-algo) - ã€ŠHello ç®—æ³•ã€‹ï¼šåŠ¨ç”»å›¾è§£ã€ä¸€é”®è¿è¡Œçš„æ•°æ®ç»“æ„ä¸ç®—æ³•æ•™ç¨‹ã€‚æ”¯æŒ Python, Java, C++, C, C#, JS, Go, Swift, Rust, Ruby, Kotlin, TS, Dart ä»£ç ã€‚ç®€ä½“ç‰ˆå’Œç¹ä½“ç‰ˆåŒæ­¥æ›´æ–°ï¼ŒEnglish version ongoing

## Go

*   [sourcegraph/sourcegraph-public-snapshot](https://github.com/sourcegraph/sourcegraph-public-snapshot) - Code AI platform with Code Search & Cody

## Vim Script

*   [amix/vimrc](https://github.com/amix/vimrc) - The ultimate Vim configuration (vimrc)

*   [vim/vim](https://github.com/vim/vim) - The official Vim repository

*   [linrongbin16/lin.vim](https://github.com/linrongbin16/lin.vim) - Lin Rongbin's (Neo)Vim Distribution

## MATLAB

*   [ShiArthur03/ShiArthur03](https://github.com/ShiArthur03/ShiArthur03) -

## C\#

*   [mahoshojo0805/ContestPrograms](https://github.com/mahoshojo0805/ContestPrograms) - æµ‹ç»˜æŠ€èƒ½å¤§èµ›ç¨‹åº

*   [Code52/carnac](https://github.com/Code52/carnac) - A utility to give some insight into how you use your keyboard

## JavaScript

*   [lutzroeder/netron](https://github.com/lutzroeder/netron) - Visualizer for neural network, deep learning and machine learning models
