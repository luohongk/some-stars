<div align="center">

# Some Stars

â­ <a href="https://luohongkun.com/"  target="_blank">LuoHongkun</a>çš„staråˆ—è¡¨ï¼Œæ¯6å°æ—¶è‡ªåŠ¨æ›´æ–°,å‚è€ƒé“¾æ¥-><a href="https://linux.do/t/topic/115143"  target="_blank">github staråˆ—è¡¨è‡ªåŠ¨æ›´æ–°</a> â­

</div><br>

## Table of Contents

*   [C](#c)
*   [CMake](#cmake)
*   [C++](#c-1)
*   [TypeScript](#typescript)
*   [Python](#python)
*   [Lua](#lua)
*   [miscellaneous](#miscellaneous)
*   [JavaScript](#javascript)
*   [CSS](#css)
*   [Jupyter Notebook](#jupyter-notebook)
*   [MATLAB](#matlab)
*   [Dockerfile](#dockerfile)
*   [SCSS](#scss)
*   [HTML](#html)
*   [Dart](#dart)
*   [Markdown](#markdown)
*   [TeX](#tex)
*   [Clojure](#clojure)
*   [Makefile](#makefile)
*   [Java](#java)
*   [Go](#go)
*   [Vim Script](#vim-script)
*   [C#](#c-2)

## C

*   [MrNeRF/gaussian-splatting-cuda](https://github.com/MrNeRF/gaussian-splatting-cuda) - 3D Gaussian Splatting, reimagined: Unleashing unmatched speed with C++ and CUDA from the ground up!

*   [0voice/algorithm-structure](https://github.com/0voice/algorithm-structure) - 2021å¹´æœ€æ–°æ€»ç»“ 500ä¸ªå¸¸ç”¨æ•°æ®ç»“æ„ï¼Œç®—æ³•ï¼Œç®—æ³•å¯¼è®ºï¼Œé¢è¯•å¸¸ç”¨ï¼Œå¤§å‚é«˜çº§å·¥ç¨‹å¸ˆæ•´ç†æ€»ç»“

*   [kevin2431/Traj-LO](https://github.com/kevin2431/Traj-LO) - \[RA-L 2024] In Defense of LiDAR-Only Odometry Using an Effective Continuous-Time Trajectory

## CMake

*   [xieyuser/GS-LIVM](https://github.com/xieyuser/GS-LIVM) - GS-LIVM: Real-Time Photo-Realistic LiDAR-Inertial-Visual Mapping with Gaussian Splatting

## C++

*   [Unsigned-Long/Useful-Functions](https://github.com/Unsigned-Long/Useful-Functions) - Give it a try! Try and die!

*   [Unsigned-Long/slam-tricks](https://github.com/Unsigned-Long/slam-tricks) - small, powerful and beautiful slam tricks with theory and practice

*   [farhad-dalirani/StereoVision-SLAM](https://github.com/farhad-dalirani/StereoVision-SLAM) - StereoVision-SLAM is a real-time visual stereo SLAM (Simultaneous Localization and Mapping)

*   [gaoxiang12/faster-lio](https://github.com/gaoxiang12/faster-lio) - Faster-LIO: Lightweight Tightly Coupled Lidar-inertial Odometry using Parallel Sparse Incremental Voxels

*   [NVIDIA/TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.

*   [microsoft/BitNet](https://github.com/microsoft/BitNet) - Official inference framework for 1-bit LLMs

*   [Geekgineer/CloudPeek](https://github.com/Geekgineer/CloudPeek) - CloudPeek is a lightweight, cross-platform, single-header C++ point cloud viewer. Itâ€™s designed for simplicity and efficiency, requiring no heavy libraries like PCL or Open3D. Ideal for visualizing and interacting with 3D data from LiDAR, photogrammetry, or other datasets, CloudPeek delivers powerful, real-time exploration in a minimalistic package

*   [zhuge2333/4DRadarSLAM](https://github.com/zhuge2333/4DRadarSLAM) -

*   [rubengooj/pl-slam](https://github.com/rubengooj/pl-slam) - This code contains an algorithm to compute stereo visual SLAM by using both point and line segment features.

*   [DapengFeng/cartgs](https://github.com/DapengFeng/cartgs) - CaRtGS: Computational Alignment for Real-Time Gaussian Splatting SLAM

*   [alsora/ros2-ORB\_SLAM2](https://github.com/alsora/ros2-ORB_SLAM2) - ROS2 node wrapping the ORB\_SLAM2 library

*   [GREAT-WHU/RoadLib](https://github.com/GREAT-WHU/RoadLib) - A lightweight library for instance-level visual road marking extraction, parameterization, mapping, etc.

*   [TohsakaZ/ppp\_ex](https://github.com/TohsakaZ/ppp_ex) - Prise Point Positioning Experiment

*   [hku-mars/Voxel-SLAM](https://github.com/hku-mars/Voxel-SLAM) -

*   [ChaoqinRobotics/LINS---LiDAR-inertial-SLAM](https://github.com/ChaoqinRobotics/LINS---LiDAR-inertial-SLAM) - A Lidar-Inertial State Estimator for Robust and Efficient Navigation based on iterated error-state Kalman filter

*   [udaysankar01/xfeatSLAM](https://github.com/udaysankar01/xfeatSLAM) - Real-time SLAM with deep features (XFeat + ORB-SLAM3)

*   [yanyan-li/Structure-SLAM-PointLine](https://github.com/yanyan-li/Structure-SLAM-PointLine) - This is a basic point-line SLAM system based on ORBSLAM2.

*   [APRIL-ZJU/lidar\_IMU\_calib](https://github.com/APRIL-ZJU/lidar_IMU_calib) - \[IROS 2020] Targetless Calibration of LiDAR-IMU System Based on Continuous-time Batch Estimation

*   [ashishkumar822/Jetson-SLAM](https://github.com/ashishkumar822/Jetson-SLAM) - A high Speed GPU accelerated SLAM for Low Powered Devices, IEEE- RAL-2023, ICRA 2024

*   [alejandrofontan/AnyFeature-VSLAM](https://github.com/alejandrofontan/AnyFeature-VSLAM) - Any-Feature V-SLAM is an automated visual SLAM library for Monocular cameras capable of switching to a chosen type of feature effortlessly and without manual intervention.

*   [fishmarch/MS-SLAM](https://github.com/fishmarch/MS-SLAM) - \[JFR 2024] This is the official implementation of MS-SLAM, a memory-efficient visual SLAM system removing redundant map points to save memory consumption.

*   [2013fangwentao/Multi\_Sensor\_Fusion](https://github.com/2013fangwentao/Multi_Sensor_Fusion) - Multi-Sensor Fusion (GNSS, IMU, Camera) å¤šæºå¤šä¼ æ„Ÿå™¨èåˆå®šä½ GPS/INSç»„åˆå¯¼èˆª  PPP/INSç´§ç»„åˆ

*   [ethz-asl/kalibr](https://github.com/ethz-asl/kalibr) - The Kalibr visual-inertial calibration toolbox

*   [LuoXubo/JointLoc](https://github.com/LuoXubo/JointLoc) - \[IROS 2024] JointLoc: A Real-time Visual Localization Framework for Planetary UAVs Based on Joint Relative and Absolute Pose Estimation

*   [ethz-asl/okvis](https://github.com/ethz-asl/okvis) - OKVIS: Open Keyframe-based Visual-Inertial SLAM.

*   [smartroboticslab/okvis2](https://github.com/smartroboticslab/okvis2) - Open Keyframe-based Visual-Inertial SLAM (Version 2)

*   [HViktorTsoi/FAST\_LIO\_LOCALIZATION](https://github.com/HViktorTsoi/FAST_LIO_LOCALIZATION) - A simple localization framework that can re-localize in built maps based on FAST-LIO.

*   [GREAT-WHU/GREAT-PVT](https://github.com/GREAT-WHU/GREAT-PVT) -

*   [mengkai98/BA\_Play](https://github.com/mengkai98/BA_Play) - éšæ‰‹å†™ä¸ªBAç©ç©

*   [Yixin-F/LiLoc](https://github.com/Yixin-F/LiLoc) - (ICRA 2025 Submitted) LiLoc: Lifelong Localization using Adaptive Submap Joining and Egocentric Factor Graph

*   [Yixin-F/better\_fastlio2](https://github.com/Yixin-F/better_fastlio2) - Postgraduate Thesis: fast\_lio\_sam + dynamic removal (T-GRS 2024) + multi-session mapping (ICRA 2022 Kim) + object-level update + online relocalization (ICRA 2025 submittion)

*   [udaysankar01/xfeat\_cpp](https://github.com/udaysankar01/xfeat_cpp) - The C++ Implementation of XFeat (Accelerated Features).

*   [chengwei0427/ct-lio](https://github.com/chengwei0427/ct-lio) - CT-LIO: Continuous-Time LiDAR-Inertial Odometry

*   [felixendres/rgbdslam\_v2](https://github.com/felixendres/rgbdslam_v2) - RGB-D SLAM for ROS

*   [Eliaul/Eq-LIO](https://github.com/Eliaul/Eq-LIO) - A tightly coupled LIO framework based on the equivariant filter.

*   [HKUST-Aerial-Robotics/GVINS](https://github.com/HKUST-Aerial-Robotics/GVINS) - Tightly coupled GNSS-Visual-Inertial system for locally smooth and globally consistent state estimation in complex environment.

*   [HuajianUP/Photo-SLAM](https://github.com/HuajianUP/Photo-SLAM) - \[CVPR 2024] Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras

*   [HKUST-Aerial-Robotics/EPSILON](https://github.com/HKUST-Aerial-Robotics/EPSILON) -

*   [rmsalinas/DBow3](https://github.com/rmsalinas/DBow3) - Improved version of DBow2

*   [MigVega/SLAM2REF](https://github.com/MigVega/SLAM2REF) -  This project allows the  alignment and correction of LiDAR-based SLAM session data with a reference map or another session, also the retrieval of 6-DoF poses with accuracy of up to 3 cm given an accurate TLS point cloud as a reference map (this map should be accurate at least regarding the position of permanent elements such as walls and columns).

*   [lava/matplotlib-cpp](https://github.com/lava/matplotlib-cpp) - Extremely simple yet powerful header-only C++ plotting library built on the popular matplotlib

*   [kuankuan-yue/VINS-FUSION-leanrning](https://github.com/kuankuan-yue/VINS-FUSION-leanrning) - VINS-FUSIONä¸­æ–‡æ³¨é‡Šç‰ˆ.ç›®å‰ç½‘ç»œä¸Šå¯¹äºVINS-monoçš„ä»£ç å·²ç»æœ‰å¾ˆå¤šè®²è§£å’Œæ³¨é‡Šäº†ï¼Œä½†æ˜¯å¯¹äºVINS-FUSIONï¼ˆä»¥ä¸‹ç®€ç§°VFï¼‰çš„æ³¨é‡Šè¿˜æ˜¯å¾ˆå°‘çš„ï¼Œåˆšå¥½æœ¬äººæœ€è¿‘ä¹Ÿæ­£åœ¨å­¦ä¹ VIOçš„ç›¸å…³çŸ¥è¯†ï¼Œæ‰€ä»¥å¯¹VFæŒ‰ç…§ç¨‹åºæ‰§è¡Œé¡ºåºè¿›è¡Œäº†ååˆ†è¯¦ç»†çš„æ³¨é‡Šï¼ŒåŒæ—¶ä¸ºäº†å’Œå¤§å®¶è¿›è¡Œäº¤æµå­¦ä¹ ï¼Œæ‰€ä»¥æŠŠç›¸å…³æ³¨é‡Šä»£ç è¿›è¡Œå¼€æºã€‚å› æ°´å¹³æœ‰é™ï¼Œé”™è¯¯è‚¯å®šä¸å°‘ï¼Œè¿˜è¯·å„ä½å¤§ä½¬ä»¬æŒ‡æ­£ã€‚

*   [gtrll/gpslam](https://github.com/gtrll/gpslam) - Sparse Gaussian Processes for SLAM

*   [UZ-SLAMLab/ORB\_SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3) - ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM

*   [i3tyc/AdaptSLAM](https://github.com/i3tyc/AdaptSLAM) - AdaptSLAM: Edge-Assisted Adaptive SLAM with Resource Constraints via Uncertainty Minimization

*   [Zhefan-Xu/onboard\_detector](https://github.com/Zhefan-Xu/onboard_detector) - \[IEEE RA-L'24] Dynamic Obstacle Detection and Tracking (DODT) algorithm for Autonomous Robots (C++/ROS)

*   [nkliuhui/sync\_gps\_lidar\_imu\_cam](https://github.com/nkliuhui/sync_gps_lidar_imu_cam) - lidar-imu-cam-GPSæ—¶é—´æˆ³ç¡¬ä»¶åŒæ­¥æ–¹æ¡ˆ

*   [tum-vision/lsd\_slam](https://github.com/tum-vision/lsd_slam) - LSD-SLAM

*   [yutongwangBIT/GOReloc](https://github.com/yutongwangBIT/GOReloc) -

*   [HeYijia/VINS-Course](https://github.com/HeYijia/VINS-Course) - VINS-Mono code without Ceres or ROS

*   [SainingZhang/UC-GS](https://github.com/SainingZhang/UC-GS) - \[BMVC 2024] Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty

*   [AndreasArendt/OpenRTK](https://github.com/AndreasArendt/OpenRTK) - Open Source precise GNSS Software

*   [PetWorm/LARVIO](https://github.com/PetWorm/LARVIO) - A lightweight, accurate and robust monocular visual inertial odometry based on Multi-State Constraint Kalman Filter.

*   [ManiiXu/VINS-Mono-Learning](https://github.com/ManiiXu/VINS-Mono-Learning) - VINS-Monoä»£ç æ³¨é‡Šï¼Œä»…ä¾›å­¦ä¹ 

*   [sair-lab/AirSLAM](https://github.com/sair-lab/AirSLAM) - ğŸš€ AirVO upgrades to AirSLAM ğŸš€

*   [city-super/Octree-GS](https://github.com/city-super/Octree-GS) - Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians

*   [CG050523/PPP-Navigation](https://github.com/CG050523/PPP-Navigation) - ä¼ªè·å•ç‚¹å®šä½ç¨‹åºå®ç°ï¼Œä»…å­¦ä¹ ä½¿ç”¨

*   [Alex-Beh/yolov5\_ros](https://github.com/Alex-Beh/yolov5_ros) -

*   [VIS4ROB-lab/ccm\_slam](https://github.com/VIS4ROB-lab/ccm_slam) - CCM-SLAM: Robust and Efficient Centralized Collaborative Monocular SLAM for Robotic Teams

*   [microsoft/Azure-Kinect-Sensor-SDK](https://github.com/microsoft/Azure-Kinect-Sensor-SDK) - A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device.

*   [yanyan-li/PlanarSLAM](https://github.com/yanyan-li/PlanarSLAM) - A RGB-D SLAM system for structural scenes, which makes use of point-line-plane features and the Manhattan World assumption.

*   [STAR-Center/VINS-RGBD](https://github.com/STAR-Center/VINS-RGBD) -

*   [TixiaoShan/LIO-SAM](https://github.com/TixiaoShan/LIO-SAM) - LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping

*   [TixiaoShan/LVI-SAM](https://github.com/TixiaoShan/LVI-SAM) - LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping

*   [danping/CoSLAM](https://github.com/danping/CoSLAM) - CoSLAM is a visual SLAM software that aims to use multiple freely moving cameras to simultaneously compute their egomotion and the 3D map of the surrounding scenes in a highly dynamic environment.

*   [luohongk/SuperVINS](https://github.com/luohongk/SuperVINS) - A robust real-time visual-inertial SLAM framework for challenging imaging conditions (integrated deep learning features)

*   [google/or-tools](https://github.com/google/or-tools) - Google's Operations Research tools:

*   [JakobEngel/dso](https://github.com/JakobEngel/dso) - Direct Sparse Odometry

*   [AnswerDotAI/gpu.cpp](https://github.com/AnswerDotAI/gpu.cpp) - A lightweight library for portable low-level GPU computation using WebGPU.

*   [ethz-asl/wavemap](https://github.com/ethz-asl/wavemap) - Fast, efficient and accurate multi-resolution, multi-sensor 3D occupancy mapping

*   [RonaldSun/VI-Stereo-DSO](https://github.com/RonaldSun/VI-Stereo-DSO) - Direct sparse odometry combined with stereo cameras and IMU

*   [GREAT-WHU/iKalibr](https://github.com/GREAT-WHU/iKalibr) -

*   [MIT-SPARK/Kimera-RPGO](https://github.com/MIT-SPARK/Kimera-RPGO) - Robust Pose Graph Optimization

*   [lian-yue0515/MM-LINS](https://github.com/lian-yue0515/MM-LINS) - a Multi-Map LiDAR-Inertial System for Over-Degraded Environments

*   [engcang/vins-application](https://github.com/engcang/vins-application) - VINS-Fusion, VINS-Fisheye, OpenVINS, EnVIO, ROVIO, S-MSCKF, ORB-SLAM2, NVIDIA Elbrus application of different sets of cameras and imu on different board including desktop and Jetson boards

*   [floatlazer/semantic\_slam](https://github.com/floatlazer/semantic_slam) - Real time semantic slam in ROS with a hand held RGB-D camera

*   [koide3/gtsam\_points](https://github.com/koide3/gtsam_points) - A collection of GTSAM factors and optimizers for point cloud SLAM

*   [BaowenZ/RaDe-GS](https://github.com/BaowenZ/RaDe-GS) - RaDe-GS: Rasterizing Depth in Gaussian Splatting

*   [Unsigned-Long/iKalibr](https://github.com/Unsigned-Long/iKalibr) - iKalibr: Unified Targetless Spatiotemporal Calibration for Resilient Integrated Inertial Systems

*   [emiliofidalgo/ibow-lcd](https://github.com/emiliofidalgo/ibow-lcd) - Appearance-based Loop Closure Detection using Incremental Bags of Binary Words

*   [bxh1/VIDO-SLAM](https://github.com/bxh1/VIDO-SLAM) - VIDO-SLAM is a  Visual Inertial SLAM system for dynamic environments, and it can  also estimate dynamic objects motion and track objects.

*   [url-kaist/dynaVINS](https://github.com/url-kaist/dynaVINS) - DynaVINS : A Visual-Inertial SLAM for Dynamic Environments

*   [MAVIS-SLAM/OpenMAVIS](https://github.com/MAVIS-SLAM/OpenMAVIS) - An open-source implementation of MAVIS-SLAM.

*   [linyicheng1/OpenSLAM-Notes](https://github.com/linyicheng1/OpenSLAM-Notes) - ä¸ªäººå¯¹ç›®å‰è¾ƒä¸ºæˆç†Ÿçš„è§†è§‰/æ¿€å…‰SLAMç®—æ³•è¿›è¡Œçš„æ³¨é‡Šä»¥åŠè§£è¯»æ–‡ä»¶

*   [guisoares9/VINS-Fusion](https://github.com/guisoares9/VINS-Fusion) - OpenCV 4, ROS Noetic, and Ceres adaptation of VINS-Fusion. An optimization-based multi-sensor state estimator

*   [cyp4x141/VINS-Fusion-noetic-Opencv4](https://github.com/cyp4x141/VINS-Fusion-noetic-Opencv4) - VINS-Fusion for opencv4 + noetic +ubuntu20.04

*   [shanpenghui/ORB\_SLAM3\_Fixed](https://github.com/shanpenghui/ORB_SLAM3_Fixed) - Optimized ORBSLAM3 to run on TUM/EuRoc/KITTI dataset

*   [karanchawla/GPS\_IMU\_Kalman\_Filter](https://github.com/karanchawla/GPS_IMU_Kalman_Filter) - Fusing GPS, IMU and Encoder sensors for accurate state estimation.

*   [yuefanhao/SuperPoint-SuperGlue-TensorRT](https://github.com/yuefanhao/SuperPoint-SuperGlue-TensorRT) - SuperPoint and SuperGlue with TensorRT. Deploy with C++.

*   [kajo-kurisu/D\_VINS](https://github.com/kajo-kurisu/D_VINS) - Merge superpointã€lightglueã€MixVPR into VINS-FUSION for loop closure with TensorRT

*   [HeYijia/PL-VIO](https://github.com/HeYijia/PL-VIO) - monocular visual inertial system with point and line features

*   [openxrlab/xrslam](https://github.com/openxrlab/xrslam) - OpenXRLab Visual-inertial SLAM Toolbox and Benchmark

*   [KumarRobotics/msckf\_vio](https://github.com/KumarRobotics/msckf_vio) - Robust Stereo Visual Inertial Odometry for Fast Autonomous Flight

*   [i2Nav-WHU/IC-GVINS](https://github.com/i2Nav-WHU/IC-GVINS) - A Robust, Real-time, INS-Centric GNSS-Visual-Inertial Navigation System

*   [ydsf16/imu\_gps\_localization](https://github.com/ydsf16/imu_gps_localization) - Using error-state Kalman filter to fuse the IMU and GPS data for localization.

*   [cnqiangfu/PL-VINS](https://github.com/cnqiangfu/PL-VINS) - PL-VINS: Real-Time Monocular Visual-Inertial SLAM with Point and Line Features

## TypeScript

*   [amir9480/vscode-cpp-helper](https://github.com/amir9480/vscode-cpp-helper) - vscode extension to create implementation for c++ function prototypes.

*   [hcengineering/platform](https://github.com/hcengineering/platform) - Huly â€” All-in-One Project Management Platform (alternative to Linear, Jira, Slack, Notion, Motion)

*   [conwnet/github1s](https://github.com/conwnet/github1s) - One second to read GitHub code with VS Code.

*   [ocsjs/ocsjs](https://github.com/ocsjs/ocsjs) - OCS ç½‘è¯¾åŠ©æ‰‹ï¼Œåˆ·è¯¾è„šæœ¬ï¼Œç½‘è¯¾è„šæœ¬ï¼Œå¸®åŠ©å¤§å­¦ç”Ÿè§£å†³ç½‘è¯¾éš¾é¢˜ï¼Œæ”¯æŒã€è¶…æ˜Ÿå­¦ä¹ é€šã€‘ã€çŸ¥é“æ™ºæ…§æ ‘ã€‘ã€èŒæ•™äº‘ã€‘ã€æ™ºæ…§èŒæ•™ã€‘ã€ä¸­å›½å¤§å­¦MOOCã€‘ç­‰ç½‘è¯¾  ï¼Œ å¯ä»¥åœ¨ è„šæœ¬çŒ« ä»¥åŠ æ²¹çŒ´ ç­‰å¼€æºè„šæœ¬ç®¡ç†å™¨ä¸‹è¿è¡Œã€‚

*   [immich-app/immich](https://github.com/immich-app/immich) - High performance self-hosted photo and video management solution.

## Python

*   [zhaihongjia/SplatLoc](https://github.com/zhaihongjia/SplatLoc) - SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality

*   [NanmiCoder/MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) - å°çº¢ä¹¦ç¬”è®° | è¯„è®ºçˆ¬è™«ã€æŠ–éŸ³è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€å¿«æ‰‹è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€B ç«™è§†é¢‘ ï½œ è¯„è®ºçˆ¬è™«ã€å¾®åšå¸–å­ ï½œ è¯„è®ºçˆ¬è™«ã€ç™¾åº¦è´´å§å¸–å­ ï½œ ç™¾åº¦è´´å§è¯„è®ºå›å¤çˆ¬è™«  | çŸ¥ä¹é—®ç­”æ–‡ç« ï½œè¯„è®ºçˆ¬è™«

*   [hkchengrex/Cutie](https://github.com/hkchengrex/Cutie) - \[CVPR 2024 Highlight] Putting the Object Back Into Video Object Segmentation

*   [facebookresearch/lingua](https://github.com/facebookresearch/lingua) - Meta Lingua: a lean, efficient, and easy-to-hack codebase to research LLMs.

*   [google/nerfies](https://github.com/google/nerfies) - This is the code for Deformable Neural Radiance Fields, a.k.a. Nerfies.

*   [Owen718/LongPrompt-LLamaGen](https://github.com/Owen718/LongPrompt-LLamaGen) - This repository provides an improved LLamaGen Model, fine-tuned on 500,000 high-quality images, each accompanied by over 300 token prompts. And it's also powered by additional prompt refining features for improved performance.

*   [openai/improved-diffusion](https://github.com/openai/improved-diffusion) - Release for Improved Denoising Diffusion Probabilistic Models

*   [hzy46/Deep-Learning-21-Examples](https://github.com/hzy46/Deep-Learning-21-Examples) - ã€Š21ä¸ªé¡¹ç›®ç©è½¬æ·±åº¦å­¦ä¹ â€”â€”â€”åŸºäºTensorFlowçš„å®è·µè¯¦è§£ã€‹é…å¥—ä»£ç 

*   [StanfordVL/3DSceneGraph](https://github.com/StanfordVL/3DSceneGraph) - The data skeleton from "3D Scene Graph: A Structure for Unified Semantics, 3D Space, and Camera" http://3dscenegraph.stanford.edu

*   [cvg/depthsplat](https://github.com/cvg/depthsplat) - DepthSplat: Connecting Gaussian Splatting and Depth

*   [HKUDS/LightRAG](https://github.com/HKUDS/LightRAG) - "LightRAG: Simple and Fast Retrieval-Augmented Generation"

*   [princeton-vl/DROID-SLAM](https://github.com/princeton-vl/DROID-SLAM) -

*   [jiaoZ7688/YOLOPX](https://github.com/jiaoZ7688/YOLOPX) -

*   [Nightmare-n/DepthAnyVideo](https://github.com/Nightmare-n/DepthAnyVideo) - Depth Any Video with Scalable Synthetic Data

*   [linyicheng1/EdgePoint](https://github.com/linyicheng1/EdgePoint) - EdgePoint: Learning Efficient Keypoint Extraction and Description for Edge Devices

*   [uzh-rpg/bflow](https://github.com/uzh-rpg/bflow) - Official implementation of "Dense Continuous-Time Optical Flow from Event Cameras"

*   [VITA-Group/LightGaussian](https://github.com/VITA-Group/LightGaussian) - \[NeurIPS 2024 Spotlight]"LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS", Zhiwen Fan, Kevin Wang, Kairun Wen, Zehao Zhu, Dejia Xu, Zhangyang Wang

*   [uzh-rpg/deep\_ev\_tracker](https://github.com/uzh-rpg/deep_ev_tracker) - Repository relating to "Data-driven Feature Tracking for Event Cameras" (CVPR, 2023, Award Candidate).

*   [1837669410/moco-pytorch](https://github.com/1837669410/moco-pytorch) - mocoçš„å­¦ä¹ ä¾‹å­ï¼Œåˆ©ç”¨mnistæ•°æ®é›†å®ç°

*   [IRMVLab/DVLO](https://github.com/IRMVLab/DVLO) - \[ECCV 2024 Oral] DVLO: Deep Visual-LiDAR Odometry with Local-to-Global Feature Fusion and Bi-Directional Structure Alignment

*   [hustvl/osp](https://github.com/hustvl/osp) - \[ECCV 2024] Occupancy as Set of Points

*   [HuangJunJie2017/BEVDet](https://github.com/HuangJunJie2017/BEVDet) - Official code base of the BEVDet series .

*   [city-super/Octree-AnyGS](https://github.com/city-super/Octree-AnyGS) - Octree-GS

*   [buaacyw/MeshAnythingV2](https://github.com/buaacyw/MeshAnythingV2) - From anything to mesh like human artists. Official impl. of "MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization"

*   [roboflow/supervision](https://github.com/roboflow/supervision) - We write your reusable computer vision tools. ğŸ’œ

*   [yifanlu0227/ChatSim](https://github.com/yifanlu0227/ChatSim) - \[CVPR2024 Highlight] Editable Scene Simulation for Autonomous Driving via LLM-Agent Collaboration

*   [cjy1992/interp-e2e-driving](https://github.com/cjy1992/interp-e2e-driving) - Interpretable End-to-end Urban Autonomous Driving with Latent Deep Reinforcement Learning

*   [chenzomi12/AIFoundation](https://github.com/chenzomi12/AIFoundation) - AIFoundation ä¸»è¦æ˜¯æŒ‡AIç³»ç»Ÿé‡åˆ°å¤§æ¨¡å‹ï¼Œä»åº•å±‚åˆ°ä¸Šå±‚å¦‚ä½•ç³»ç»Ÿçº§åœ°æ”¯æŒå¤§æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ï¼Œå…¨æ ˆçš„æ ¸å¿ƒæŠ€æœ¯ã€‚

*   [Robertwyq/PanoOcc](https://github.com/Robertwyq/PanoOcc) - \[CVPR 2024] PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation

*   [TheAlgorithms/Python](https://github.com/TheAlgorithms/Python) - All Algorithms implemented in Python

*   [morrisfl/UniFEx](https://github.com/morrisfl/UniFEx) - Framework for computationally efficient training of universal image feature extraction models.

*   [qintonguav/ParkingE2E](https://github.com/qintonguav/ParkingE2E) -

*   [pytorch/pytorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration

*   [AnyLoc/Revisit-Anything](https://github.com/AnyLoc/Revisit-Anything) - Code release for Revisit Anything: Visual Place Recognition via Image Segment Retrieval (ECCV 2024)

*   [eth-ait/GaussianHaircut](https://github.com/eth-ait/GaussianHaircut) - Gaussian Haircut: Human Hair Reconstruction with Strand-Aligned 3D Gaussians

*   [pyg-team/pytorch-frame](https://github.com/pyg-team/pytorch-frame) - Tabular Deep Learning Library for PyTorch

*   [jkulhanek/wild-gaussians](https://github.com/jkulhanek/wild-gaussians) - \[NeurIPS'24] WildGaussians: 3D Gaussian Splatting In the Wild

*   [cas-lab-munich/SigmaRL](https://github.com/cas-lab-munich/SigmaRL) - SigmaRL: A Sample-Efficient and Generalizable Multi-Agent Reinforcement Learning Framework for Motion Planning

*   [DLR-MI/UTrack](https://github.com/DLR-MI/UTrack) - Multi-Object Tracking with Uncertain Detections \[ECCV 2024 UnCV]

*   [stanfordnlp/dspy](https://github.com/stanfordnlp/dspy) - DSPy: The framework for programmingâ€”not promptingâ€”foundation models

*   [TempleRAIL/drl\_vo\_nav](https://github.com/TempleRAIL/drl_vo_nav) - \[T-RO 2023] DRL-VO: Learning to Navigate Through Crowded Dynamic Scenes Using Velocity Obstacles

*   [lucasbrynte/gasfm](https://github.com/lucasbrynte/gasfm) - Implementation of the CVPR 2024 paper "Learning Structure-from-Motion with Graph Attention Networks".

*   [SPengLiang/OccupancyM3D](https://github.com/SPengLiang/OccupancyM3D) - \[CVPR 2024] Learning Occupancy for Monocular 3D Object Detection

*   [zhangganlin/GlORIE-SLAM](https://github.com/zhangganlin/GlORIE-SLAM) - GlORIE-SLAM: Globally Optimized RGB-only Implicit Encoding Point Cloud SLAM

*   [jbriales/rgbd\_benchmark\_tools](https://github.com/jbriales/rgbd_benchmark_tools) - Tools for TUM RGBD Dataset Benchmark

*   [yastrebksv/TennisProject](https://github.com/yastrebksv/TennisProject) - Tennis analysis using deep learning and machineÂ learning

*   [cvg/GeoCalib](https://github.com/cvg/GeoCalib) - GeoCalib: Learning Single-image Calibration with Geometric Optimization (ECCV 2024)

*   [NVIDIA/TransformerEngine](https://github.com/NVIDIA/TransformerEngine) - A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.

*   [lus6-Jenny/RING](https://github.com/lus6-Jenny/RING) - \[IEEE T-RO 2023] Source code of RING and RING++ for loop closure detection in LiDAR SLAM.

*   [hacksider/Deep-Live-Cam](https://github.com/hacksider/Deep-Live-Cam) - real time face swap and one-click video deepfake with only a single image

*   [GANWANSHUI/GaussianOcc](https://github.com/GANWANSHUI/GaussianOcc) - GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation with Gaussian Splatting

*   [GradientSpaces/LoopSplat](https://github.com/GradientSpaces/LoopSplat) - LoopSplat: Loop Closure by Registering 3D Gaussian Splats

*   [zhaofuq/LOD-3DGS](https://github.com/zhaofuq/LOD-3DGS) - LetsGo: Large-Scale Garage Modeling and Rendering via LiDAR-Assisted Gaussian(Published in SIGGRAPH Asia 2024)

*   [hjr37/CP-SLAM](https://github.com/hjr37/CP-SLAM) - CP-SLAM: Collaborative Neural Point-based SLAM

*   [cvg/nicer-slam](https://github.com/cvg/nicer-slam) - \[3DV'24 Best Paper Honorable Mention] NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM

*   [lpiccinelli-eth/UniDepth](https://github.com/lpiccinelli-eth/UniDepth) - Universal Monocular Metric Depth Estimation

*   [JeongminB/E-D3DGS](https://github.com/JeongminB/E-D3DGS) - \[ECCV 2024] Official repository for "Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian Splatting"

*   [spla-tam/SplaTAM](https://github.com/spla-tam/SplaTAM) - SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM (CVPR 2024)

*   [sparolab/solid](https://github.com/sparolab/solid) - (RA-L 2024) This repository is the official code for Narrowing your FOV with SOLiD: Spatially Organized and Lightweight Global Descriptor for FOV-constrained LiDAR Place Recognition.

*   [IPNL-POLYU/UrbanNavDataset](https://github.com/IPNL-POLYU/UrbanNavDataset) - UrbanNav:An Open-sourced Multisensory Dataset for Benchmarking Positioning Algorithms Designed for Urban Areas

*   [YuxueYang1204/TrimGS](https://github.com/YuxueYang1204/TrimGS) - Trim 3D Gaussian Splatting for Accurate Geometry Representation

*   [open-mmlab/mmtracking](https://github.com/open-mmlab/mmtracking) - OpenMMLab Video Perception Toolbox. It supports Video Object Detection (VID), Multiple Object Tracking (MOT), Single Object Tracking (SOT), Video Instance Segmentation (VIS) with a unified framework.

*   [huggingface/transformers](https://github.com/huggingface/transformers) - ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.

*   [openai/openai-python](https://github.com/openai/openai-python) - The official Python library for the OpenAI API

*   [llmbev/talk2bev](https://github.com/llmbev/talk2bev) - Talk2BEV: Language-Enhanced Bird's Eye View Maps (Accepted to ICRA'24)

*   [liuyuan-pal/SyncDreamer](https://github.com/liuyuan-pal/SyncDreamer) - \[ICLR 2024 Spotlight] SyncDreamer: Generating Multiview-consistent Images from a Single-view Image

*   [fudan-zvg/4d-gaussian-splatting](https://github.com/fudan-zvg/4d-gaussian-splatting) - \[ICLR 2024] Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting

*   [eriksandstroem/Loopy-SLAM](https://github.com/eriksandstroem/Loopy-SLAM) -

*   [qinzheng93/GeoTransformer](https://github.com/qinzheng93/GeoTransformer) - \[CVPR2022] Geometric Transformer for Fast and Robust Point Cloud Registration

*   [yanyan-li/GeoGaussian](https://github.com/yanyan-li/GeoGaussian) - GeoGaussian: Geometry-aware Gaussian Splatting for Scene Rendering

*   [Parskatt/DeDoDe](https://github.com/Parskatt/DeDoDe) - \[3DV 2024 Oral] DeDoDe ğŸ¶ Detect, Don't Describe --- Describe, Don't Detect, for Local Feature Matching

*   [ericzzj1989/BALF](https://github.com/ericzzj1989/BALF) - \[WACV 2024] BALF: Simple and Efficient Blur Aware Local Feature Detector

*   [lyakaap/NetVLAD-pytorch](https://github.com/lyakaap/NetVLAD-pytorch) - PyTorch implementation of NetVLAD & Online Hardest Triplet Loss.

*   [meta-llama/llama-stack-apps](https://github.com/meta-llama/llama-stack-apps) - Agentic components of the Llama Stack APIs

*   [xiaobiaodu/DreamCar](https://github.com/xiaobiaodu/DreamCar) - DreamCar: Leveraging Car-specific Prior for in-the-wild 3D Car Reconstruction

*   [nianticlabs/acezero](https://github.com/nianticlabs/acezero) - \[ECCV 2024 - Oral] ACE0 is a learning-based structure-from-motion approach that estimates camera parameters of sets of images by learning a multi-view consistent, implicit scene representation.

*   [meta-llama/llama-models](https://github.com/meta-llama/llama-models) - Utilities intended for use with Llama models.

*   [cs230-stanford/cs230-code-examples](https://github.com/cs230-stanford/cs230-code-examples) - Code examples in pyTorch and Tensorflow for CS230

*   [ddbourgin/numpy-ml](https://github.com/ddbourgin/numpy-ml) - Machine learning, in numpy

*   [lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch) - Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch

*   [tarashakhurana/4d-occ-forecasting](https://github.com/tarashakhurana/4d-occ-forecasting) - CVPR 2023: Official code for \`Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting'

*   [uoip/stereo\_msckf](https://github.com/uoip/stereo_msckf) - Python implementation of Multi-State Constraint Kalman Filter (MSCKF) for Vision-aided Inertial Navigation.

*   [fundamentalvision/BEVFormer](https://github.com/fundamentalvision/BEVFormer) - \[ECCV 2022] This is the official implementation of BEVFormer, a camera-only framework for autonomous driving perception, e.g., 3D object detection and semantic map segmentation.

*   [NVlabs/FB-BEV](https://github.com/NVlabs/FB-BEV) - Official PyTorch implementation of FB-BEV & FB-OCC - Forward-backward view transformation for vision-centric autonomous driving perception

*   [OpenDriveLab/OccNet](https://github.com/OpenDriveLab/OccNet) - \[ICCV 2023] OccNet: Scene as Occupancy

*   [Tsinghua-MARS-Lab/Occ3D](https://github.com/Tsinghua-MARS-Lab/Occ3D) -

*   [ViewFormerOcc/ViewFormer-Occ](https://github.com/ViewFormerOcc/ViewFormer-Occ) - \[ECCV 2024] ViewFormer: Exploring Spatiotemporal Modeling for Multi-View 3D Occupancy Perception via View-Guided Transformers

*   [MCG-NJU/SparseOcc](https://github.com/MCG-NJU/SparseOcc) - \[ECCV 2024] Fully Sparse 3D Occupancy Prediction & RayIoU Evaluation Metric

*   [VISION-SJTU/SparseOcc](https://github.com/VISION-SJTU/SparseOcc) - Official implementation for 'SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction' (CVPR 2024)

*   [weiyithu/SurroundOcc](https://github.com/weiyithu/SurroundOcc) - \[ICCV 2023] SurroundOcc: Multi-camera 3D Occupancy Prediction for Autonomous Driving

*   [autonomousvision/occupancy\_networks](https://github.com/autonomousvision/occupancy_networks) - This repository contains the code for the paper "Occupancy Networks - Learning 3D Reconstruction in Function Space"

*   [SY-007-Research/3dgs\_render\_python](https://github.com/SY-007-Research/3dgs_render_python) -

*   [Ferry-Li/SI-SOD](https://github.com/Ferry-Li/SI-SOD) - ICML2024: Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection

*   [Ferry-Li/SI\_Metric](https://github.com/Ferry-Li/SI_Metric) - A portable computation of Size-Invariant Metrics for ICML2024: Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection

*   [autonomousvision/mip-splatting](https://github.com/autonomousvision/mip-splatting) - \[CVPR'24 Best Student Paper] Mip-Splatting: Alias-free 3D Gaussian Splatting

*   [Vincentqyw/image-matching-webui](https://github.com/Vincentqyw/image-matching-webui) - ğŸ¤— image matching toolbox webui

*   [LiheYoung/Depth-Anything](https://github.com/LiheYoung/Depth-Anything) - \[CVPR 2024] Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data. Foundation Model for Monocular Depth Estimation

*   [microsoft/graphrag](https://github.com/microsoft/graphrag) - A modular graph-based Retrieval-Augmented Generation (RAG) system

*   [rvp-group/vbr-devkit](https://github.com/rvp-group/vbr-devkit) - Vision Benchmark in Rome Development Kit

*   [utiasSTARS/pykitti](https://github.com/utiasSTARS/pykitti) - Python tools for working with KITTI data.

*   [huang-yh/GaussianFormer](https://github.com/huang-yh/GaussianFormer) - \[ECCV 2024] Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction

*   [TQTQliu/MVSGaussian](https://github.com/TQTQliu/MVSGaussian) - \[ECCV 2024] MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo

*   [buaacyw/MeshAnything](https://github.com/buaacyw/MeshAnything) - From anything to mesh like human artists. Official impl. of "MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers"

*   [swc-17/SparseDrive](https://github.com/swc-17/SparseDrive) - SparseDrive: End-to-End Autonomous Driving via Sparse Scene Representation

*   [minghanqin/LangSplat](https://github.com/minghanqin/LangSplat) - Official implementation of the paper "LangSplat: 3D Language Gaussian Splatting" \[CVPR2024 Highlight]

*   [Xinyu-Yi/TransPose](https://github.com/Xinyu-Yi/TransPose) - A real-time motion capture system that estimates poses and global translations using only 6 inertial measurement units

*   [Awesome3DGS/3D-Gaussian-Splatting-Papers](https://github.com/Awesome3DGS/3D-Gaussian-Splatting-Papers) - 3Dé«˜æ–¯è®ºæ–‡ï¼ŒæŒç»­æ›´æ–°ï¼Œæ¬¢è¿äº¤æµè®¨è®ºã€‚

*   [JonathonLuiten/Dynamic3DGaussians](https://github.com/JonathonLuiten/Dynamic3DGaussians) -

*   [cvg/glue-factory](https://github.com/cvg/glue-factory) - Training library for local feature detection and matching

*   [cvg/LightGlue](https://github.com/cvg/LightGlue) - LightGlue: Local Feature Matching at Light Speed (ICCV 2023)

*   [muskie82/MonoGS](https://github.com/muskie82/MonoGS) - \[CVPR'24 Highlight & Best Demo Award] Gaussian Splatting SLAM

## Lua

*   [gaboolic/rime-shuangpin-fuzhuma](https://github.com/gaboolic/rime-shuangpin-fuzhuma) - å¢¨å¥‡éŸ³å½¢ï¼Œæ‰“é€ æœ€å¼ºåŒæ‹¼è¾…åŠ©ç rimeè¾“å…¥æ–¹æ¡ˆï¼Œè®©å¤©ä¸‹åŒæ‹¼ç”¨æˆ·äººäººç”¨å¾—ä¸Šè¾…åŠ©ç ã€‚åŸºäºé›¾å‡‡-ç™½éœœè¯åº“ï¼Œæ”¯æŒå°é¹¤åŒæ‹¼ã€è‡ªç„¶ç åŒæ‹¼ã€æœç‹—åŒæ‹¼ã€å¾®è½¯åŒæ‹¼ç­‰å¤šç§åŒæ‹¼ï¼Œè¾…åŠ©ç æ”¯æŒå¢¨å¥‡ç ï¼ˆåŸåˆ›æ‹†åˆ†å¼€æºæ”¯æŒ4ä¸‡å­—ï¼‰ã€è‡ªç„¶ç éƒ¨é¦–è¾…ã€å°é¹¤éŸ³å½¢ï¼ˆé¹¤å½¢è¾…ï¼‰ç­‰ï¼Œæ”¯æŒåŒæ‹¼å’Œè¾…åŠ©ç ä¹‹é—´æ’åˆ—ç»„åˆï¼Œæ”¯æŒæ•´å¥/å­—è¯è¾“å…¥ã€‚ä¸è®¤è¯†çš„å­—å¯ä»¥ç¬”ç”»ã€éƒ¨ä»¶æ‹†å­—ã€ä»“é¢‰ç åæŸ¥ã€‚æ”¯æŒawã€ajæ¨¡å¼è¾“å…¥è‹±æ–‡ã€æ—¥æ–‡ï¼Œæ”¯æŒåŒæ‹¼å¹¶å‡»è¾“å…¥ã€emojiã€å¿«ç¬¦ã€æ—¥æœŸã€å¤§å†™æ•°å­—ã€è®¡ç®—å™¨ç­‰é«˜çº§åŠŸèƒ½ã€‚é›¾å‡‡é¹¤|é›¾å‡‡è‡ªç„¶|å¢¨å¥‡ç |å¢¨å¥‡éŸ³å½¢

## miscellaneous

*   [520xyxyzq/3DGS-CD](https://github.com/520xyxyzq/3DGS-CD) - 3DGS-based change detection for physical object rearrangement

*   [52CV/awesome-huggingface](https://github.com/52CV/awesome-huggingface) - ğŸ¤— A list of wonderful open-source projects & applications integrated with Hugging Face libraries.

*   [HCPLab-SYSU/Embodied\_AI\_Paper\_List](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List) - \[Embodied-AI-Survey-2024] Paper list and projects for Embodied AI

*   [hku-mars/LAMM](https://github.com/hku-mars/LAMM) -

*   [JusticeFighterDance/JusticeFighter110](https://github.com/JusticeFighterDance/JusticeFighter110) - ç”°æŸ¯å®‡ (Tian Keyu)æ¶æ„æ”»å‡»é›†ç¾¤äº‹ä»¶çš„è¯æ®æ­éœ²

*   [william-sto/JusticeNeverTooLate](https://github.com/william-sto/JusticeNeverTooLate) - å­—èŠ‚è·³åŠ¨ç“œæœ€ç»ˆçœŸå®æƒ…å†µï¼Œç”¨äº‹å®è¯´è¯ï¼Œæ­£ä¹‰ä¼šè¿Ÿåˆ°ä½†ä¸ä¼šç¼ºå¸­ï¼

*   [RuijieZhu94/MotionGS](https://github.com/RuijieZhu94/MotionGS) - \[NeurIPS 2024] MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting

*   [amusi/CVPR2024-Papers-with-Code](https://github.com/amusi/CVPR2024-Papers-with-Code) - CVPR 2024 è®ºæ–‡å’Œå¼€æºé¡¹ç›®åˆé›†

*   [zhuhu00/Awesome\_Dynamic\_SLAM](https://github.com/zhuhu00/Awesome_Dynamic_SLAM) - Dynamic SLAM, Life-long SLAM Research(Lidar, Visual, Sensor Fusion etc.)

*   [hongwenjun/tmux\_for\_windows](https://github.com/hongwenjun/tmux_for_windows) - tmuxæ˜¯ä¸€ä¸ªå¼€æºå·¥å…·ï¼Œç”¨äºåœ¨ä¸€ä¸ªç»ˆç«¯çª—å£ä¸­è¿è¡Œå¤šä¸ªç»ˆç«¯ä¼šè¯ã€‚æœ¬å·¥å…·ä»msys2é‡Œæå–ï¼Œå¯ä»¥åœ¨Git for Windowsçš„Git Bash (MingW64)ä¸‹æ­£å¸¸ä½¿ç”¨ã€‚

*   [HumanAIGC/AnimateAnyone](https://github.com/HumanAIGC/AnimateAnyone) - Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation

*   [minwoo0611/HeLiOS](https://github.com/minwoo0611/HeLiOS) - LiDAR Place Recognition

*   [Simulation-Group/ESGaussian](https://github.com/Simulation-Group/ESGaussian) - ES-Gaussian: Gaussian Splatting Mapping via Error Space-Based Gaussian Completion

*   [Ji1Xingyu/SGBA](https://github.com/Ji1Xingyu/SGBA) -

*   [Open3DVLab/StreetSurfGS](https://github.com/Open3DVLab/StreetSurfGS) - StreetSurfGS: Scalable Large Scene Surface Reconstruction with Gaussian Splatting for Urban Street Scences

*   [QiZS-BIT/GSPR](https://github.com/QiZS-BIT/GSPR) - GSPR: Multimodal Place Recognition using 3D Gaussian Splatting for Autonomous Driving

*   [TianxingChen/Embodied-AI-Guide](https://github.com/TianxingChen/Embodied-AI-Guide) - å…·èº«æ™ºèƒ½å…¥é—¨æŒ‡å—

*   [Open3DVLab/GigaGS](https://github.com/Open3DVLab/GigaGS) - GigaGS: Scaling up Planar-Based 3D Gaussians for Large Scene Surface Reconstruction

*   [Thinklab-SJTU/Awesome-LLM4AD](https://github.com/Thinklab-SJTU/Awesome-LLM4AD) - A curated list of awesome LLM for Autonomous Driving resources (continually updated)

*   [PeidongLi/SSR](https://github.com/PeidongLi/SSR) -

*   [ai-vip/stable-diffusion-tutorial](https://github.com/ai-vip/stable-diffusion-tutorial) - å…¨ç½‘æœ€å…¨Stable Diffusionå…¨å¥—æ•™ç¨‹ï¼Œä»å…¥é—¨åˆ°è¿›é˜¶ï¼Œè€—æ—¶ä¸‰ä¸ªæœˆåˆ¶ä½œ

*   [AlbertSlam/Lee-SLAM-source](https://github.com/AlbertSlam/Lee-SLAM-source) - SLAM å¼€å‘å­¦ä¹ èµ„æºä¸ç»éªŒåˆ†äº«

*   [YangSiri/OR-LIM](https://github.com/YangSiri/OR-LIM) - OR-LIM: Observability-aware robust LiDAR-Inertial-Mapping  under High Dynamic Sensor Motion

*   [jimazeyu/GraspSplats](https://github.com/jimazeyu/GraspSplats) - GraspSplats: Efficient Manipulation with 3D Feature Splatting

*   [DeepLabc/LargeScale\_3DGS](https://github.com/DeepLabc/LargeScale_3DGS) - 3D Gaussian Splatting Papers Relating to Large-Scale Scene.

*   [sjtuyinjie/awesome-LiDAR-Visual-SLAM](https://github.com/sjtuyinjie/awesome-LiDAR-Visual-SLAM) - A curated list of resources relevant to LiDAR-Visual-Fusion-SLAM

*   [perklet/reverse-interview-zh](https://github.com/perklet/reverse-interview-zh) - æŠ€æœ¯é¢è¯•æœ€ååé—®é¢è¯•å®˜çš„è¯

*   [kwea123/gaussian\_splatting\_notes](https://github.com/kwea123/gaussian_splatting_notes) - A detailed formulae explanation on gaussian splatting

*   [zju3dv/100-Phones](https://github.com/zju3dv/100-Phones) -

*   [623637646/996.Leave](https://github.com/623637646/996.Leave) - é€ƒç¦»996

*   [Meltwin/Noetic-Ubuntu22.04](https://github.com/Meltwin/Noetic-Ubuntu22.04) - Manual instructions on how to install ROS1 Noetic on Ubuntu 22.04

*   [hku-mars/FAST-LIVO2](https://github.com/hku-mars/FAST-LIVO2) - FAST-LIVO2: Fast, Direct LiDAR-Inertial-Visual Odometry

*   [StevenCui/VIO-Doc](https://github.com/StevenCui/VIO-Doc) - ä¸»æµVIOè®ºæ–‡æ¨å¯¼åŠä»£ç è§£æ

*   [ericzzj1989/Awesome-Image-Matching](https://github.com/ericzzj1989/Awesome-Image-Matching) -

*   [miss-mumu/developer2gwy](https://github.com/miss-mumu/developer2gwy) - å…¬åŠ¡å‘˜ä»å…¥é—¨åˆ°ä¸Šå²¸ï¼Œæœ€ä½³ç¨‹åºå‘˜å…¬è€ƒå®è·µæ•™ç¨‹

*   [0voice/expert\_readed\_books](https://github.com/0voice/expert_readed_books) - 2021å¹´æœ€æ–°æ€»ç»“ï¼Œæ¨èå·¥ç¨‹å¸ˆåˆé€‚è¯»æœ¬ï¼Œè®¡ç®—æœºç§‘å­¦ï¼Œè½¯ä»¶æŠ€æœ¯ï¼Œåˆ›ä¸šï¼Œæ€æƒ³ç±»ï¼Œæ•°å­¦ç±»ï¼Œäººç‰©ä¼ è®°ä¹¦ç±

*   [jianzongwu/Awesome-Open-Vocabulary](https://github.com/jianzongwu/Awesome-Open-Vocabulary) - (TPAMI 2024) A Survey on Open Vocabulary Learning

*   [lvchuandong/Awesome-Multi-Camera-3D-Occupancy-Prediction](https://github.com/lvchuandong/Awesome-Multi-Camera-3D-Occupancy-Prediction) - Awesome papers and code about Multi-Camera 3D Occupancy Prediction, such as TPVFormer, SurroundOcc, PanoOcc, OccFormer, FB-OCC, SelfOcc, COTR, SparseOcc. In this repository, you will see the latest 3D occupancy prediction papers and code.

*   [eriksandstroem/Splat-SLAM](https://github.com/eriksandstroem/Splat-SLAM) -

*   [bdvisl/DriveInsight](https://github.com/bdvisl/DriveInsight) -

*   [pubsys/ReviewSystem](https://github.com/pubsys/ReviewSystem) - å®¡ç¨¿ç³»ç»Ÿçš„è‡ªè¿°

*   [weisongwen/UrbanNavDataset](https://github.com/weisongwen/UrbanNavDataset) - UrbanNav: anÂ Open-Sourcing Localization Data Collected in Asian Urban Canyons, Including Tokyo and Hong Kong

*   [datawhalechina/pumpkin-book](https://github.com/datawhalechina/pumpkin-book) - ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼ˆè¥¿ç“œä¹¦ï¼‰å…¬å¼è¯¦è§£

*   [pengsida/learning\_research](https://github.com/pengsida/learning_research) - æœ¬äººçš„ç§‘ç ”ç»éªŒ

## JavaScript

*   [eliahuhorwitz/Academic-project-page-template](https://github.com/eliahuhorwitz/Academic-project-page-template) - A project page template for academic papers. Demo at https://eliahuhorwitz.github.io/Academic-project-page-template/

*   [lutzroeder/netron](https://github.com/lutzroeder/netron) - Visualizer for neural network, deep learning and machine learning models

## CSS

*   [zzwu29/Arxiv](https://github.com/zzwu29/Arxiv) -

*   [Maserhe/VScode-Markdown-theme-Maserhe](https://github.com/Maserhe/VScode-Markdown-theme-Maserhe) - vscode è‡ªå®šä¹‰Markdownæ’ç‰ˆé£æ ¼ï¼Œä»¥åŠä»£ç å—æ ·å¼é£æ ¼ã€‚

*   [wzzheng/GaussianFormer](https://github.com/wzzheng/GaussianFormer) - Project Page for GaussianFormer

## Jupyter Notebook

*   [cumtcssuld/RSP\_of\_CUMTCS](https://github.com/cumtcssuld/RSP_of_CUMTCS) - ã€çŸ¿å¤§è®¡ç®—æœºå­¦é™¢èµ„æºå…±äº«è®¡åˆ’ï¼ˆResource SharingPlan of CUMTCSï¼‰ã€‘æœ¬ä»“åº“ç”±çŸ¿å¤§è®¡ç®—æœºå­¦é™¢å­¦ç”Ÿä¼šå­¦ä¹ éƒ¨ç‰µå¤´ç»´æŠ¤ï¼Œç”±è®¡ç®—æœºå­¦é™¢å…¨ä½“åŒå­¦å…±å»ºå…±äº«ã€‚æ¬¢è¿å¤§å®¶ç§¯æçš„å‚åŠ åˆ°æœ¬èµ„æºåº“çš„å»ºè®¾ä¸­æ¥å§ï¼ï¼ˆæ¯å½“æœ‰é‡å¤§æ›´æ–°ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†æ•´ä¸ªåº“å…‹éš†åˆ°ç äº‘ï¼Œç‚¹å‡»ä¸‹è¾¹é“¾æ¥ï¼Œåˆ°æˆ‘ä»¬çš„ç äº‘ä»“åº“å¯ä»¥è·å¾—æ›´å¥½çš„ä¸‹è½½ä½“éªŒï¼‰

*   [ut-amrl/ObVi-SLAM](https://github.com/ut-amrl/ObVi-SLAM) - Long-Term Object Visual SLAM

*   [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) - A latent text-to-image diffusion model

*   [hanyangyu1021/LMGaussian](https://github.com/hanyangyu1021/LMGaussian) - code will be available soon

*   [haksorus/gsplatloc](https://github.com/haksorus/gsplatloc) - GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization

*   [TommyZihao/Train\_Custom\_Dataset](https://github.com/TommyZihao/Train_Custom_Dataset) - æ ‡æ³¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè®­ç»ƒã€è¯„ä¼°ã€æµ‹è¯•ã€éƒ¨ç½²è‡ªå·±çš„äººå·¥æ™ºèƒ½ç®—æ³•

*   [isl-org/ZoeDepth](https://github.com/isl-org/ZoeDepth) - Metric depth estimation from a single image

*   [datawhalechina/leedl-tutorial](https://github.com/datawhalechina/leedl-tutorial) - ã€Šæå®æ¯…æ·±åº¦å­¦ä¹ æ•™ç¨‹ã€‹ï¼ˆæå®æ¯…è€å¸ˆæ¨èğŸ‘ï¼Œè‹¹æœä¹¦ğŸï¼‰ï¼ŒPDFä¸‹è½½åœ°å€ï¼šhttps://github.com/datawhalechina/leedl-tutorial/releases

*   [Fafa-DL/Lhy\_Machine\_Learning](https://github.com/Fafa-DL/Lhy_Machine_Learning) - æå®æ¯…2021/2022/2023æ˜¥å­£æœºå™¨å­¦ä¹ è¯¾ç¨‹è¯¾ä»¶åŠä½œä¸š

*   [yubaoliu/RDS-SLAM](https://github.com/yubaoliu/RDS-SLAM) - DS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods

*   [SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist) - The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery ğŸ§‘â€ğŸ”¬

*   [datawhalechina/self-llm](https://github.com/datawhalechina/self-llm) - ã€Šå¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—ã€‹åŸºäºLinuxç¯å¢ƒå¿«é€Ÿéƒ¨ç½²å¼€æºå¤§æ¨¡å‹ï¼Œæ›´é€‚åˆä¸­å›½å®å®çš„éƒ¨ç½²æ•™ç¨‹

*   [facebookresearch/sam2](https://github.com/facebookresearch/sam2) - The repository provides code for running inference with the Meta Segment Anything Model 2 (SAM 2), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.

*   [hustvl/4DGaussians](https://github.com/hustvl/4DGaussians) - \[CVPR 2024] 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering

*   [heucoder/ML-DL\_book](https://github.com/heucoder/ML-DL_book) - æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ä¸€äº›ä¸ªäººè®¤ä¸ºä¸é”™çš„ä¹¦ç±ã€‚

## MATLAB

*   [zhao-zhibo/INS](https://github.com/zhao-zhibo/INS) - INS.IMU. Inertial navigation mechanical arrangement algorithm, based on Yan Gongmin's PSINS æƒ¯å¯¼æœºæ¢°ç¼–æ’ç®—æ³•ï¼Œä»¥ä¸¥æ­æ•çš„PSINSä¸ºåŸºç¡€ï¼Œå¯ä»¥å®Œæˆæ­¦æ±‰å¤§å­¦çš„æœºæ¢°ç¼–æ’è¯¾ç¨‹ä½œä¸š.

*   [ShiArthur03/ShiArthur03](https://github.com/ShiArthur03/ShiArthur03) -

## Dockerfile

*   [jaeseok4104/slam-docker](https://github.com/jaeseok4104/slam-docker) - SLAM Docker for research

## SCSS

*   [RayeRen/acad-homepage.github.io](https://github.com/RayeRen/acad-homepage.github.io) - AcadHomepage: A Modern and Responsive Academic Personal Homepage

*   [mcdviral/mcdviral.github.io](https://github.com/mcdviral/mcdviral.github.io) -

## HTML

*   [beichensky/Font](https://github.com/beichensky/Font) - FiraCode å’Œ Operator Mono å­—ä½“

## Dart

*   [localsend/localsend](https://github.com/localsend/localsend) - An open-source cross-platform alternative to AirDrop

*   [chen08209/FlClash](https://github.com/chen08209/FlClash) - A multi-platform proxy client based on ClashMeta,simple and easy to use, open-source and ad-free.

## Markdown

*   [labuladong/fucking-algorithm](https://github.com/labuladong/fucking-algorithm) - åˆ·ç®—æ³•å…¨é å¥—è·¯ï¼Œè®¤å‡† labuladong å°±å¤Ÿäº†ï¼English version supported! Crack LeetCode, not only how, but also why.

*   [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) - Master programming by recreating your favorite technologies from scratch.

## TeX

*   [whutug/whu-thesis](https://github.com/whutug/whu-thesis) - :memo: æ­¦æ±‰å¤§å­¦æ¯•ä¸šè®ºæ–‡ LaTeX æ¨¡ç‰ˆ 2024

## Clojure

*   [tonsky/FiraCode](https://github.com/tonsky/FiraCode) - Free monospaced font with programming ligatures

## Makefile

*   [kahowang/FAST\_LIO\_SAM](https://github.com/kahowang/FAST_LIO_SAM) - Front\_end : fastlio2  Back\_end : lio\_sam

## Java

*   [krahets/hello-algo](https://github.com/krahets/hello-algo) - ã€ŠHello ç®—æ³•ã€‹ï¼šåŠ¨ç”»å›¾è§£ã€ä¸€é”®è¿è¡Œçš„æ•°æ®ç»“æ„ä¸ç®—æ³•æ•™ç¨‹ã€‚æ”¯æŒ Python, Java, C++, C, C#, JS, Go, Swift, Rust, Ruby, Kotlin, TS, Dart ä»£ç ã€‚ç®€ä½“ç‰ˆå’Œç¹ä½“ç‰ˆåŒæ­¥æ›´æ–°ï¼ŒEnglish version ongoing

## Go

*   [sourcegraph/sourcegraph-public-snapshot](https://github.com/sourcegraph/sourcegraph-public-snapshot) - Code AI platform with Code Search & Cody

## Vim Script

*   [amix/vimrc](https://github.com/amix/vimrc) - The ultimate Vim configuration (vimrc)

*   [vim/vim](https://github.com/vim/vim) - The official Vim repository

*   [linrongbin16/lin.vim](https://github.com/linrongbin16/lin.vim) - Lin Rongbin's (Neo)Vim Distribution

## C\#

*   [mahoshojo0805/ContestPrograms](https://github.com/mahoshojo0805/ContestPrograms) - æµ‹ç»˜æŠ€èƒ½å¤§èµ›ç¨‹åº
