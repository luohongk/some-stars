<div align="center">

# Some Stars

‚≠ê <a href="https://luohongkun.com/"  target="_blank">LuoHongkun</a>ÁöÑstarÂàóË°®ÔºåÊØè6Â∞èÊó∂Ëá™Âä®Êõ¥Êñ∞,ÂèÇËÄÉÈìæÊé•-><a href="https://linux.do/t/topic/115143"  target="_blank">github starÂàóË°®Ëá™Âä®Êõ¥Êñ∞</a> ‚≠ê

</div><br>

## Table of Contents

*   [Python](#python)
*   [C++](#c)
*   [miscellaneous](#miscellaneous)
*   [JavaScript](#javascript)
*   [Cuda](#cuda)
*   [Jupyter Notebook](#jupyter-notebook)
*   [TypeScript](#typescript)
*   [Makefile](#makefile)
*   [Dockerfile](#dockerfile)
*   [LLVM](#llvm)
*   [Shell](#shell)
*   [HTML](#html)
*   [CSS](#css)
*   [C#](#c-1)
*   [Swift](#swift)
*   [Astro](#astro)
*   [Rust](#rust)
*   [MATLAB](#matlab)
*   [Fortran](#fortran)
*   [Matlab](#matlab-1)
*   [Go](#go)
*   [Cython](#cython)
*   [TeX](#tex)
*   [C](#c-2)
*   [CMake](#cmake)
*   [Lua](#lua)
*   [SCSS](#scss)
*   [Dart](#dart)
*   [Markdown](#markdown)
*   [Clojure](#clojure)
*   [Java](#java)
*   [Vim Script](#vim-script)

## Python

*   [whu-lyh/SaliencyI2PLoc](https://github.com/whu-lyh/SaliencyI2PLoc) - Official code of SaliencyI2PLoc

*   [robot-learning-freiburg/LCDNet](https://github.com/robot-learning-freiburg/LCDNet) - PyTorch code for training LCDNet for loop closure detection in LiDAR SLAM. http://rl.uni-freiburg.de/research/lidar-slam-lc

*   [MarSaKi/VLN-BEVBert](https://github.com/MarSaKi/VLN-BEVBert) - \[ICCV 2023} Official repo of "BEVBert: Multimodal Map Pre-training for Language-guided Navigation"

*   [crepuscularlight/SemanticLoopClosure](https://github.com/crepuscularlight/SemanticLoopClosure) - Master thesis regarding semantic loop closure

*   [Ghiara/LEGION](https://github.com/Ghiara/LEGION) - Official implementation of paper on Nature Machine Intelligence: "Preserving and Combining Knowledge in Robotic Lifelong Reinforcement Learning"

*   [All-Hands-AI/OpenHands](https://github.com/All-Hands-AI/OpenHands) - üôå OpenHands: Code Less, Make More

*   [Zhefan-Xu/isaac-go2-ros2](https://github.com/Zhefan-Xu/isaac-go2-ros2) - Unitree Go2 simulation platform for testing navigation, decision-making and autonomous tasks. (NVIDIA Isaac/ROS2)

*   [YicongHong/Recurrent-VLN-BERT](https://github.com/YicongHong/Recurrent-VLN-BERT) - Code of the CVPR 2021 Oral paper: A Recurrent Vision-and-Language BERT for Navigation

*   [gaoxiangjun/Mani-GS](https://github.com/gaoxiangjun/Mani-GS) - \[CVPR' 2025'] Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh

*   [convexsplatting/convex-splatting](https://github.com/convexsplatting/convex-splatting) - \[CVPR 2025] Original implementation of "3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes"

*   [jzhzhang/NaVid-VLN-CE](https://github.com/jzhzhang/NaVid-VLN-CE) - \[RSS 2024] NaVid: Video-based VLM Plans the Next Step for Vision-and-Language Navigation

*   [jacobkrantz/VLN-CE](https://github.com/jacobkrantz/VLN-CE) - Vision-and-Language Navigation in Continuous Environments using Habitat

*   [JeffLIrion/python-graphslam](https://github.com/JeffLIrion/python-graphslam) - Graph SLAM solver in Python

*   [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) - Generative Models by Stability AI

*   [vdorbala/LGX](https://github.com/vdorbala/LGX) - Code for LGX (Language Guided Exploration). We use LLMs to perform embodied robot navigation in a zero-shot manner.

*   [PKU-VCL-3DV/SLAM3R](https://github.com/PKU-VCL-3DV/SLAM3R) - \[CVPR 2025] Real-time dense scene reconstruction with SLAM3R

*   [fanegg/Feat2GS](https://github.com/fanegg/Feat2GS) - \[CVPR2025] Feat2GS: Probing Visual Foundation Models with Gaussian Splatting

*   [MrZihan/Sim2Real-VLN-3DFF](https://github.com/MrZihan/Sim2Real-VLN-3DFF) - Official implementation of Sim-to-Real Transfer via 3D Feature Fields for Vision-and-Language Navigation  (CoRL'24).

*   [csiro-robotics/Pair-VPR](https://github.com/csiro-robotics/Pair-VPR) - \[IEEE RA-L 2025] The official repository for Pair-VPR: Place-Aware Pre-training and Contrastive Pair Classification for Visual Place Recognition with Vision Transformers

*   [facebookresearch/fast3r](https://github.com/facebookresearch/fast3r) - \[CVPR 2025] Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass

*   [XiaohanLei/GaussNav](https://github.com/XiaohanLei/GaussNav) - PyTorch implementation of paper: GaussNav: Gaussian Splatting for Visual Navigation

*   [dmar-bonn/active-gs](https://github.com/dmar-bonn/active-gs) - ActiveGS: Active Scene Reconstruction Using Gaussian Splatting

*   [WU-CVGL/Omni-Scene](https://github.com/WU-CVGL/Omni-Scene) - \[CVPR2025] Omni-Scene: Omni-Gaussian Representation for Ego-Centric Sparse-View Scene Reconstruction

*   [hzxie/GaussianCity](https://github.com/hzxie/GaussianCity) - The official implementation of "GaussianCity: Generative Gaussian Splatting for Unbounded 3D City Generation". (CVPR 2025)

*   [showlab/ShowUI](https://github.com/showlab/ShowUI) - \[CVPR 2025] Open-source, End-to-end, Vision-Language-Action model for GUI Agent & Computer Use.

*   [iris0329/SeeGround](https://github.com/iris0329/SeeGround) - \[CVPR'25] SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding

*   [pengwangucla/DeLS-3D](https://github.com/pengwangucla/DeLS-3D) - The code for DeLS-3D of CVPR 2018

*   [rpng/calc](https://github.com/rpng/calc) - Convolutional Autoencoder for Loop Closure

*   [CASIA-IVA-Lab/FastSAM](https://github.com/CASIA-IVA-Lab/FastSAM) - Fast Segment Anything

*   [rmurai0610/MASt3R-SLAM](https://github.com/rmurai0610/MASt3R-SLAM) - \[CVPR 2025] MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors

*   [AirVLN/AirVLN](https://github.com/AirVLN/AirVLN) -

*   [xuxw98/ESAM](https://github.com/xuxw98/ESAM) - \[ICLR 2025, Oral] EmbodiedSAM: Online Segment Any 3D Thing in Real Time

*   [fishmarch/ROSTools](https://github.com/fishmarch/ROSTools) -

*   [sair-lab/AirCode](https://github.com/sair-lab/AirCode) - AirCode: A Robust Object Encoding Method (RA-L, ICRA 2022)

*   [jingyaogong/minimind](https://github.com/jingyaogong/minimind) - üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!

*   [url-kaist/MambaGlue](https://github.com/url-kaist/MambaGlue) - MambaGlue: Fast and Robust Local Feature Matching With Mamba @ ICRA'25

*   [fraunhoferhhi/AT-GS](https://github.com/fraunhoferhhi/AT-GS) - Adaptive and Temporally Consistent Gaussian Surfels for Multi-view Dynamic Reconstruction

*   [sunsmarterjie/yolov12](https://github.com/sunsmarterjie/yolov12) - YOLOv12: Attention-Centric Real-Time Object Detectors

*   [HKUDS/GraphGPT](https://github.com/HKUDS/GraphGPT) - \[SIGIR'2024] "GraphGPT: Graph Instruction Tuning for Large Language Models"

*   [luigifreda/pyslam](https://github.com/luigifreda/pyslam) - pySLAM is a visual SLAM pipeline in Python for monocular, stereo and RGBD cameras. It supports many modern local and global features, different loop-closing methods, a volumetric reconstruction pipeline, and depth prediction models.

*   [wangyizhao/PRIOR-SLAM](https://github.com/wangyizhao/PRIOR-SLAM) - PRIOR-SLAM: Enabling Visual SLAM for Loop Closure under Large Viewpoint Variations

*   [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) - Open-sourced codes for MiniGPT-4 and MiniGPT-v2 (https://minigpt-4.github.io, https://minigpt-v2.github.io/)

*   [yuanzhoulvpi2017/vscode\_debug\_transformers](https://github.com/yuanzhoulvpi2017/vscode_debug_transformers) -

*   [DavideCatto/XFeat-ONNX](https://github.com/DavideCatto/XFeat-ONNX) -

*   [DavideCatto/XFeat-ONNX](https://github.com/DavideCatto/XFeat-ONNX) -

*   [datawhalechina/tiny-universe](https://github.com/datawhalechina/tiny-universe) - „ÄäÂ§ßÊ®°ÂûãÁôΩÁõíÂ≠êÊûÑÂª∫ÊåáÂçó„ÄãÔºö‰∏Ä‰∏™ÂÖ®ÊâãÊêìÁöÑTiny-Universe

*   [BJHYZJ/DovSG](https://github.com/BJHYZJ/DovSG) - \[RA-L 2025] Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided Mobile Manipulation

*   [yang-zj1026/VLN-CE-Isaac](https://github.com/yang-zj1026/VLN-CE-Isaac) - Vision-Language Navigation Benchmark in Isaac Lab

*   [CUT3R/CUT3R](https://github.com/CUT3R/CUT3R) - Official implementation of Continuous 3D Perception Model with Persistent State

*   [LYX0501/InstructNav](https://github.com/LYX0501/InstructNav) -

*   [huggingface/open-r1](https://github.com/huggingface/open-r1) - Fully open reproduction of DeepSeek-R1

*   [deepseek-ai/DeepSeek-Coder](https://github.com/deepseek-ai/DeepSeek-Coder) - DeepSeek Coder: Let the Code Write Itself

*   [Irvingao/Point-DETR3D](https://github.com/Irvingao/Point-DETR3D) - \[AAAI 2024] Point-DETR3D: Leveraging Imagery Data with Spatial Point Prior for Weakly Semi-Supervised 3D Object Detection

*   [luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv](https://github.com/luohongk/Awesome-Localization-And-3D-Reconstruction-From-Arxiv) - Ëøô‰∏™‰ªìÂ∫ìÊòØÂú®arxiv‰∏äÊî∂ÈõÜÁöÑÊúâÂÖ≥ÂÆö‰ΩçÂØºËà™Ôºå‰∏âÁª¥ÈáçÂª∫ÔºåVLNÔºåVLAÁöÑÁõ∏ÂÖ≥ËÆ∫Êñá„ÄÇÊØèÂ§©ÈÉΩ‰ºöËá™Âä®Êõ¥Êñ∞ÔºÅissueÂå∫ÂüüÊòØÊúÄÊñ∞10ÁØáËÆ∫Êñá

*   [HaoyiZhu/SPA](https://github.com/HaoyiZhu/SPA) - \[ICLR 2025] SPA: 3D Spatial-Awareness Enables Effective Embodied Representation

*   [zezhishao/DailyArXiv](https://github.com/zezhishao/DailyArXiv) - Daily ArXiv Papers.

*   [microsoft/MoGe](https://github.com/microsoft/MoGe) - MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision

*   [NVlabs/InstantSplat](https://github.com/NVlabs/InstantSplat) - InstantSplat: Sparse-view SfM-free Gaussian Splatting in Seconds

*   [Nanne/pytorch-NetVlad](https://github.com/Nanne/pytorch-NetVlad) - Pytorch implementation of NetVlad including training on Pittsburgh.

*   [VITA-Group/MM3DGS-SLAM](https://github.com/VITA-Group/MM3DGS-SLAM) - \[IROS 2024] MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements

*   [hmz-15/Interactive-Predicate-Learning](https://github.com/hmz-15/Interactive-Predicate-Learning) - InterPreT: Interactive Predicate Learning from Language Feedback for Generalizable Task Planning (RSS 2024)

*   [google-deepmind/mujoco\_menagerie](https://github.com/google-deepmind/mujoco_menagerie) - A collection of high-quality models for the MuJoCo physics engine, curated by Google DeepMind.

*   [Aceinna/gnss-ins-sim](https://github.com/Aceinna/gnss-ins-sim) - Open-source GNSS + inertial navigation, sensor fusion simulator.  Motion trajectory generator, sensor models, and navigation

*   [modelscope/FunClip](https://github.com/modelscope/FunClip) - Open-source, accurate and easy-to-use video speech recognition & clipping tool, LLM based AI clipping intergrated.

*   [naver/mast3r](https://github.com/naver/mast3r) - Grounding Image Matching in 3D with MASt3R

*   [opendilab/LightZero](https://github.com/opendilab/LightZero) - \[NeurIPS 2023 Spotlight] LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios (awesome MCTS)

*   [naver/dust3r](https://github.com/naver/dust3r) - DUSt3R: Geometric 3D Vision Made Easy

*   [OpenDriveLab/AgiBot-World](https://github.com/OpenDriveLab/AgiBot-World) - The Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems

*   [facebookresearch/DiT](https://github.com/facebookresearch/DiT) - Official PyTorch Implementation of "Scalable Diffusion Models with Transformers"

*   [TianxingChen/RoboTwin](https://github.com/TianxingChen/RoboTwin) - \[CVPR 25] RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins

*   [deepseek-ai/DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) -

*   [MachinePerceptionLab/QQ-SLAM](https://github.com/MachinePerceptionLab/QQ-SLAM) -

*   [YvanYin/Metric3D](https://github.com/YvanYin/Metric3D) - The repo for "Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image" and "Metric3Dv2: A Versatile Monocular Geometric Foundation Model..."

*   [modelscope/modelscope-agent](https://github.com/modelscope/modelscope-agent) - ModelScope-Agent: An agent framework connecting models in ModelScope with the world

*   [Genesis-Embodied-AI/Genesis](https://github.com/Genesis-Embodied-AI/Genesis) - A generative world for general-purpose robotics & embodied AI learning.

*   [gramuah/ros4vsn](https://github.com/gramuah/ros4vsn) - Evaluation of Visual Semantic Navigation Models in Real Robots

*   [Byaidu/PDFMathTranslate](https://github.com/Byaidu/PDFMathTranslate) - PDF scientific paper translation with preserved formats - Âü∫‰∫é AI ÂÆåÊï¥‰øùÁïôÊéíÁâàÁöÑ PDF ÊñáÊ°£ÂÖ®ÊñáÂèåËØ≠ÁøªËØëÔºåÊîØÊåÅ Google/DeepL/Ollama/OpenAI Á≠âÊúçÂä°ÔºåÊèê‰æõ CLI/GUI/Docker/Zotero

*   [LemonAttn/ownflow](https://github.com/LemonAttn/ownflow) - Âà©Áî®numpyÂÆûÁé∞‰∏Ä‰∏™Â∞èÂûãÂÆûÈ™åÊÄßÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂

*   [myhhub/stock](https://github.com/myhhub/stock) - stockËÇ°Á•®.Ëé∑ÂèñËÇ°Á•®Êï∞ÊçÆ,ËÆ°ÁÆóËÇ°Á•®ÊåáÊ†á,Á≠πÁ†ÅÂàÜÂ∏É,ËØÜÂà´ËÇ°Á•®ÂΩ¢ÊÄÅ,ÁªºÂêàÈÄâËÇ°,ÈÄâËÇ°Á≠ñÁï•,ËÇ°Á•®È™åËØÅÂõûÊµã,ËÇ°Á•®Ëá™Âä®‰∫§Êòì,ÊîØÊåÅPCÂèäÁßªÂä®ËÆæÂ§á„ÄÇ

*   [AliYoussef97/SuperPoint-PrP](https://github.com/AliYoussef97/SuperPoint-PrP) -

*   [PKU-YuanGroup/Open-Sora-Plan](https://github.com/PKU-YuanGroup/Open-Sora-Plan) - This project aim to reproduce Sora (Open AI T2V model), we wish the open source community contribute to this project.

*   [hustvl/DiffusionDrive](https://github.com/hustvl/DiffusionDrive) - \[CVPR 2025] Truncated Diffusion Model for Real-Time End-to-End Autonomous Driving

*   [ispc-lab/HRegNet](https://github.com/ispc-lab/HRegNet) - \[ICCV 2021] HRegNet: A Hierarchical Network for Large-scale Outdoor LiDAR Point Cloud Registration

*   [nerfstudio-project/gsplat](https://github.com/nerfstudio-project/gsplat) - CUDA accelerated rasterization of gaussian splatting

*   [ranahanocka/point2mesh](https://github.com/ranahanocka/point2mesh) - Reconstruct Watertight Meshes from Point Clouds \[SIGGRAPH 2020]

*   [TianxingChen/G3Flow](https://github.com/TianxingChen/G3Flow) - \[CVPR 25] G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation

*   [TheBlewish/Automated-AI-Web-Researcher-Ollama](https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama) - A python program that turns an LLM, running on Ollama, into an automated researcher, which will with a single query determine focus areas to investigate, do websearches and scrape content from various relevant websites and do research for you all on its own! And more, not limited to but including saving the findings for you!

*   [facebookresearch/neuralfeels](https://github.com/facebookresearch/neuralfeels) - Neural feels with neural fields: Visuo-tactile perception for in-hand manipulation

*   [ori-drs/oxford\_spires\_dataset](https://github.com/ori-drs/oxford_spires_dataset) -

*   [blazzbyte/OpenInterpreterUI](https://github.com/blazzbyte/OpenInterpreterUI) - Simplify code execution with Open Interpreter UI Project with Streamlit. A user-friendly GUI for Python, JavaScript, and more. Pay-as-you-go, no subscriptions. Ideal for beginners.

*   [fudan-zvg/gaussian-raytracing](https://github.com/fudan-zvg/gaussian-raytracing) -

*   [ChenYutongTHU/SplatFormer](https://github.com/ChenYutongTHU/SplatFormer) - \[ICLR' 25] SplatFormer: Point Transformer for Robust 3D Gaussian Splatting

*   [akawincent/ZED-data-collector](https://github.com/akawincent/ZED-data-collector) - In this project, ZED camera is used to extract image, IMU, pose data and convert them into a dataset format as ground truth for evaluation of other SLAM systems

*   [Parskatt/RoMa](https://github.com/Parskatt/RoMa) - \[CVPR 2024] RoMa: Robust Dense Feature Matching; RoMa is the robust dense feature matcher capable of estimating pixel-dense warps and reliable certainties for almost any image pair.

*   [microsoft/autogen](https://github.com/microsoft/autogen) - A programming framework for agentic AI ü§ñ PyPi: autogen-agentchat Discord: https://aka.ms/autogen-discord Office Hour: https://aka.ms/autogen-officehour

*   [KwanWaiPang/Gaussian-SLAM\_comment](https://github.com/KwanWaiPang/Gaussian-SLAM_comment) - Gaussian-SLAMÁöÑ‰∏≠ÊñáÊ≥®Èáä

*   [open-mmlab/mmdetection](https://github.com/open-mmlab/mmdetection) - OpenMMLab Detection Toolbox and Benchmark

*   [OpenRobotLab/VLM-Grounder](https://github.com/OpenRobotLab/VLM-Grounder) - \[CoRL 2024] VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding

*   [GREAT-WHU/GREAT-Dataset](https://github.com/GREAT-WHU/GREAT-Dataset) -

*   [LibraHp/GetQzonehistory](https://github.com/LibraHp/GetQzonehistory) - Ëé∑ÂèñQQÁ©∫Èó¥ÂèëÂ∏ÉÁöÑÂéÜÂè≤ËØ¥ËØ¥

*   [VladimirYugay/Gaussian-SLAM](https://github.com/VladimirYugay/Gaussian-SLAM) - Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting

*   [MisEty/RTG-SLAM](https://github.com/MisEty/RTG-SLAM) - RTG-SLAM: Real-time 3D Reconstruction at Scale Using Gaussian Splatting (ACM SIGGRAPH 2024)

*   [Tencent/Tencent-Hunyuan-Large](https://github.com/Tencent/Tencent-Hunyuan-Large) -

*   [cvg/NoPoSplat](https://github.com/cvg/NoPoSplat) - No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images

*   [megvii-research/MCTrack](https://github.com/megvii-research/MCTrack) - This is the offical implementation of the paper "MCTrack: A Unified 3D Multi-Object Tracking Framework for Autonomous Driving"

*   [nv-tlabs/SCube](https://github.com/nv-tlabs/SCube) - \[NeurIPS 2024] SCube: Instant Large-Scale Scene Reconstruction using VoxSplats

*   [princeton-vl/RAFT-Stereo](https://github.com/princeton-vl/RAFT-Stereo) -

*   [ChenHoy/DROID-Splat](https://github.com/ChenHoy/DROID-Splat) - End-to-End SLAM with camera calibration, monocular prior integration and dense Rendering

*   [OpenInterpreter/open-interpreter](https://github.com/OpenInterpreter/open-interpreter) - A natural language interface for computers

*   [robot-learning-freiburg/CL-SLAM](https://github.com/robot-learning-freiburg/CL-SLAM) - Continual SLAM: Beyond Lifelong Simultaneous Localization and Mapping through Continual Learning. http://continual-slam.cs.uni-freiburg.de

*   [ywyeli/Place3D](https://github.com/ywyeli/Place3D) - \[NeurIPS'24 Spotlight] Is Your LiDAR Placement Optimized for 3D Scene Understanding?

*   [TommyZihao/openvino\_tonypi](https://github.com/TommyZihao/openvino_tonypi) - Âü∫‰∫éOpenVINOÔºåÊú¨Âú∞ÈÉ®ÁΩ≤Â§ßÊ®°ÂûãÊô∫ËÉΩ‰ΩìAgentÔºåÊéßÂà∂TonyPi‰∫∫ÂΩ¢Êú∫Âô®‰∫∫

*   [donydchen/mvsplat](https://github.com/donydchen/mvsplat) - üåä \[ECCV'24 Oral] MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images

*   [songw-zju/LiDAR2Map](https://github.com/songw-zju/LiDAR2Map) - The official implementation of "LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using Online Camera Distillation" (CVPR 2023)

*   [zhaihongjia/SplatLoc](https://github.com/zhaihongjia/SplatLoc) - \[TVCG 2025] SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality

*   [NanmiCoder/MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) - Â∞èÁ∫¢‰π¶Á¨îËÆ∞ | ËØÑËÆ∫Áà¨Ëô´„ÄÅÊäñÈü≥ËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅÂø´ÊâãËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅB Á´ôËßÜÈ¢ë ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÂæÆÂçöÂ∏ñÂ≠ê ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÁôæÂ∫¶Ë¥¥ÂêßÂ∏ñÂ≠ê ÔΩú ÁôæÂ∫¶Ë¥¥ÂêßËØÑËÆ∫ÂõûÂ§çÁà¨Ëô´  | Áü•‰πéÈóÆÁ≠îÊñáÁ´†ÔΩúËØÑËÆ∫Áà¨Ëô´

*   [hkchengrex/Cutie](https://github.com/hkchengrex/Cutie) - \[CVPR 2024 Highlight] Putting the Object Back Into Video Object Segmentation

*   [520xyxyzq/3DGS-CD](https://github.com/520xyxyzq/3DGS-CD) - 3DGS-based change detection for physical object rearrangement

*   [facebookresearch/lingua](https://github.com/facebookresearch/lingua) - Meta Lingua: a lean, efficient, and easy-to-hack codebase to research LLMs.

*   [google/nerfies](https://github.com/google/nerfies) - This is the code for Deformable Neural Radiance Fields, a.k.a. Nerfies.

*   [Owen718/LongPrompt-LLamaGen](https://github.com/Owen718/LongPrompt-LLamaGen) - This repository provides an improved LLamaGen Model, fine-tuned on 500,000 high-quality images, each accompanied by over 300 token prompts. And it's also powered by additional prompt refining features for improved performance.

*   [openai/improved-diffusion](https://github.com/openai/improved-diffusion) - Release for Improved Denoising Diffusion Probabilistic Models

*   [hzy46/Deep-Learning-21-Examples](https://github.com/hzy46/Deep-Learning-21-Examples) - „Ää21‰∏™È°πÁõÆÁé©ËΩ¨Ê∑±Â∫¶Â≠¶‰π†‚Äî‚Äî‚ÄîÂü∫‰∫éTensorFlowÁöÑÂÆûË∑µËØ¶Ëß£„ÄãÈÖçÂ•ó‰ª£Á†Å

*   [StanfordVL/3DSceneGraph](https://github.com/StanfordVL/3DSceneGraph) - The data skeleton from "3D Scene Graph: A Structure for Unified Semantics, 3D Space, and Camera" http://3dscenegraph.stanford.edu

*   [cvg/depthsplat](https://github.com/cvg/depthsplat) - \[CVPR'25] DepthSplat: Connecting Gaussian Splatting and Depth

*   [HKUDS/LightRAG](https://github.com/HKUDS/LightRAG) - "LightRAG: Simple and Fast Retrieval-Augmented Generation"

*   [princeton-vl/DROID-SLAM](https://github.com/princeton-vl/DROID-SLAM) -

*   [jiaoZ7688/YOLOPX](https://github.com/jiaoZ7688/YOLOPX) -

*   [Nightmare-n/DepthAnyVideo](https://github.com/Nightmare-n/DepthAnyVideo) - Depth Any Video with Scalable Synthetic Data (ICLR 2025)

*   [linyicheng1/EdgePoint](https://github.com/linyicheng1/EdgePoint) - EdgePoint: Learning Efficient Keypoint Extraction and Description for Edge Devices

*   [uzh-rpg/bflow](https://github.com/uzh-rpg/bflow) - Official implementation of "Dense Continuous-Time Optical Flow from Event Cameras"

*   [VITA-Group/LightGaussian](https://github.com/VITA-Group/LightGaussian) - \[NeurIPS 2024 Spotlight]"LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS", Zhiwen Fan, Kevin Wang, Kairun Wen, Zehao Zhu, Dejia Xu, Zhangyang Wang

*   [uzh-rpg/deep\_ev\_tracker](https://github.com/uzh-rpg/deep_ev_tracker) - Repository relating to "Data-driven Feature Tracking for Event Cameras" (CVPR, 2023, Award Candidate) and "Data-driven Feature Tracking for Event Cameras with and without Frames" (T-PAMI 2025)

*   [LemonAttn/moco-pytorch](https://github.com/LemonAttn/moco-pytorch) - mocoÁöÑÂ≠¶‰π†‰æãÂ≠êÔºåÂà©Áî®mnistÊï∞ÊçÆÈõÜÂÆûÁé∞

*   [IRMVLab/DVLO](https://github.com/IRMVLab/DVLO) - \[ECCV 2024 Oral] DVLO: Deep Visual-LiDAR Odometry with Local-to-Global Feature Fusion and Bi-Directional Structure Alignment

*   [hustvl/osp](https://github.com/hustvl/osp) - \[ECCV 2024] Occupancy as Set of Points

*   [HuangJunJie2017/BEVDet](https://github.com/HuangJunJie2017/BEVDet) - Code base of the BEVDet series .

*   [city-super/Octree-AnyGS](https://github.com/city-super/Octree-AnyGS) - Octree-GS

*   [buaacyw/MeshAnythingV2](https://github.com/buaacyw/MeshAnythingV2) - From anything to mesh like human artists. Official impl. of "MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization"

*   [roboflow/supervision](https://github.com/roboflow/supervision) - We write your reusable computer vision tools. üíú

*   [yifanlu0227/ChatSim](https://github.com/yifanlu0227/ChatSim) - \[CVPR2024 Highlight] Editable Scene Simulation for Autonomous Driving via LLM-Agent Collaboration

*   [cjy1992/interp-e2e-driving](https://github.com/cjy1992/interp-e2e-driving) - Interpretable End-to-end Urban Autonomous Driving with Latent Deep Reinforcement Learning

*   [chenzomi12/AIInfra](https://github.com/chenzomi12/AIInfra) - AIInfraÔºàAI Âü∫Á°ÄËÆæÊñΩÔºâÊåáAIÁ≥ªÁªü‰ªéÂ∫ïÂ±ÇËäØÁâáÁ≠âÁ°¨‰ª∂ÔºåÂà∞‰∏äÂ±ÇËΩØ‰ª∂Ê†àÊîØÊåÅAIÂ§ßÊ®°ÂûãËÆ≠ÁªÉÂíåÊé®ÁêÜ„ÄÇ

*   [Robertwyq/PanoOcc](https://github.com/Robertwyq/PanoOcc) - \[CVPR 2024] PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation

*   [TheAlgorithms/Python](https://github.com/TheAlgorithms/Python) - All Algorithms implemented in Python

*   [morrisfl/UniFEx](https://github.com/morrisfl/UniFEx) - Framework for computationally efficient training of universal image feature extraction models.

*   [qintonguav/ParkingE2E](https://github.com/qintonguav/ParkingE2E) -

*   [hanyangyu1021/LMGaussian](https://github.com/hanyangyu1021/LMGaussian) - code will be available soon

*   [pytorch/pytorch](https://github.com/pytorch/pytorch) - Tensors and Dynamic neural networks in Python with strong GPU acceleration

*   [eth-ait/GaussianHaircut](https://github.com/eth-ait/GaussianHaircut) - Gaussian Haircut: Human Hair Reconstruction with Strand-Aligned 3D Gaussians

*   [pyg-team/pytorch-frame](https://github.com/pyg-team/pytorch-frame) - Tabular Deep Learning Library for PyTorch

*   [jkulhanek/wild-gaussians](https://github.com/jkulhanek/wild-gaussians) - \[NeurIPS'24] WildGaussians: 3D Gaussian Splatting In the Wild

*   [bassamlab/SigmaRL](https://github.com/bassamlab/SigmaRL) - SigmaRL: A Sample-Efficient and Generalizable Multi-Agent Reinforcement Learning Framework for Motion Planning

*   [DLR-MI/UTrack](https://github.com/DLR-MI/UTrack) - Multi-Object Tracking with Uncertain Detections \[ECCV 2024 UnCV]

*   [stanfordnlp/dspy](https://github.com/stanfordnlp/dspy) - DSPy: The framework for programming‚Äînot prompting‚Äîlanguage models

*   [TempleRAIL/drl\_vo\_nav](https://github.com/TempleRAIL/drl_vo_nav) - \[T-RO 2023] DRL-VO: Learning to Navigate Through Crowded Dynamic Scenes Using Velocity Obstacles

*   [lucasbrynte/gasfm](https://github.com/lucasbrynte/gasfm) - Implementation of the CVPR 2024 paper "Learning Structure-from-Motion with Graph Attention Networks".

*   [SPengLiang/OccupancyM3D](https://github.com/SPengLiang/OccupancyM3D) - \[CVPR 2024] Learning Occupancy for Monocular 3D Object Detection

*   [zhangganlin/GlORIE-SLAM](https://github.com/zhangganlin/GlORIE-SLAM) - GlORIE-SLAM: Globally Optimized RGB-only Implicit Encoding Point Cloud SLAM

*   [jbriales/rgbd\_benchmark\_tools](https://github.com/jbriales/rgbd_benchmark_tools) - Tools for TUM RGBD Dataset Benchmark

*   [yastrebksv/TennisProject](https://github.com/yastrebksv/TennisProject) - Tennis analysis using deep learning and machine¬†learning

*   [cvg/GeoCalib](https://github.com/cvg/GeoCalib) - GeoCalib: Learning Single-image Calibration with Geometric Optimization (ECCV 2024)

*   [NVIDIA/TransformerEngine](https://github.com/NVIDIA/TransformerEngine) - A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.

*   [lus6-Jenny/RING](https://github.com/lus6-Jenny/RING) - \[IEEE T-RO 2023] Source code of RING and RING++ for loop closure detection in LiDAR SLAM.

*   [hacksider/Deep-Live-Cam](https://github.com/hacksider/Deep-Live-Cam) - real time face swap and one-click video deepfake with only a single image

*   [GANWANSHUI/GaussianOcc](https://github.com/GANWANSHUI/GaussianOcc) - GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation with Gaussian Splatting

*   [GradientSpaces/LoopSplat](https://github.com/GradientSpaces/LoopSplat) - \[3DV 2025, Oral] LoopSplat: Loop Closure by Registering 3D Gaussian Splats

*   [zhaofuq/LOD-3DGS](https://github.com/zhaofuq/LOD-3DGS) - LetsGo: Large-Scale Garage Modeling and Rendering via LiDAR-Assisted Gaussian(Published in SIGGRAPH Asia 2024)

*   [hjr37/CP-SLAM](https://github.com/hjr37/CP-SLAM) - CP-SLAM: Collaborative Neural Point-based SLAM

*   [cvg/nicer-slam](https://github.com/cvg/nicer-slam) - \[3DV'24 Best Paper Honorable Mention] NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM

*   [lpiccinelli-eth/UniDepth](https://github.com/lpiccinelli-eth/UniDepth) - Universal Monocular Metric Depth Estimation

*   [JeongminB/E-D3DGS](https://github.com/JeongminB/E-D3DGS) - \[ECCV 2024] Official repository for "Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian Splatting"

*   [spla-tam/SplaTAM](https://github.com/spla-tam/SplaTAM) - SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM (CVPR 2024)

*   [sparolab/SOLiD](https://github.com/sparolab/SOLiD) - (RA-L 2024) This repository is the official code for Narrowing your FOV with SOLiD: Spatially Organized and Lightweight Global Descriptor for FOV-constrained LiDAR Place Recognition.

*   [IPNL-POLYU/UrbanNavDataset](https://github.com/IPNL-POLYU/UrbanNavDataset) - UrbanNav:An Open-sourced Multisensory Dataset for Benchmarking Positioning Algorithms Designed for Urban Areas

*   [YuxueYang1204/TrimGS](https://github.com/YuxueYang1204/TrimGS) - Trim 3D Gaussian Splatting for Accurate Geometry Representation

*   [open-mmlab/mmtracking](https://github.com/open-mmlab/mmtracking) - OpenMMLab Video Perception Toolbox. It supports Video Object Detection (VID), Multiple Object Tracking (MOT), Single Object Tracking (SOT), Video Instance Segmentation (VIS) with a unified framework.

*   [huggingface/transformers](https://github.com/huggingface/transformers) - ü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.

*   [openai/openai-python](https://github.com/openai/openai-python) - The official Python library for the OpenAI API

*   [llmbev/talk2bev](https://github.com/llmbev/talk2bev) - Talk2BEV: Language-Enhanced Bird's Eye View Maps (ICRA'24)

*   [liuyuan-pal/SyncDreamer](https://github.com/liuyuan-pal/SyncDreamer) - \[ICLR 2024 Spotlight] SyncDreamer: Generating Multiview-consistent Images from a Single-view Image

*   [fudan-zvg/4d-gaussian-splatting](https://github.com/fudan-zvg/4d-gaussian-splatting) - \[ICLR 2024] Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting

*   [eriksandstroem/Loopy-SLAM](https://github.com/eriksandstroem/Loopy-SLAM) -

*   [qinzheng93/GeoTransformer](https://github.com/qinzheng93/GeoTransformer) - \[CVPR2022] Geometric Transformer for Fast and Robust Point Cloud Registration

*   [yanyan-li/GeoGaussian](https://github.com/yanyan-li/GeoGaussian) - GeoGaussian: Geometry-aware Gaussian Splatting for Scene Rendering

*   [Parskatt/DeDoDe](https://github.com/Parskatt/DeDoDe) - \[3DV 2024 Oral] DeDoDe üé∂ Detect, Don't Describe --- Describe, Don't Detect, for Local Feature Matching

*   [ericzzj1989/BALF](https://github.com/ericzzj1989/BALF) - \[WACV 2024] BALF: Simple and Efficient Blur Aware Local Feature Detector

*   [lyakaap/NetVLAD-pytorch](https://github.com/lyakaap/NetVLAD-pytorch) - PyTorch implementation of NetVLAD & Online Hardest Triplet Loss.

*   [xiaobiaodu/DreamCar](https://github.com/xiaobiaodu/DreamCar) - \[RA-L] DreamCar: Leveraging Car-specific Prior for in-the-wild 3D Car Reconstruction

*   [nianticlabs/acezero](https://github.com/nianticlabs/acezero) - \[ECCV 2024 - Oral] ACE0 is a learning-based structure-from-motion approach that estimates camera parameters of sets of images by learning a multi-view consistent, implicit scene representation.

*   [meta-llama/llama-models](https://github.com/meta-llama/llama-models) - Utilities intended for use with Llama models.

*   [cs230-stanford/cs230-code-examples](https://github.com/cs230-stanford/cs230-code-examples) - Code examples in pyTorch and Tensorflow for CS230

*   [ddbourgin/numpy-ml](https://github.com/ddbourgin/numpy-ml) - Machine learning, in numpy

*   [lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch) - Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch

*   [tarashakhurana/4d-occ-forecasting](https://github.com/tarashakhurana/4d-occ-forecasting) - CVPR 2023: Official code for \`Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting'

*   [uoip/stereo\_msckf](https://github.com/uoip/stereo_msckf) - Python implementation of Multi-State Constraint Kalman Filter (MSCKF) for Vision-aided Inertial Navigation.

*   [fundamentalvision/BEVFormer](https://github.com/fundamentalvision/BEVFormer) - \[ECCV 2022] This is the official implementation of BEVFormer, a camera-only framework for autonomous driving perception, e.g., 3D object detection and semantic map segmentation.

*   [NVlabs/FB-BEV](https://github.com/NVlabs/FB-BEV) - Official PyTorch implementation of FB-BEV & FB-OCC - Forward-backward view transformation for vision-centric autonomous driving perception

*   [OpenDriveLab/OccNet](https://github.com/OpenDriveLab/OccNet) - \[ICCV 2023] OccNet: Scene as Occupancy

*   [Tsinghua-MARS-Lab/Occ3D](https://github.com/Tsinghua-MARS-Lab/Occ3D) -

*   [ViewFormerOcc/ViewFormer-Occ](https://github.com/ViewFormerOcc/ViewFormer-Occ) - \[ECCV 2024] ViewFormer: Exploring Spatiotemporal Modeling for Multi-View 3D Occupancy Perception via View-Guided Transformers

*   [MCG-NJU/SparseOcc](https://github.com/MCG-NJU/SparseOcc) - \[ECCV 2024] Fully Sparse 3D Occupancy Prediction & RayIoU Evaluation Metric

*   [VISION-SJTU/SparseOcc](https://github.com/VISION-SJTU/SparseOcc) - Official implementation for 'SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction' (CVPR 2024)

*   [weiyithu/SurroundOcc](https://github.com/weiyithu/SurroundOcc) - \[ICCV 2023] SurroundOcc: Multi-camera 3D Occupancy Prediction for Autonomous Driving

*   [autonomousvision/occupancy\_networks](https://github.com/autonomousvision/occupancy_networks) - This repository contains the code for the paper "Occupancy Networks - Learning 3D Reconstruction in Function Space"

*   [SY-007-Research/3dgs\_render\_python](https://github.com/SY-007-Research/3dgs_render_python) -

*   [Ferry-Li/SI-SOD](https://github.com/Ferry-Li/SI-SOD) - ICML2024: Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection

*   [Ferry-Li/SI\_Metric](https://github.com/Ferry-Li/SI_Metric) - A portable computation of Size-Invariant Metrics for ICML2024: Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection

*   [autonomousvision/mip-splatting](https://github.com/autonomousvision/mip-splatting) - \[CVPR'24 Best Student Paper] Mip-Splatting: Alias-free 3D Gaussian Splatting

*   [Vincentqyw/image-matching-webui](https://github.com/Vincentqyw/image-matching-webui) - ü§ó image matching webui

*   [LiheYoung/Depth-Anything](https://github.com/LiheYoung/Depth-Anything) - \[CVPR 2024] Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data. Foundation Model for Monocular Depth Estimation

*   [microsoft/graphrag](https://github.com/microsoft/graphrag) - A modular graph-based Retrieval-Augmented Generation (RAG) system

*   [rvp-group/vbr-devkit](https://github.com/rvp-group/vbr-devkit) - Vision Benchmark in Rome Development Kit

*   [utiasSTARS/pykitti](https://github.com/utiasSTARS/pykitti) - Python tools for working with KITTI data.

*   [huang-yh/GaussianFormer](https://github.com/huang-yh/GaussianFormer) - \[ECCV 2024] Scene as Gaussians for Vision-Based 3D Semantic Occupancy Prediction

*   [TQTQliu/MVSGaussian](https://github.com/TQTQliu/MVSGaussian) - \[ECCV 2024] MVSGaussian: Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo

*   [buaacyw/MeshAnything](https://github.com/buaacyw/MeshAnything) - \[ICLR 2025] From anything to mesh like human artists. Official impl. of "MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers"

*   [swc-17/SparseDrive](https://github.com/swc-17/SparseDrive) - SparseDrive: End-to-End Autonomous Driving via Sparse Scene Representation

*   [minghanqin/LangSplat](https://github.com/minghanqin/LangSplat) - Official implementation of the paper "LangSplat: 3D Language Gaussian Splatting" \[CVPR2024 Highlight]

## C++

*   [SlamCabbage/NDTMC](https://github.com/SlamCabbage/NDTMC) - \[IROS 2024] A 3D Global Descriptor For Loop Closure Detection. NDT-Map-Code.

*   [Joanna-HE/LIGO.](https://github.com/Joanna-HE/LIGO.) -

*   [gogojjh/M-LOAM](https://github.com/gogojjh/M-LOAM) - Robust Odometry and Mapping for Multi-LiDAR Systems with Online Extrinsic Calibration

*   [JokerJohn/PALoc](https://github.com/JokerJohn/PALoc) - \[TMECH'2024] Official codes of ‚ÄùPALoc: Advancing SLAM Benchmarking with Prior-Assisted 6-DoF Trajectory Generation and Uncertainty Estimation‚Äú

*   [sikang/mpl\_ros](https://github.com/sikang/mpl_ros) - A ROS wrapper for trajectory planning based on motion primitives

*   [Zhefan-Xu/NavRL](https://github.com/Zhefan-Xu/NavRL) - \[IEEE RA-L'25] NavRL: Learning Safe Flight in Dynamic Environments (NVIDIA Isaac/Python/ROS1/ROS2)

*   [Zhefan-Xu/CERLAB-UAV-Autonomy](https://github.com/Zhefan-Xu/CERLAB-UAV-Autonomy) - \[CMU] A Versatile and Modular Framework Designed for Autonomous Unmanned Aerial Vehicles \[UAVs] (C++/ROS/PX4)

*   [JD-hust/gs-dso](https://github.com/JD-hust/gs-dso) - a monocular direct sparse odometry with prior continuous 3D gaussian maps for indoor environments

*   [YWL0720/YOLO\_ORB\_SLAM3\_with\_pointcloud\_map](https://github.com/YWL0720/YOLO_ORB_SLAM3_with_pointcloud_map) - This code is an extended version of YOLO\_ORB\_SLAM3, which adds the functionality of creating dense point cloud maps.

*   [engcang/FAST-LIO-SAM](https://github.com/engcang/FAST-LIO-SAM) - a SLAM implementation combining FAST-LIO2 with pose graph optimization and loop closing based on LIO-SAM paper

*   [smilefacehh/LIO-SAM-DetailedNote](https://github.com/smilefacehh/LIO-SAM-DetailedNote) - LIO-SAMÊ∫êÁ†ÅËØ¶ÁªÜÊ≥®ÈáäÔºå3D SLAMËûçÂêàÊøÄÂÖâ„ÄÅIMU„ÄÅGPS

*   [deepseek-ai/FlashMLA](https://github.com/deepseek-ai/FlashMLA) - FlashMLA: Efficient MLA decoding kernels

*   [78/xiaozhi-esp32](https://github.com/78/xiaozhi-esp32) - Build your own AI friend

*   [brucezhcw/VINS-Explorer](https://github.com/brucezhcw/VINS-Explorer) - A Robust and Versatile Monocular Visual-Inertial State Estimator

*   [fishmarch/ORB-SLAM3-Dense](https://github.com/fishmarch/ORB-SLAM3-Dense) -

*   [fishmarch/ORB\_SLAM3\_Fixed](https://github.com/fishmarch/ORB_SLAM3_Fixed) - Fixed some bugs of original ORB\_SLAM3

*   [mp3guy/ElasticFusion](https://github.com/mp3guy/ElasticFusion) - Real-time dense visual SLAM system

*   [ethz-asl/maplab](https://github.com/ethz-asl/maplab) - A Modular and Multi-Modal Mapping Framework

*   [MIT-SPARK/Spatial-Hash](https://github.com/MIT-SPARK/Spatial-Hash) - Minimal C++ library for spatial data structures based on voxel-block-hashing

*   [MIT-SPARK/Khronos](https://github.com/MIT-SPARK/Khronos) - Spatio-Temporal Metric-Semantic SLAM

*   [shichaoy/cube\_slam](https://github.com/shichaoy/cube_slam) - CubeSLAM: Monocular 3D Object Detection and SLAM

*   [smartroboticslab/GSFusion](https://github.com/smartroboticslab/GSFusion) - GSFusion: Online RGB-D Mapping Where Gaussian Splatting Meets TSDF Fusion

*   [shg8/3DGS.cpp](https://github.com/shg8/3DGS.cpp) -  A cross-platform, high performance renderer for Gaussian Splatting using Vulkan Compute. Supports Windows, Linux, macOS, iOS, and visionOS

*   [hyperlogic/splatapult](https://github.com/hyperlogic/splatapult) - A 3d gaussian splatting renderer in C++ and OpenGL

*   [MIT-SPARK/Kimera-VIO](https://github.com/MIT-SPARK/Kimera-VIO) - Visual Inertial Odometry with SLAM capabilities and 3D Mesh generation.

*   [colmap/colmap](https://github.com/colmap/colmap) - COLMAP - Structure-from-Motion and Multi-View Stereo

*   [HKUST-Aerial-Robotics/G3Reg](https://github.com/HKUST-Aerial-Robotics/G3Reg) - A fast and robust global registration library for outdoor LiDAR point clouds.

*   [hku-mars/FAST-LIVO](https://github.com/hku-mars/FAST-LIVO) - A Fast and Tightly-coupled Sparse-Direct LiDAR-Inertial-Visual Odometry (LIVO).

*   [jedeschaud/ct\_icp](https://github.com/jedeschaud/ct_icp) - CT-ICP: Continuous-Time LiDAR Odometry

*   [hku-mars/r3live](https://github.com/hku-mars/r3live) - A Robust, Real-time, RGB-colored, LiDAR-Inertial-Visual tightly-coupled state Estimation and mapping package

*   [gisbi-kim/SC-LIO-SAM](https://github.com/gisbi-kim/SC-LIO-SAM) - LiDAR-inertial SLAM: Scan Context + LIO-SAM

*   [lovelyyoshino/FAST\_LIO2\_Noted](https://github.com/lovelyyoshino/FAST_LIO2_Noted) - FAST\_LIO2\_Noted ‰∏≠ÊñáÊ≥®ÈáäÁâà

*   [luohongk/SuperVINS](https://github.com/luohongk/SuperVINS) - A real-time visual-inertial SLAM framework for challenging imaging conditions (integrated deep learning features)

*   [linyicheng1/ceres-example](https://github.com/linyicheng1/ceres-example) - some ceres examples with notes

*   [XRIM-Lab/GS-CPR](https://github.com/XRIM-Lab/GS-CPR) - \[ICLR 2025] Official repo of "GS-CPR: Efficient Camera Pose Refinement via 3D Gaussian Splatting"

*   [PJLab-ADG/SensorsCalibration](https://github.com/PJLab-ADG/SensorsCalibration) - OpenCalib: A Multi-sensor Calibration Toolbox for Autonomous Driving

*   [IF-A-CAT/LIR-LIVO](https://github.com/IF-A-CAT/LIR-LIVO) - LIR-LIVO: A Lightweight,Robust Lidar/Vision/Inertial Odometry with Illumination-Resilient Deep Features

*   [cvg/limap](https://github.com/cvg/limap) - A toolbox for mapping and localization with line features.

*   [PJLab-ADG/Livox-Mapping](https://github.com/PJLab-ADG/Livox-Mapping) - An all-in-one and ready-to-use LiDAR-inertial odometry system for Livox LiDAR

*   [ROBOT-WSC/BEV-LSLAM](https://github.com/ROBOT-WSC/BEV-LSLAM) - BEV-LSLAM: A Novel and Compact BEV LiDAR SLAM for Outdoor Environment

*   [YungeCui/BoW3D](https://github.com/YungeCui/BoW3D) - \[RA-L] BoW3D: Bag of Words for Real-Time Loop Closing in 3D LiDAR SLAM.

*   [hku-mars/SUPER](https://github.com/hku-mars/SUPER) -

*   [sdwyc/ROLO](https://github.com/sdwyc/ROLO) - This is a ROS package for lidar odometry implementation using rotation optimization method.

*   [liquorleaf/OmniGS](https://github.com/liquorleaf/OmniGS) - \[WACV 2025] OmniGS: Fast Radiance Field Reconstruction using Omnidirectional Gaussian Splatting

*   [johannes-graeter/limo](https://github.com/johannes-graeter/limo) - Lidar-Monocular Visual Odometry

*   [HKUST-Aerial-Robotics/ESVO](https://github.com/HKUST-Aerial-Robotics/ESVO) - This repository maintains the implementation of "Event-based Stereo Visual Odometry".

*   [strasdat/Sophus](https://github.com/strasdat/Sophus) - C++ implementation of Lie Groups using Eigen.

*   [YWL0720/YOLO\_ORB\_SLAM3](https://github.com/YWL0720/YOLO_ORB_SLAM3) - This is an improved version of ORB-SLAM3 that adds an object detection module implemented with YOLOv5 to achieve SLAM in dynamic environments.

*   [ACFR-RPG/DynOSAM](https://github.com/ACFR-RPG/DynOSAM) - Offical code release for DynoSAM: Dynamic Object Smoothing And Mapping \[Submitted TRO Visual SLAM SI]. A visual SLAM framework and pipeline for Dynamic environements, estimating for the motion/pose of objects and their structure, as well as the camera odometry and static map.

*   [suchetanrs/ORB-SLAM3-ROS2-Docker](https://github.com/suchetanrs/ORB-SLAM3-ROS2-Docker) - This repository contains a full wrapper class for running ORB-SLAM3 on a docker container with ROS2 Humble with Ubuntu 22.04.

*   [introlab/rtabmap](https://github.com/introlab/rtabmap) - RTAB-Map library and standalone application

*   [hku-mars/FAST\_LIO](https://github.com/hku-mars/FAST_LIO) - A computationally efficient and robust LiDAR-inertial odometry (LIO) package

*   [YibinWu/LIO-EKF](https://github.com/YibinWu/LIO-EKF) - Maybe the simplest LiDAR-inertial odometry that one can have.

*   [lpercc/HA3D\_simulator](https://github.com/lpercc/HA3D_simulator) - Official implementation of Human-Aware Vision-and-Language Navigation: Bridging Simulation to Reality with Dynamic Human Interactions (NeurIPS DB Track'24 Spotlight).

*   [google/minja](https://github.com/google/minja) - A minimalistic C++ Jinja templating engine for LLM chat templates

*   [Unsigned-Long/eKalibr](https://github.com/Unsigned-Long/eKalibr) - eKalibr: Event Camera Calibration Framework

*   [onnx/onnx-tensorrt](https://github.com/onnx/onnx-tensorrt) - ONNX-TensorRT: TensorRT backend for ONNX

*   [tqdm/tqdm.cpp](https://github.com/tqdm/tqdm.cpp) - C++ port of tqdm

*   [ethz-asl/lidar\_align](https://github.com/ethz-asl/lidar_align) - A simple method for finding the extrinsic calibration between a 3D lidar and a 6-dof pose sensor

*   [alexhua/Aria2-Manager](https://github.com/alexhua/Aria2-Manager) - A useful tool to run Aria2 in the background easily

*   [MrNeRF/Light\_Glue\_CPP](https://github.com/MrNeRF/Light_Glue_CPP) - CPP Implementation of "LightGlue: Local Feature Matching at Light Speed"

*   [HKUST-Aerial-Robotics/RIO](https://github.com/HKUST-Aerial-Robotics/RIO) - Optimization Based and Point Uncertainty Aware Radar-inertial Odometry for 4D Radar System

*   [OctoMap/octomap\_msgs](https://github.com/OctoMap/octomap_msgs) - ROS package to provide messages and serializations / conversion for the OctoMap library

*   [pierotofy/OpenSplat](https://github.com/pierotofy/OpenSplat) - Production-grade 3D gaussian splatting with CPU/GPU support for Windows, Mac and Linux üöÄ

*   [SJTU-ViSYS/Ground-Fusion](https://github.com/SJTU-ViSYS/Ground-Fusion) - Ground-Fusion: A Low-cost Ground SLAM System Robust to Corner Cases (ICRA2024)

*   [tum-vision/dvo\_slam](https://github.com/tum-vision/dvo_slam) - Dense Visual Odometry and SLAM

*   [Zhefan-Xu/time\_optimizer](https://github.com/Zhefan-Xu/time_optimizer) - \[IEEE ICRA'24] Optimal Trajectory Time Allocation Library for Autonomous Robots (C++/ROS)

*   [UnknownFreeOccupied/ufomap](https://github.com/UnknownFreeOccupied/ufomap) - UFOMap: An Efficient Probabilistic 3D Mapping Framework That Embraces the Unknown

*   [lturing/ORB\_SLAM3\_ROS](https://github.com/lturing/ORB_SLAM3_ROS) -

*   [lturing/vins\_fusion\_pangolin](https://github.com/lturing/vins_fusion_pangolin) -

*   [unitreerobotics/point\_lio\_unilidar](https://github.com/unitreerobotics/point_lio_unilidar) - Point-LIO algorithm for Unitree LiDAR products.

*   [hku-mars/IKFoM](https://github.com/hku-mars/IKFoM) - A computationally efficient and convenient toolkit of iterated Kalman filter.

*   [facebookresearch/Replica-Dataset](https://github.com/facebookresearch/Replica-Dataset) - The Replica Dataset v1 as published in https://arxiv.org/abs/1906.05797 .

*   [stereolabs/zed-sdk](https://github.com/stereolabs/zed-sdk) - ‚ö°Ô∏èThe spatial perception framework for rapidly building smart robots and spaces

*   [stereolabs/zed-ros-wrapper](https://github.com/stereolabs/zed-ros-wrapper) - ROS wrapper for the ZED SDK

*   [hku-mars/ikd-Tree](https://github.com/hku-mars/ikd-Tree) - This repository provides implementation of an incremental k-d tree for robotic applications.

*   [triple-Mu/YOLOv8-TensorRT](https://github.com/triple-Mu/YOLOv8-TensorRT) - YOLOv8 using TensorRT accelerate !

*   [Glencsa/YOLOv8-ORB-SLAM3](https://github.com/Glencsa/YOLOv8-ORB-SLAM3) - YOLOv8-ORB-SLAM3: Semantic SLAM with dynamic feature point removal

*   [YWL0720/I2EKF-LO](https://github.com/YWL0720/I2EKF-LO) - \[IROS 2024] I2EKF-LO: A Dual-Iteration Extended Kalman Filter based  LiDAR Odometry

*   [arclab-hku/Event\_based\_VO-VIO-SLAM](https://github.com/arclab-hku/Event_based_VO-VIO-SLAM) - HKU-Dataset for Event-based VO/VIO/SLAM

*   [LeonardoDiCaprio1/Map\_ORBSLAM\_ROS](https://github.com/LeonardoDiCaprio1/Map_ORBSLAM_ROS) - You can densely map datasets through RVIZ and create your own TUM dataset to create maps

*   [qdLMF/VINS-Fusion-GPU-BA](https://github.com/qdLMF/VINS-Fusion-GPU-BA) - A CUDA reimplementation of Bundle Adjustment for VINS-Fusion

*   [halismai/photobundle](https://github.com/halismai/photobundle) - Photometric Bundle Adjustment for Vision-Based SLAM

*   [NKU-MobFly-Robotics/LRAE](https://github.com/NKU-MobFly-Robotics/LRAE) - LRAE: Large-Region-Aware Safe and Fast Autonomous Exploration of Ground Robots for Uneven Terrains, RA-L, 2024

*   [TUMFTM/ORB\_SLAM3\_RGBL](https://github.com/TUMFTM/ORB_SLAM3_RGBL) - RGB-L: An Extension to Integrate LiDAR Data into ORB-SLAM3

*   [ZJU-FAST-Lab/ego-planner](https://github.com/ZJU-FAST-Lab/ego-planner) -

*   [HKUST-Aerial-Robotics/FM-Fusion](https://github.com/HKUST-Aerial-Robotics/FM-Fusion) - \[RA-L] FM-Fusion: Instance-aware Semantic Mapping Boosted by Vision-Language Foundation Models

*   [GDUT-Kyle/faster\_lio\_sam](https://github.com/GDUT-Kyle/faster_lio_sam) - FASTER-LIO-SAM: A SLAM system based on iVox and GTSAM.

*   [NAIL-HNU/ESVO2](https://github.com/NAIL-HNU/ESVO2) -

*   [Taeyoung96/GRIL-Calib](https://github.com/Taeyoung96/GRIL-Calib) - \[RA-L 2024] GRIL-Calib: Targetless Ground Robot IMU-LiDAR Extrinsic Calibration Method using Ground Plane Motion Constraints

*   [Yaepiii/C-LOAM](https://github.com/Yaepiii/C-LOAM) - A Compact LiDAR Odometry and Mapping with Dynamic Removal \[ICUS 2024]

*   [Yaepiii/TRLO](https://github.com/Yaepiii/TRLO) -

*   [Unsigned-Long/Useful-Functions](https://github.com/Unsigned-Long/Useful-Functions) - Give it a try! Try and die!

*   [Unsigned-Long/slam-tricks](https://github.com/Unsigned-Long/slam-tricks) - small, powerful and beautiful slam tricks with theory and practice

*   [farhad-dalirani/StereoVision-SLAM](https://github.com/farhad-dalirani/StereoVision-SLAM) - StereoVision-SLAM is a real-time visual stereo SLAM (Simultaneous Localization and Mapping)

*   [gaoxiang12/faster-lio](https://github.com/gaoxiang12/faster-lio) - Faster-LIO: Lightweight Tightly Coupled Lidar-inertial Odometry using Parallel Sparse Incremental Voxels

*   [NVIDIA/TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) - TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.

*   [microsoft/BitNet](https://github.com/microsoft/BitNet) - Official inference framework for 1-bit LLMs

*   [Geekgineer/CloudPeek](https://github.com/Geekgineer/CloudPeek) - CloudPeek is a lightweight, cross-platform, single-header C++ point cloud viewer. It‚Äôs designed for simplicity and efficiency, requiring no heavy libraries like PCL or Open3D. Ideal for visualizing and interacting with 3D data from LiDAR, photogrammetry, or other datasets, CloudPeek delivers powerful, real-time exploration in a minimalistic package

*   [zhuge2333/4DRadarSLAM](https://github.com/zhuge2333/4DRadarSLAM) -

*   [rubengooj/pl-slam](https://github.com/rubengooj/pl-slam) - This code contains an algorithm to compute stereo visual SLAM by using both point and line segment features.

*   [DapengFeng/cartgs](https://github.com/DapengFeng/cartgs) - \[RA-L] CaRtGS: Computational Alignment for Real-Time Gaussian Splatting SLAM

*   [hku-mars/LAMM](https://github.com/hku-mars/LAMM) -

*   [alsora/ros2-ORB\_SLAM2](https://github.com/alsora/ros2-ORB_SLAM2) - ROS2 node wrapping the ORB\_SLAM2 library

*   [GREAT-WHU/RoadLib](https://github.com/GREAT-WHU/RoadLib) - A lightweight library for instance-level visual road marking extraction, parameterization, mapping, etc.

*   [TohsakaZ/ppp\_ex](https://github.com/TohsakaZ/ppp_ex) - Prise Point Positioning Experiment

*   [hku-mars/Voxel-SLAM](https://github.com/hku-mars/Voxel-SLAM) -

*   [ChaoqinRobotics/LINS---LiDAR-inertial-SLAM](https://github.com/ChaoqinRobotics/LINS---LiDAR-inertial-SLAM) - A Lidar-Inertial State Estimator for Robust and Efficient Navigation based on iterated error-state Kalman filter

*   [udaysankar01/xfeatSLAM](https://github.com/udaysankar01/xfeatSLAM) - Real-time SLAM with deep features (XFeat + ORB-SLAM3)

*   [yanyan-li/Structure-SLAM-PointLine](https://github.com/yanyan-li/Structure-SLAM-PointLine) - This is a basic point-line SLAM system based on ORBSLAM2.

*   [APRIL-ZJU/lidar\_IMU\_calib](https://github.com/APRIL-ZJU/lidar_IMU_calib) - \[IROS 2020] Targetless Calibration of LiDAR-IMU System Based on Continuous-time Batch Estimation

*   [ashishkumar822/Jetson-SLAM](https://github.com/ashishkumar822/Jetson-SLAM) - A high Speed GPU accelerated SLAM for Low Powered Devices, IEEE- RAL-2023, ICRA 2024

*   [alejandrofontan/AnyFeature-VSLAM](https://github.com/alejandrofontan/AnyFeature-VSLAM) - Any-Feature V-SLAM is an automated visual SLAM library for Monocular cameras capable of switching to a chosen type of feature effortlessly and without manual intervention.

*   [fishmarch/MS-SLAM](https://github.com/fishmarch/MS-SLAM) - \[JFR 2024] This is the official implementation of MS-SLAM, a memory-efficient visual SLAM system removing redundant map points to save memory consumption.

*   [2013fangwentao/Multi\_Sensor\_Fusion](https://github.com/2013fangwentao/Multi_Sensor_Fusion) - Multi-Sensor Fusion (GNSS, IMU, Camera) Â§öÊ∫êÂ§ö‰º†ÊÑüÂô®ËûçÂêàÂÆö‰Ωç GPS/INSÁªÑÂêàÂØºËà™  PPP/INSÁ¥ßÁªÑÂêà

*   [ethz-asl/kalibr](https://github.com/ethz-asl/kalibr) - The Kalibr visual-inertial calibration toolbox

*   [LuoXubo/JointLoc](https://github.com/LuoXubo/JointLoc) - \[IROS 2024] JointLoc: A Real-time Visual Localization Framework for Planetary UAVs Based on Joint Relative and Absolute Pose Estimation

*   [ethz-asl/okvis](https://github.com/ethz-asl/okvis) - OKVIS: Open Keyframe-based Visual-Inertial SLAM.

*   [jimazeyu/GraspSplats](https://github.com/jimazeyu/GraspSplats) - GraspSplats: Efficient Manipulation with 3D Feature Splatting

*   [smartroboticslab/okvis2](https://github.com/smartroboticslab/okvis2) - Open Keyframe-based Visual-Inertial SLAM (Version 2)

*   [HViktorTsoi/FAST\_LIO\_LOCALIZATION](https://github.com/HViktorTsoi/FAST_LIO_LOCALIZATION) - A simple localization framework that can re-localize in built maps based on FAST-LIO.

*   [GREAT-WHU/GREAT-PVT](https://github.com/GREAT-WHU/GREAT-PVT) -

*   [mengkai98/BA\_Play](https://github.com/mengkai98/BA_Play) - ÈöèÊâãÂÜô‰∏™BAÁé©Áé©

*   [Yixin-F/LiLoc](https://github.com/Yixin-F/LiLoc) - (ICRA 2025) LiLoc: Lifelong Localization using Adaptive Submap Joining and Egocentric Factor Graph

*   [Yixin-F/better\_fastlio2](https://github.com/Yixin-F/better_fastlio2) - Postgraduate Thesis: fast\_lio\_sam + dynamic removal (T-GRS 2024) + multi-session mapping (ICRA 2022 Kim) + object-level update + online relocalization (ICRA 2025) + real-world application (MD-LVIO)

*   [udaysankar01/xfeat\_cpp](https://github.com/udaysankar01/xfeat_cpp) - The C++ Implementation of XFeat (Accelerated Features).

*   [chengwei0427/ct-lio](https://github.com/chengwei0427/ct-lio) - CT-LIO: Continuous-Time LiDAR-Inertial Odometry

*   [felixendres/rgbdslam\_v2](https://github.com/felixendres/rgbdslam_v2) - RGB-D SLAM for ROS

*   [Eliaul/Eq-LIO](https://github.com/Eliaul/Eq-LIO) - A tightly coupled LIO framework based on the equivariant filter.

*   [HKUST-Aerial-Robotics/GVINS](https://github.com/HKUST-Aerial-Robotics/GVINS) - Tightly coupled GNSS-Visual-Inertial system for locally smooth and globally consistent state estimation in complex environment.

*   [HuajianUP/Photo-SLAM](https://github.com/HuajianUP/Photo-SLAM) - \[CVPR 2024] Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras

*   [HKUST-Aerial-Robotics/EPSILON](https://github.com/HKUST-Aerial-Robotics/EPSILON) -

*   [rmsalinas/DBow3](https://github.com/rmsalinas/DBow3) - Improved version of DBow2

*   [MigVega/SLAM2REF](https://github.com/MigVega/SLAM2REF) -  This project allows the  alignment and correction of LiDAR-based SLAM session data with a reference map or another session, also the retrieval of 6-DoF poses with accuracy of up to 3 cm given an accurate TLS point cloud as a reference map (this map should be accurate at least regarding the position of permanent elements such as walls and columns).

*   [lava/matplotlib-cpp](https://github.com/lava/matplotlib-cpp) - Extremely simple yet powerful header-only C++ plotting library built on the popular matplotlib

*   [kuankuan-yue/VINS-FUSION-leanrning](https://github.com/kuankuan-yue/VINS-FUSION-leanrning) - VINS-FUSION‰∏≠ÊñáÊ≥®ÈáäÁâà.ÁõÆÂâçÁΩëÁªú‰∏äÂØπ‰∫éVINS-monoÁöÑ‰ª£Á†ÅÂ∑≤ÁªèÊúâÂæàÂ§öËÆ≤Ëß£ÂíåÊ≥®Èáä‰∫ÜÔºå‰ΩÜÊòØÂØπ‰∫éVINS-FUSIONÔºà‰ª•‰∏ãÁÆÄÁß∞VFÔºâÁöÑÊ≥®ÈáäËøòÊòØÂæàÂ∞ëÁöÑÔºåÂàöÂ•ΩÊú¨‰∫∫ÊúÄËøë‰πüÊ≠£Âú®Â≠¶‰π†VIOÁöÑÁõ∏ÂÖ≥Áü•ËØÜÔºåÊâÄ‰ª•ÂØπVFÊåâÁÖßÁ®ãÂ∫èÊâßË°åÈ°∫Â∫èËøõË°å‰∫ÜÂçÅÂàÜËØ¶ÁªÜÁöÑÊ≥®ÈáäÔºåÂêåÊó∂‰∏∫‰∫ÜÂíåÂ§ßÂÆ∂ËøõË°å‰∫§ÊµÅÂ≠¶‰π†ÔºåÊâÄ‰ª•ÊääÁõ∏ÂÖ≥Ê≥®Èáä‰ª£Á†ÅËøõË°åÂºÄÊ∫ê„ÄÇÂõ†Ê∞¥Âπ≥ÊúâÈôêÔºåÈîôËØØËÇØÂÆö‰∏çÂ∞ëÔºåËøòËØ∑ÂêÑ‰ΩçÂ§ß‰Ω¨‰ª¨ÊåáÊ≠£„ÄÇ

*   [gtrll/gpslam](https://github.com/gtrll/gpslam) - Sparse Gaussian Processes for SLAM

*   [UZ-SLAMLab/ORB\_SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3) - ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM

*   [i3tyc/AdaptSLAM](https://github.com/i3tyc/AdaptSLAM) - AdaptSLAM: Edge-Assisted Adaptive SLAM with Resource Constraints via Uncertainty Minimization

*   [Zhefan-Xu/onboard\_detector](https://github.com/Zhefan-Xu/onboard_detector) - \[IEEE RA-L'24] Dynamic Obstacle Detection and Tracking (DODT) algorithm for Autonomous Robots (C++/ROS)

*   [nkliuhui/sync\_gps\_lidar\_imu\_cam](https://github.com/nkliuhui/sync_gps_lidar_imu_cam) - lidar-imu-cam-GPSÊó∂Èó¥Êà≥Á°¨‰ª∂ÂêåÊ≠•ÊñπÊ°à

*   [tum-vision/lsd\_slam](https://github.com/tum-vision/lsd_slam) - LSD-SLAM

*   [yutongwangBIT/GOReloc](https://github.com/yutongwangBIT/GOReloc) -

*   [HeYijia/VINS-Course](https://github.com/HeYijia/VINS-Course) - VINS-Mono code without Ceres or ROS

*   [SainingZhang/UC-GS](https://github.com/SainingZhang/UC-GS) - \[BMVC 2024] Drone-assisted Road Gaussian Splatting with Cross-view Uncertainty

*   [AndreasArendt/OpenRTK](https://github.com/AndreasArendt/OpenRTK) - Open Source precise GNSS Software

*   [PetWorm/LARVIO](https://github.com/PetWorm/LARVIO) - A lightweight, accurate and robust monocular visual inertial odometry based on Multi-State Constraint Kalman Filter.

*   [ManiiXu/VINS-Mono-Learning](https://github.com/ManiiXu/VINS-Mono-Learning) - VINS-Mono‰ª£Á†ÅÊ≥®ÈáäÔºå‰ªÖ‰æõÂ≠¶‰π†

*   [sair-lab/AirSLAM](https://github.com/sair-lab/AirSLAM) - üöÄ AirVO upgrades to AirSLAM \[TRO]üöÄ

*   [city-super/Octree-GS](https://github.com/city-super/Octree-GS) - Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians

*   [CG050523/PPP-Navigation](https://github.com/CG050523/PPP-Navigation) - ‰º™Ë∑ùÂçïÁÇπÂÆö‰ΩçÁ®ãÂ∫èÂÆûÁé∞Ôºå‰ªÖÂ≠¶‰π†‰ΩøÁî®

*   [Alex-Beh/yolov5\_ros](https://github.com/Alex-Beh/yolov5_ros) -

*   [VIS4ROB-lab/ccm\_slam](https://github.com/VIS4ROB-lab/ccm_slam) - CCM-SLAM: Robust and Efficient Centralized Collaborative Monocular SLAM for Robotic Teams

*   [microsoft/Azure-Kinect-Sensor-SDK](https://github.com/microsoft/Azure-Kinect-Sensor-SDK) - A cross platform (Linux and Windows) user mode SDK to read data from your Azure Kinect device.

*   [hku-mars/FAST-LIVO2](https://github.com/hku-mars/FAST-LIVO2) - FAST-LIVO2: Fast, Direct LiDAR-Inertial-Visual Odometry

*   [yanyan-li/PlanarSLAM](https://github.com/yanyan-li/PlanarSLAM) - A RGB-D SLAM system for structural scenes, which makes use of point-line-plane features and the Manhattan World assumption.

*   [STAR-Center/VINS-RGBD](https://github.com/STAR-Center/VINS-RGBD) -

*   [TixiaoShan/LIO-SAM](https://github.com/TixiaoShan/LIO-SAM) - LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping

*   [TixiaoShan/LVI-SAM](https://github.com/TixiaoShan/LVI-SAM) - LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping

*   [danping/CoSLAM](https://github.com/danping/CoSLAM) - CoSLAM is a visual SLAM software that aims to use multiple freely moving cameras to simultaneously compute their egomotion and the 3D map of the surrounding scenes in a highly dynamic environment.

*   [google/or-tools](https://github.com/google/or-tools) - Google's Operations Research tools:

*   [JakobEngel/dso](https://github.com/JakobEngel/dso) - Direct Sparse Odometry

*   [AnswerDotAI/gpu.cpp](https://github.com/AnswerDotAI/gpu.cpp) - A lightweight library for portable low-level GPU computation using WebGPU.

*   [ethz-asl/wavemap](https://github.com/ethz-asl/wavemap) - Fast, efficient and accurate multi-resolution, multi-sensor 3D occupancy mapping

*   [RonaldSun/VI-Stereo-DSO](https://github.com/RonaldSun/VI-Stereo-DSO) - Direct sparse odometry combined with stereo cameras and IMU

*   [GREAT-WHU/iKalibr](https://github.com/GREAT-WHU/iKalibr) -

*   [MIT-SPARK/Kimera-RPGO](https://github.com/MIT-SPARK/Kimera-RPGO) - Robust Pose Graph Optimization

*   [lian-yue0515/MM-LINS](https://github.com/lian-yue0515/MM-LINS) - a Multi-Map LiDAR-Inertial System for Over-Degraded Environments

*   [engcang/vins-application](https://github.com/engcang/vins-application) - VINS-Fusion, VINS-Fisheye, OpenVINS, EnVIO, ROVIO, S-MSCKF, ORB-SLAM2, NVIDIA Elbrus application of different sets of cameras and imu on different board including desktop and Jetson boards

*   [floatlazer/semantic\_slam](https://github.com/floatlazer/semantic_slam) - Real time semantic slam in ROS with a hand held RGB-D camera

*   [koide3/gtsam\_points](https://github.com/koide3/gtsam_points) - A collection of GTSAM factors and optimizers for point cloud SLAM

*   [BaowenZ/RaDe-GS](https://github.com/BaowenZ/RaDe-GS) - RaDe-GS: Rasterizing Depth in Gaussian Splatting

*   [Unsigned-Long/iKalibr](https://github.com/Unsigned-Long/iKalibr) - \[IEEE T-RO 2025] iKalibr: Multi-Sensor Calibration (Extrinsics & Time Offsets)

*   [emiliofidalgo/ibow-lcd](https://github.com/emiliofidalgo/ibow-lcd) - Appearance-based Loop Closure Detection using Incremental Bags of Binary Words

*   [bxh1/VIDO-SLAM](https://github.com/bxh1/VIDO-SLAM) - VIDO-SLAM is a  Visual Inertial SLAM system for dynamic environments, and it can  also estimate dynamic objects motion and track objects.

*   [url-kaist/dynaVINS](https://github.com/url-kaist/dynaVINS) - DynaVINS : A Visual-Inertial SLAM for Dynamic Environments

*   [MAVIS-SLAM/OpenMAVIS](https://github.com/MAVIS-SLAM/OpenMAVIS) - An open-source implementation of MAVIS-SLAM.

*   [linyicheng1/OpenSLAM-Notes](https://github.com/linyicheng1/OpenSLAM-Notes) - ‰∏™‰∫∫ÂØπÁõÆÂâçËæÉ‰∏∫ÊàêÁÜüÁöÑËßÜËßâ/ÊøÄÂÖâSLAMÁÆóÊ≥ïËøõË°åÁöÑÊ≥®Èáä‰ª•ÂèäËß£ËØªÊñá‰ª∂

## miscellaneous

*   [YOUNG-bit/open\_semantic\_slam](https://github.com/YOUNG-bit/open_semantic_slam) - ICRA2025: OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding

*   [liw95/LightLoc](https://github.com/liw95/LightLoc) - \[CVPR2025] LightLoc: Learning Outdoor LiDAR Localization at Light Speed

*   [HKUST-Aerial-Robotics/SG-Reg](https://github.com/HKUST-Aerial-Robotics/SG-Reg) - \[T-RO under review] SG-Reg: Generalizable and Efficient Scene Graph Registration

*   [PetWorm/IMU-Preintegration-Propogation-Doc](https://github.com/PetWorm/IMU-Preintegration-Propogation-Doc) - ‰∏≠ÊñáÊñáÊ°£ÔºöIMUÈ¢ÑÁßØÂàÜÊÄªÁªì‰∏éÂÖ¨ÂºèÊé®ÂØº

*   [GeLuzhou/Dynamic-GSG](https://github.com/GeLuzhou/Dynamic-GSG) - Dynamic 3D Gaussian Scene Graphs or Environment Adaptation

*   [HKUST-Aerial-Robotics/GS-LIVO](https://github.com/HKUST-Aerial-Robotics/GS-LIVO) -

*   [MIT-SPARK/Kimera](https://github.com/MIT-SPARK/Kimera) - Index repo for Kimera code

*   [AdrianWilczynski/OneDarkPro](https://github.com/AdrianWilczynski/OneDarkPro) - "One Dark Pro" theme for Visual Studio generated using Alexander Teinum's "Dainty for Visual Studio", saved with "Visual Studio Color Theme Designer" and tweaked to closer match Binaryify's "One Dark Pro" theme for Visual Studio Code.

*   [szx-0633/DeepSeek-R1-learning-note](https://github.com/szx-0633/DeepSeek-R1-learning-note) - My learning note about DeepSeek-R1 reasoning LLM

*   [John19187/v2ray-SSR-Clash-Verge-Shadowrocke](https://github.com/John19187/v2ray-SSR-Clash-Verge-Shadowrocke) - 2025Âπ¥3Êúà-ÂÖçË¥πÈ´òÈÄüÔºà23.5M/SÔºâv2ray„ÄÅsing-box„ÄÅClash„ÄÅVerge„ÄÅSSR„ÄÅShadowrocke-Â∞èÁÅ´ÁÆ≠Êú∫Âú∫ËäÇÁÇπËÆ¢ÈòÖÊåáÂçó

*   [Lee-JaeWon/2024-Arxiv-Paper-List-Gaussian-Splatting](https://github.com/Lee-JaeWon/2024-Arxiv-Paper-List-Gaussian-Splatting) - 2024 Gaussian Splatting Paper List(Arxiv)

*   [StarCycle/Awesome-Embodied-AI-Job](https://github.com/StarCycle/Awesome-Embodied-AI-Job) - DeepTimberÁ§æÂå∫ÂÖ∑Ë∫´Êô∫ËÉΩÊãõË¥§Ê¶ú | A list for Embodied AI / Robotics Jobs (PhD, RA, intern, full-time, etc

*   [Pawdroid/Free-servers](https://github.com/Pawdroid/Free-servers) - üöÄ ÂÖçË¥πËÆ¢ÈòÖÂú∞ÂùÄÔºåüöÄ ÂÖçË¥πËäÇÁÇπÔºåüöÄ 6Â∞èÊó∂Êõ¥Êñ∞‰∏ÄÊ¨°ÔºåÂÖ±‰∫´ËäÇÁÇπÔºåËäÇÁÇπË¥®ÈáèÈ´òÂèØÁî®ÔºåÂÆåÂÖ®ÂÖçË¥π„ÄÇÂÖçË¥πclashËÆ¢ÈòÖÂú∞ÂùÄÔºåÂÖçË¥πÁøªÂ¢ô„ÄÅÂÖçË¥πÁßëÂ≠¶‰∏äÁΩë„ÄÅÂÖçË¥πÊ¢ØÂ≠ê„ÄÅÂÖçË¥πss/v2ray/trojanËäÇÁÇπ„ÄÅË∞∑Ê≠åÂïÜÂ∫ó„ÄÅÁøªÂ¢ôÊ¢ØÂ≠ê„ÄÇüöÄ Free subscription address, üöÄ Free node, üöÄ Updated every 6 hours, shared node, high-quality node availability, completely free. Free clash subscription address, free ss/v2ray/trojan node.

*   [getActivity/EmojiPackage](https://github.com/getActivity/EmojiPackage) - Ë°®ÊÉÖÂåÖËµÑÊ∫êÂêàÈõÜÔºåÂº†Âº†ÈÉΩÊòØÁªèÂÖ∏

*   [fudan-zvg/DG-SLAM](https://github.com/fudan-zvg/DG-SLAM) - \[NeurIPS 2024] DG-SLAM: Robust Dynamic Gaussian Splatting SLAM with Hybrid Pose Optimization

*   [BestJunYu/Awesome-Physics-aware-Generation](https://github.com/BestJunYu/Awesome-Physics-aware-Generation) - Physical laws underpin all existence, and harnessing them for generative modeling opens boundless possibilities for advancing science and shaping the future!

*   [deepseek-ai/awesome-deepseek-integration](https://github.com/deepseek-ai/awesome-deepseek-integration) - Integrate the DeepSeek API into popular softwares

*   [LongHZ140516/awesome-framework-gallery](https://github.com/LongHZ140516/awesome-framework-gallery) - Awesome lists about framework figures in papers

*   [deepseek-ai/DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1) -

*   [shinyypig/latex-vscode-config](https://github.com/shinyypig/latex-vscode-config) - Use LaTeX in VSCode.

*   [cheryyunl/awesome-generalist-agents](https://github.com/cheryyunl/awesome-generalist-agents) - A curated list of papers for generalist agents

*   [jinyummiao/map-in-mono-reloc](https://github.com/jinyummiao/map-in-mono-reloc) - a paper list of visual re-localization algorithms

*   [Vincentqyw/Recent-Stars-2025](https://github.com/Vincentqyw/Recent-Stars-2025) - üî•SLAM, VIsual localization, keypoint detection, Image matching, Pose/Object tracking, Depth/Disparity/Flow Estimation, 3D-graphic, etc. related papers and code

*   [youngguncho/awesome-slam-datasets](https://github.com/youngguncho/awesome-slam-datasets) - A curated list of awesome datasets for SLAM

*   [zju3dv/MatchAnything](https://github.com/zju3dv/MatchAnything) - Code for "MatchAnything: Universal Cross-Modality Image Matching with Large-Scale Pre-Training", Arxiv 2025.

*   [GarlanLou/LF-GNSS](https://github.com/GarlanLou/LF-GNSS) - LF-GNSS: an open-sourced deep learning and Kalman filter integrated framework for satellite positioning.

*   [Hannibal046/Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM) - Awesome-LLM: a curated list of Large Language Model

*   [sirius1024/iterm2-with-oh-my-zsh](https://github.com/sirius1024/iterm2-with-oh-my-zsh) - iTerm2 + Oh My Zsh ÊâìÈÄ†ËàíÈÄÇÁªàÁ´Ø‰ΩìÈ™å

*   [dtc111111/awesome-3dgs-for-robotics](https://github.com/dtc111111/awesome-3dgs-for-robotics) -

*   [siyuanliii/SLAck](https://github.com/siyuanliii/SLAck) - Official Implementation of ECCV2024 paper: SLAck

*   [Active-SLAM/Active-SLAM-Paper-List](https://github.com/Active-SLAM/Active-SLAM-Paper-List) - This repository primarily organizes papers, code, and other relevant materials related to Active SLAM and Robotic Exploration.

*   [serhii-londar/open-source-mac-os-apps](https://github.com/serhii-londar/open-source-mac-os-apps) - üöÄ Awesome list of open source applications for macOS. https://t.me/s/opensourcemacosapps

*   [linyicheng1/Quaternion-Kinematics-for-the-Error-State-Kalman-Filter](https://github.com/linyicheng1/Quaternion-Kinematics-for-the-Error-State-Kalman-Filter) - Quaternion Kinematics for the Error-State Kalman Filter (‰∏≠ÊñáÂÖ®ÊñáÁøªËØë)

*   [SJTU-ViSYS/M2DGR-plus](https://github.com/SJTU-ViSYS/M2DGR-plus) - Extension and update of M2DGR: a novel Multi-modal and Multi-scenario SLAM Dataset for Ground Robots (ICRA2022 & ICRA2024)

*   [ZexinHe/Neural-LightRig](https://github.com/ZexinHe/Neural-LightRig) - Official code for Neural LightRig.

*   [noodle-lab/GaussianSpa](https://github.com/noodle-lab/GaussianSpa) - Project website: https://noodle-lab.github.io/gaussianspa/

*   [HKUST-Aerial-Robotics/OmniNxt](https://github.com/HKUST-Aerial-Robotics/OmniNxt) - \[IROS'24 Oral] A Fully Open-source and Compact Aerial Robot with Omnidirectional Visual Perception

*   [GeekLiB/Lee-SLAM-source](https://github.com/GeekLiB/Lee-SLAM-source) - SLAM ÂºÄÂèëÂ≠¶‰π†ËµÑÊ∫ê‰∏éÁªèÈ™åÂàÜ‰∫´

*   [uzh-rpg/event-based\_vision\_resources](https://github.com/uzh-rpg/event-based_vision_resources) - Event-based Vision Resources. Community effort to collect knowledge on event-based vision technology (papers, workshops, datasets, code, videos, etc)

*   [bkhanal-11/awesome-360-depth-estimation](https://github.com/bkhanal-11/awesome-360-depth-estimation) - State-of-the-art papers for depth estimation of 360 images.

*   [L3Y1Q2/MyBrain](https://github.com/L3Y1Q2/MyBrain) - Knowledge makes up the brain

*   [franciscoliu/Awesome-GenAI-Unlearning](https://github.com/franciscoliu/Awesome-GenAI-Unlearning) -

*   [wlxing1901/eroam](https://github.com/wlxing1901/eroam) -

*   [changh95/visual-slam-roadmap](https://github.com/changh95/visual-slam-roadmap) - Roadmap to become a Visual-SLAM developer in 2023

*   [kmk97/DGS-SLAM](https://github.com/kmk97/DGS-SLAM) -

*   [SJTU-ViSYS/M2DGR](https://github.com/SJTU-ViSYS/M2DGR) - M2DGRÔºö a Multi-modal and Multi-scenario Dataset for Ground Robots(RA-L2021 & ICRA2022)

*   [IntelliSensing/UAV-VisLoc](https://github.com/IntelliSensing/UAV-VisLoc) - UAV-VisLoc: A Large-scale Dataset for UAV Visual Localization

*   [luohongk/slam-handbook-chinese](https://github.com/luohongk/slam-handbook-chinese) - Êú¨È°πÁõÆ‰∏ªË¶ÅÊòØÂÖ≥‰∫éslam handbookÁöÑ‰∏≠ÊñáÁâàÊú¨

*   [SLAM-Handbook-contributors/slam-handbook-public-release](https://github.com/SLAM-Handbook-contributors/slam-handbook-public-release) - Release repo for our SLAM Handbook

*   [RipplePiam/MobaXterm-Chinese-Simplified](https://github.com/RipplePiam/MobaXterm-Chinese-Simplified) - MobaXterm ÁÆÄ‰Ωì‰∏≠ÊñáÊ±âÂåñÁâàüåèüñ•üñ•üñ• „ÄêüíåÊÖ¢Â∑•Á≤æÂøÉÂà∂‰ΩúÔºå"ÊèêÁ§∫"‰πüÊ±âÂåñüíª„Äë „ÄêüòçÊéß‰ª∂Â∏ÉÂ±ÄÁ≤æÁªÜË∞ÉÊï¥„Äë

*   [OpenDriveLab/End-to-end-Autonomous-Driving](https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving) - \[IEEE T-PAMI 2024] All you need for End-to-end Autonomous Driving

*   [xiliu8006/3DGS-Enhancer](https://github.com/xiliu8006/3DGS-Enhancer) -

*   [maziarraissi/Applied-Deep-Learning](https://github.com/maziarraissi/Applied-Deep-Learning) - Applied Deep Learning Course

*   [520xyxyzq/awesome-object-SLAM](https://github.com/520xyxyzq/awesome-object-SLAM) - A curated list of Object SLAM papers and resources

*   [HuaiyuanXu/3D-Occupancy-Perception](https://github.com/HuaiyuanXu/3D-Occupancy-Perception) - \[Information Fusion 2025] A Survey on Occupancy Perception for Autonomous Driving: The Information Fusion Perspective

*   [chicleee/Image-Matching-Paper-List](https://github.com/chicleee/Image-Matching-Paper-List) - A personal list of papers and resources of image matching and pose estimation, including perspective images and panoramas.

*   [sheng00125/LIV-GaussMap](https://github.com/sheng00125/LIV-GaussMap) -

*   [SilenceOverflow/Awesome-SLAM](https://github.com/SilenceOverflow/Awesome-SLAM) - A curated list of SLAM resources

*   [52CV/awesome-huggingface](https://github.com/52CV/awesome-huggingface) - ü§ó A list of wonderful open-source projects & applications integrated with Hugging Face libraries.

*   [HCPLab-SYSU/Embodied\_AI\_Paper\_List](https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List) - \[Embodied-AI-Survey-2024] Paper list and projects for Embodied AI

*   [JusticeFighterDance/JusticeFighter110](https://github.com/JusticeFighterDance/JusticeFighter110) - Áî∞ÊüØÂÆá (Tian Keyu)ÊÅ∂ÊÑèÊîªÂáªÈõÜÁæ§‰∫ã‰ª∂ÁöÑËØÅÊçÆÊè≠Èú≤

*   [william-sto/JusticeNeverTooLate](https://github.com/william-sto/JusticeNeverTooLate) - Â≠óËäÇË∑≥Âä®ÁìúÊúÄÁªàÁúüÂÆûÊÉÖÂÜµÔºåÁî®‰∫ãÂÆûËØ¥ËØùÔºåÊ≠£‰πâ‰ºöËøüÂà∞‰ΩÜ‰∏ç‰ºöÁº∫Â∏≠ÔºÅ

*   [RuijieZhu94/MotionGS](https://github.com/RuijieZhu94/MotionGS) - \[NeurIPS 2024] MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting

*   [amusi/CVPR2025-Papers-with-Code](https://github.com/amusi/CVPR2025-Papers-with-Code) - CVPR 2025 ËÆ∫ÊñáÂíåÂºÄÊ∫êÈ°πÁõÆÂêàÈõÜ

*   [zhuhu00/Awesome\_Dynamic\_SLAM](https://github.com/zhuhu00/Awesome_Dynamic_SLAM) - Dynamic SLAM, Life-long SLAM Research(Lidar, Visual, Sensor Fusion etc.)

*   [hongwenjun/tmux\_for\_windows](https://github.com/hongwenjun/tmux_for_windows) - tmuxÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÂ∑•ÂÖ∑ÔºåÁî®‰∫éÂú®‰∏Ä‰∏™ÁªàÁ´ØÁ™óÂè£‰∏≠ËøêË°åÂ§ö‰∏™ÁªàÁ´Ø‰ºöËØù„ÄÇÊú¨Â∑•ÂÖ∑‰ªémsys2ÈáåÊèêÂèñÔºåÂèØ‰ª•Âú®Git for WindowsÁöÑGit Bash (MingW64)‰∏ãÊ≠£Â∏∏‰ΩøÁî®„ÄÇ

*   [HumanAIGC/AnimateAnyone](https://github.com/HumanAIGC/AnimateAnyone) - Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation

*   [minwoo0611/HeLiOS](https://github.com/minwoo0611/HeLiOS) - Heterogeneous LiDAR Place Recognition

*   [Ji1Xingyu/SGBA](https://github.com/Ji1Xingyu/SGBA) -

*   [Open3DVLab/StreetSurfGS](https://github.com/Open3DVLab/StreetSurfGS) - StreetSurfGS: Scalable Large Scene Surface Reconstruction with Gaussian Splatting for Urban Street Scences

*   [QiZS-BIT/GSPR](https://github.com/QiZS-BIT/GSPR) - GSPR: Multimodal Place Recognition using 3D Gaussian Splatting for Autonomous Driving

*   [TianxingChen/Embodied-AI-Guide](https://github.com/TianxingChen/Embodied-AI-Guide) - ÂÖ∑Ë∫´Êô∫ËÉΩÂÖ•Èó®ÊåáÂçó Embodied-AI-Guide

*   [Open3DVLab/GigaGS](https://github.com/Open3DVLab/GigaGS) - GigaGS: Scaling up Planar-Based 3D Gaussians for Large Scene Surface Reconstruction

*   [Thinklab-SJTU/Awesome-LLM4AD](https://github.com/Thinklab-SJTU/Awesome-LLM4AD) - A curated list of awesome LLM for Autonomous Driving resources (continually updated)

*   [PeidongLi/SSR](https://github.com/PeidongLi/SSR) - \[ICLR 2025] The official implementation of SSR

*   [ai-vip/stable-diffusion-tutorial](https://github.com/ai-vip/stable-diffusion-tutorial) - ÂÖ®ÁΩëÊúÄÂÖ®Stable DiffusionÂÖ®Â•óÊïôÁ®ãÔºå‰ªéÂÖ•Èó®Âà∞ËøõÈò∂ÔºåËÄóÊó∂‰∏â‰∏™ÊúàÂà∂‰Ωú

*   [AlbertSlam/Lee-SLAM-source](https://github.com/AlbertSlam/Lee-SLAM-source) - SLAM ÂºÄÂèëÂ≠¶‰π†ËµÑÊ∫ê‰∏éÁªèÈ™åÂàÜ‰∫´

*   [YangSiri/OR-LIM](https://github.com/YangSiri/OR-LIM) - OR-LIM: Observability-aware robust LiDAR-Inertial-Mapping  under High Dynamic Sensor Motion

*   [DeepLabc/LargeScale\_3DGS](https://github.com/DeepLabc/LargeScale_3DGS) - 3D Gaussian Splatting Papers Relating to Large-Scale Scene.

*   [sjtuyinjie/awesome-LiDAR-Visual-SLAM](https://github.com/sjtuyinjie/awesome-LiDAR-Visual-SLAM) - A curated list of resources relevant to LiDAR-Visual-Fusion-SLAM

*   [perkfly/reverse-interview-zh](https://github.com/perkfly/reverse-interview-zh) - ÊäÄÊúØÈù¢ËØïÊúÄÂêéÂèçÈóÆÈù¢ËØïÂÆòÁöÑËØù

*   [kwea123/gaussian\_splatting\_notes](https://github.com/kwea123/gaussian_splatting_notes) - A detailed formulae explanation on gaussian splatting

*   [zju3dv/100-Phones](https://github.com/zju3dv/100-Phones) -

*   [623637646/996.Leave](https://github.com/623637646/996.Leave) - ÈÄÉÁ¶ª996

*   [Meltwin/Noetic-Ubuntu22.04](https://github.com/Meltwin/Noetic-Ubuntu22.04) - Manual instructions on how to install ROS1 Noetic on Ubuntu 22.04

*   [StevenCui/VIO-Doc](https://github.com/StevenCui/VIO-Doc) - ‰∏ªÊµÅVIOËÆ∫ÊñáÊé®ÂØºÂèä‰ª£Á†ÅËß£Êûê

*   [ericzzj1989/Awesome-Image-Matching](https://github.com/ericzzj1989/Awesome-Image-Matching) -

*   [miss-mumu/developer2gwy](https://github.com/miss-mumu/developer2gwy) - ÂÖ¨Âä°Âëò‰ªéÂÖ•Èó®Âà∞‰∏äÂ≤∏ÔºåÊúÄ‰Ω≥Á®ãÂ∫èÂëòÂÖ¨ËÄÉÂÆûË∑µÊïôÁ®ã

*   [meta-llama/llama-stack-apps](https://github.com/meta-llama/llama-stack-apps) - Agentic components of the Llama Stack APIs

*   [0voice/expert\_readed\_books](https://github.com/0voice/expert_readed_books) - 2021Âπ¥ÊúÄÊñ∞ÊÄªÁªìÔºåÊé®ËçêÂ∑•Á®ãÂ∏àÂêàÈÄÇËØªÊú¨ÔºåËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÔºåËΩØ‰ª∂ÊäÄÊúØÔºåÂàõ‰∏öÔºåÊÄùÊÉ≥Á±ªÔºåÊï∞Â≠¶Á±ªÔºå‰∫∫Áâ©‰º†ËÆ∞‰π¶Á±ç

*   [jianzongwu/Awesome-Open-Vocabulary](https://github.com/jianzongwu/Awesome-Open-Vocabulary) - (TPAMI 2024) A Survey on Open Vocabulary Learning

*   [lvchuandong/Awesome-Multi-Camera-3D-Occupancy-Prediction](https://github.com/lvchuandong/Awesome-Multi-Camera-3D-Occupancy-Prediction) - Awesome papers and code about Multi-Camera 3D Occupancy Prediction, such as TPVFormer, SurroundOcc, PanoOcc, OccFormer, FB-OCC, SelfOcc, COTR, SparseOcc, GaussianFormer, GaussianOcc. In this repository, you will see the latest 3D occupancy prediction papers and code.

*   [eriksandstroem/Splat-SLAM](https://github.com/eriksandstroem/Splat-SLAM) -

*   [bdvisl/DriveInsight](https://github.com/bdvisl/DriveInsight) -

*   [pubsys/ReviewSystem](https://github.com/pubsys/ReviewSystem) - ÂÆ°Á®øÁ≥ªÁªüÁöÑËá™Ëø∞

*   [weisongwen/UrbanNavDataset](https://github.com/weisongwen/UrbanNavDataset) - UrbanNav: an¬†Open-Sourcing Localization Data Collected in Asian Urban Canyons, Including Tokyo and Hong Kong

## JavaScript

*   [kishimisu/Gaussian-Splatting-WebGL](https://github.com/kishimisu/Gaussian-Splatting-WebGL) - 3D Gaussian Splatting Renderer for WebGL

*   [open-webui/open-webui](https://github.com/open-webui/open-webui) - User-friendly AI Interface (Supports Ollama, OpenAI API, ...)

*   [overleaf/overleaf](https://github.com/overleaf/overleaf) - A web-based collaborative LaTeX editor

*   [antimatter15/splat](https://github.com/antimatter15/splat) - WebGL 3D Gaussian Splat Viewer

*   [vernesong/OpenClash](https://github.com/vernesong/OpenClash) - A Clash Client For OpenWrt

*   [eliahuhorwitz/Academic-project-page-template](https://github.com/eliahuhorwitz/Academic-project-page-template) - A project page template for academic papers. Demo at https://eliahuhorwitz.github.io/Academic-project-page-template/

## Cuda

*   [qdLMF/LightGlue-with-FlashAttentionV2-TensorRT](https://github.com/qdLMF/LightGlue-with-FlashAttentionV2-TensorRT) - A cutlass cute  implementation of headdim-64 flashattentionv2 TensorRT plugin for LightGlue. Run on Jetson Orin NX 8GB with TensorRT 8.5.2.

*   [deepseek-ai/DeepGEMM](https://github.com/deepseek-ai/DeepGEMM) - DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling

*   [MarvinChung/Orbeez-SLAM](https://github.com/MarvinChung/Orbeez-SLAM) -

## Jupyter Notebook

*   [HandsOnLLM/Hands-On-Large-Language-Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models) - Official code repo for the O'Reilly Book - "Hands-On Large Language Models"

*   [CurryYuan/ZSVG3D](https://github.com/CurryYuan/ZSVG3D) - \[CVPR 2024] Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding

*   [robot-pesg/BotanicGarden](https://github.com/robot-pesg/BotanicGarden) - BotanicGarden: A high-quality dataset for robot navigation in unstructured natural environments

*   [QwenLM/Qwen2.5-VL](https://github.com/QwenLM/Qwen2.5-VL) - Qwen2.5-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.

*   [DjangoPeng/LLM-quickstart](https://github.com/DjangoPeng/LLM-quickstart) - Quick Start for Large Language Models (Theoretical Learning and Practical Fine-tuning) Â§ßËØ≠Ë®ÄÊ®°ÂûãÂø´ÈÄüÂÖ•Èó®ÔºàÁêÜËÆ∫Â≠¶‰π†‰∏éÂæÆË∞ÉÂÆûÊàòÔºâ

*   [zju3dv/LoFTR](https://github.com/zju3dv/LoFTR) - Code for "LoFTR: Detector-Free Local Feature Matching with Transformers", CVPR 2021, T-PAMI 2022

*   [hesamsheikh/ml-retreat](https://github.com/hesamsheikh/ml-retreat) - Machine Learning Journal for Intermediate to Advanced Topics.

*   [DataExpert-io/data-engineer-handbook](https://github.com/DataExpert-io/data-engineer-handbook) - This is a repo with links to everything you'd ever want to learn about data engineering

*   [whu-huangyue/HZAU\_HuangYue\_JianMo](https://github.com/whu-huangyue/HZAU_HuangYue_JianMo) - Êú¨ÁßëHZAUÔºåÂõΩËµõÁúÅ‰∏ÄÁúÅ‰∫åÔºà‰∫åÊ¨°ÔºâÔºå‰∫öÂ§™ËµõÔºà‰∏ÄÁ≠âÂ•ñÔºâÔºåÂ∞èÁæéËµõÔºàMÂ•ñÔºâÁ≠âÁ≠âÁ≠â

*   [florinshen/FlashSplat](https://github.com/florinshen/FlashSplat) - \[ECCV2024] FlashSplat: 2D to 3D Gaussian Splatting Segmentation Solved Optimally

*   [yzslab/gaussian-splatting-lightning](https://github.com/yzslab/gaussian-splatting-lightning) - A 3D Gaussian Splatting framework with various derived algorithms and an interactive web viewer

*   [CyberOrigin2077/Cyber](https://github.com/CyberOrigin2077/Cyber) - This repo is designed for General Robotic Operation System

*   [Tencent/HunyuanDiT](https://github.com/Tencent/HunyuanDiT) - Hunyuan-DiT : A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding

*   [microsoft/OmniParser](https://github.com/microsoft/OmniParser) - A simple screen parsing tool towards pure vision based GUI agent

*   [TommyZihao/vlm\_arm](https://github.com/TommyZihao/vlm_arm) - Êú∫Ê¢∞ËáÇ+Â§ßÊ®°Âûã+Â§öÊ®°ÊÄÅ=‰∫∫Êú∫Âçè‰ΩúÂÖ∑Ë∫´Êô∫ËÉΩ‰Ωì

*   [cumtcssuld/RSP\_of\_CUMTCS](https://github.com/cumtcssuld/RSP_of_CUMTCS) - „ÄêÁüøÂ§ßËÆ°ÁÆóÊú∫Â≠¶Èô¢ËµÑÊ∫êÂÖ±‰∫´ËÆ°ÂàíÔºàResource SharingPlan of CUMTCSÔºâ„ÄëÊú¨‰ªìÂ∫ìÁî±ÁüøÂ§ßËÆ°ÁÆóÊú∫Â≠¶Èô¢Â≠¶Áîü‰ºöÂ≠¶‰π†ÈÉ®ÁâµÂ§¥Áª¥Êä§ÔºåÁî±ËÆ°ÁÆóÊú∫Â≠¶Èô¢ÂÖ®‰ΩìÂêåÂ≠¶ÂÖ±Âª∫ÂÖ±‰∫´„ÄÇÊ¨¢ËøéÂ§ßÂÆ∂ÁßØÊûÅÁöÑÂèÇÂä†Âà∞Êú¨ËµÑÊ∫êÂ∫ìÁöÑÂª∫ËÆæ‰∏≠Êù•ÂêßÔºÅÔºàÊØèÂΩìÊúâÈáçÂ§ßÊõ¥Êñ∞ÔºåÊàë‰ª¨ÈÉΩ‰ºöÂ∞ÜÊï¥‰∏™Â∫ìÂÖãÈöÜÂà∞Á†Å‰∫ëÔºåÁÇπÂáª‰∏ãËæπÈìæÊé•ÔºåÂà∞Êàë‰ª¨ÁöÑÁ†Å‰∫ë‰ªìÂ∫ìÂèØ‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑ‰∏ãËΩΩ‰ΩìÈ™åÔºâ

*   [ut-amrl/ObVi-SLAM](https://github.com/ut-amrl/ObVi-SLAM) - Long-Term Object Visual SLAM

*   [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) - A latent text-to-image diffusion model

*   [AnyLoc/Revisit-Anything](https://github.com/AnyLoc/Revisit-Anything) - Code release for Revisit Anything: Visual Place Recognition via Image Segment Retrieval (ECCV 2024)

*   [haksorus/gsplatloc](https://github.com/haksorus/gsplatloc) - GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization

*   [TommyZihao/Train\_Custom\_Dataset](https://github.com/TommyZihao/Train_Custom_Dataset) - Ê†áÊ≥®Ëá™Â∑±ÁöÑÊï∞ÊçÆÈõÜÔºåËÆ≠ÁªÉ„ÄÅËØÑ‰º∞„ÄÅÊµãËØï„ÄÅÈÉ®ÁΩ≤Ëá™Â∑±ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁÆóÊ≥ï

*   [isl-org/ZoeDepth](https://github.com/isl-org/ZoeDepth) - Metric depth estimation from a single image

*   [datawhalechina/leedl-tutorial](https://github.com/datawhalechina/leedl-tutorial) - „ÄäÊùéÂÆèÊØÖÊ∑±Â∫¶Â≠¶‰π†ÊïôÁ®ã„ÄãÔºàÊùéÂÆèÊØÖËÄÅÂ∏àÊé®ËçêüëçÔºåËãπÊûú‰π¶üçéÔºâÔºåPDF‰∏ãËΩΩÂú∞ÂùÄÔºöhttps://github.com/datawhalechina/leedl-tutorial/releases

*   [Fafa-DL/Lhy\_Machine\_Learning](https://github.com/Fafa-DL/Lhy_Machine_Learning) - ÊùéÂÆèÊØÖ2021/2022/2023Êò•Â≠£Êú∫Âô®Â≠¶‰π†ËØæÁ®ãËØæ‰ª∂Âèä‰Ωú‰∏ö

*   [yubaoliu/RDS-SLAM](https://github.com/yubaoliu/RDS-SLAM) - DS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods

*   [SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist) - The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery üßë‚Äçüî¨

*   [datawhalechina/self-llm](https://github.com/datawhalechina/self-llm) - „ÄäÂºÄÊ∫êÂ§ßÊ®°ÂûãÈ£üÁî®ÊåáÂçó„ÄãÈíàÂØπ‰∏≠ÂõΩÂÆùÂÆùÈáèË∫´ÊâìÈÄ†ÁöÑÂü∫‰∫éLinuxÁéØÂ¢ÉÂø´ÈÄüÂæÆË∞ÉÔºàÂÖ®ÂèÇÊï∞/LoraÔºâ„ÄÅÈÉ®ÁΩ≤ÂõΩÂÜÖÂ§ñÂºÄÊ∫êÂ§ßÊ®°ÂûãÔºàLLMÔºâ/Â§öÊ®°ÊÄÅÂ§ßÊ®°ÂûãÔºàMLLMÔºâÊïôÁ®ã

*   [facebookresearch/sam2](https://github.com/facebookresearch/sam2) - The repository provides code for running inference with the Meta Segment Anything Model 2 (SAM 2), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.

## TypeScript

*   [microsoft/vscode](https://github.com/microsoft/vscode) - Visual Studio Code

*   [mastra-ai/mastra](https://github.com/mastra-ai/mastra) - The TypeScript AI agent framework. ‚ö° Assistants, RAG, observability. Supports any LLM: GPT-4, Claude, Gemini, Llama.

*   [Binaryify/OneDark-Pro](https://github.com/Binaryify/OneDark-Pro) - Atom's iconic One Dark theme for Visual Studio Code

*   [David-patrick-chuks/Instagram-AI-Agent](https://github.com/David-patrick-chuks/Instagram-AI-Agent) - Instagram Ai Agent üå∏ is built using Node.js and TypeScript üõ†Ô∏è, designed for seamless job execution üì∏. It's lightweight, efficient, and still evolving üöß‚Äîexciting new features coming soon! üåü

*   [MegaScenes/web-viewer](https://github.com/MegaScenes/web-viewer) - web viewer for 3d reconstructions

*   [coaidev/coai](https://github.com/coaidev/coai) - üöÄ Next Generation AI One-Stop Internationalization Solution. üöÄ ‰∏ã‰∏Ä‰ª£ AI ‰∏ÄÁ´ôÂºè B/C Á´ØËß£ÂÜ≥ÊñπÊ°àÔºåÊîØÊåÅ OpenAIÔºåMidjourneyÔºåClaudeÔºåËÆØÈ£ûÊòüÁÅ´ÔºåStable DiffusionÔºåDALL¬∑EÔºåChatGLMÔºåÈÄö‰πâÂçÉÈóÆÔºåËÖæËÆØÊ∑∑ÂÖÉÔºå360 Êô∫ËÑëÔºåÁôæÂ∑ù AIÔºåÁÅ´Â±±ÊñπËàüÔºåÊñ∞ÂøÖÂ∫îÔºåGeminiÔºåMoonshot Á≠âÊ®°ÂûãÔºåÊîØÊåÅÂØπËØùÂàÜ‰∫´ÔºåËá™ÂÆö‰πâÈ¢ÑËÆæÔºå‰∫ëÁ´ØÂêåÊ≠•ÔºåÊ®°ÂûãÂ∏ÇÂú∫ÔºåÊîØÊåÅÂºπÊÄßËÆ°Ë¥πÂíåËÆ¢ÈòÖËÆ°ÂàíÊ®°ÂºèÔºåÊîØÊåÅÂõæÁâáËß£ÊûêÔºåÊîØÊåÅËÅîÁΩëÊêúÁ¥¢ÔºåÊîØÊåÅÊ®°ÂûãÁºìÂ≠òÔºå‰∏∞ÂØåÁæéËßÇÁöÑÂêéÂè∞ÁÆ°ÁêÜ‰∏é‰ª™Ë°®ÁõòÊï∞ÊçÆÁªüËÆ°„ÄÇ

*   [Eugeny/tabby](https://github.com/Eugeny/tabby) - A terminal for a more modern age

*   [amir9480/vscode-cpp-helper](https://github.com/amir9480/vscode-cpp-helper) - vscode extension to create implementation for c++ function prototypes.

*   [hcengineering/platform](https://github.com/hcengineering/platform) - Huly ‚Äî All-in-One Project Management Platform (alternative to Linear, Jira, Slack, Notion, Motion)

*   [conwnet/github1s](https://github.com/conwnet/github1s) - One second to read GitHub code with VS Code.

*   [ocsjs/ocsjs](https://github.com/ocsjs/ocsjs) - OCS ÁΩëËØæÂä©ÊâãÔºåÂà∑ËØæËÑöÊú¨ÔºåÁΩëËØæËÑöÊú¨ÔºåÂ∏ÆÂä©Â§ßÂ≠¶ÁîüËß£ÂÜ≥ÁΩëËØæÈöæÈ¢òÔºåÊîØÊåÅ„ÄêË∂ÖÊòüÂ≠¶‰π†ÈÄö„Äë„ÄêÁü•ÈÅìÊô∫ÊÖßÊ†ë„Äë„ÄêËÅåÊïô‰∫ë„Äë„ÄêÊô∫ÊÖßËÅåÊïô„Äë„Äê‰∏≠ÂõΩÂ§ßÂ≠¶MOOC„ÄëÁ≠âÁΩëËØæ  Ôºå ÂèØ‰ª•Âú® ËÑöÊú¨Áå´ ‰ª•Âèä Ê≤πÁå¥ Á≠âÂºÄÊ∫êËÑöÊú¨ÁÆ°ÁêÜÂô®‰∏ãËøêË°å„ÄÇ

*   [immich-app/immich](https://github.com/immich-app/immich) - High performance self-hosted photo and video management solution.

## Makefile

*   [zh-google-styleguide/zh-google-styleguide](https://github.com/zh-google-styleguide/zh-google-styleguide) - Google ÂºÄÊ∫êÈ°πÁõÆÈ£éÊ†ºÊåáÂçó (‰∏≠ÊñáÁâà)

*   [kahowang/FAST\_LIO\_SAM](https://github.com/kahowang/FAST_LIO_SAM) - Front\_end : fastlio2  Back\_end : lio\_sam

## Dockerfile

*   [linyicheng1/Dockers](https://github.com/linyicheng1/Dockers) - ‰∏Ä‰∫õÂ∏∏Áî®ÁöÑDockerfile Êñá‰ª∂ÔºåËÉΩÂ§üÂø´ÈÄüÈÉ®ÁΩ≤ËøêË°å‰∏Ä‰∫õÂ∏∏Áî®ÁÆóÊ≥ïÔºåÈÅøÂÖçÈáçÂ§çÈÖçÁΩÆÁéØÂ¢É

*   [jaeseok4104/slam-docker](https://github.com/jaeseok4104/slam-docker) - SLAM Docker for research

## LLVM

*   [llvm/llvm-project](https://github.com/llvm/llvm-project) - The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.

## Shell

*   [QwenLM/Qwen2.5](https://github.com/QwenLM/Qwen2.5) - Qwen2.5 is the large language model series developed by Qwen team, Alibaba Cloud.

*   [techahold/rustdeskinstall](https://github.com/techahold/rustdeskinstall) - Easy install Script for Rustdesk

*   [liguodongiot/llm-resource](https://github.com/liguodongiot/llm-resource) - LLMÂÖ®Ê†à‰ºòË¥®ËµÑÊ∫êÊ±áÊÄª

*   [atakandag/data\_collection\_vloc](https://github.com/atakandag/data_collection_vloc) - Data Collection with Zed2 and Ouster LiDAR and 3D Reconstruction with Rtabmap

## HTML

*   [f/awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts) - This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.

*   [VINGS-Mono/VINGS-Mono.github.io](https://github.com/VINGS-Mono/VINGS-Mono.github.io) -

*   [PKUFlyingPig/cs-self-learning](https://github.com/PKUFlyingPig/cs-self-learning) - ËÆ°ÁÆóÊú∫Ëá™Â≠¶ÊåáÂçó

*   [rohinmanvi/GeoLLM](https://github.com/rohinmanvi/GeoLLM) -

*   [beichensky/Font](https://github.com/beichensky/Font) - FiraCode Âíå Operator Mono Â≠ó‰Ωì

## CSS

*   [luohongk/AcademicHomepage](https://github.com/luohongk/AcademicHomepage) - This project is a beautiful personal academic homepage template created by me. Welcome to use it.

*   [zzwu29/Arxiv](https://github.com/zzwu29/Arxiv) -

*   [Maserhe/VScode-Markdown-theme-Maserhe](https://github.com/Maserhe/VScode-Markdown-theme-Maserhe) - vscode Ëá™ÂÆö‰πâMarkdownÊéíÁâàÈ£éÊ†ºÔºå‰ª•Âèä‰ª£Á†ÅÂùóÊ†∑ÂºèÈ£éÊ†º„ÄÇ

*   [wzzheng/GaussianFormer](https://github.com/wzzheng/GaussianFormer) - Project Page for GaussianFormer

## C\#

*   [2dust/v2rayN](https://github.com/2dust/v2rayN) - A GUI client for Windows, Linux and macOS, support Xray and sing-box and others

*   [mahoshojo0805/ContestPrograms](https://github.com/mahoshojo0805/ContestPrograms) - ÊµãÁªòÊäÄËÉΩÂ§ßËµõÁ®ãÂ∫è

## Swift

*   [jordanbaird/Ice](https://github.com/jordanbaird/Ice) - Powerful menu bar manager for macOS

*   [lwouis/alt-tab-macos](https://github.com/lwouis/alt-tab-macos) - Windows alt-tab on macOS

*   [exelban/stats](https://github.com/exelban/stats) - macOS system monitor in your menu bar

*   [ejbills/DockDoor](https://github.com/ejbills/DockDoor) - Window peeking for macOS

*   [Caldis/Mos](https://github.com/Caldis/Mos) - ‰∏Ä‰∏™Áî®‰∫éÂú® macOS ‰∏äÂπ≥Êªë‰Ω†ÁöÑÈº†Ê†áÊªöÂä®ÊïàÊûúÊàñÂçïÁã¨ËÆæÁΩÆÊªöÂä®ÊñπÂêëÁöÑÂ∞èÂ∑•ÂÖ∑, ËÆ©‰Ω†ÁöÑÊªöËΩÆÁàΩÂ¶ÇËß¶ÊéßÊùø  |  A lightweight tool used to smooth scrolling and set scroll direction independently for your mouse on macOS

*   [gao-sun/eul](https://github.com/gao-sun/eul) - üñ•Ô∏è macOS status monitoring app written in SwiftUI.

## Astro

*   [RomanHauksson/academic-project-astro-template](https://github.com/RomanHauksson/academic-project-astro-template) - Simple project page template for your research paper, built with Astro and Tailwind CSS

## Rust

*   [rustdesk/rustdesk](https://github.com/rustdesk/rustdesk) - An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.

*   [lapce/lapce](https://github.com/lapce/lapce) - Lightning-fast and Powerful Code Editor written in Rust

*   [typst/typst](https://github.com/typst/typst) - A new markup-based typesetting system that is powerful and easy to learn.

*   [makeecat/Peng](https://github.com/makeecat/Peng) - A minimal quadrotor autonomy framework in Rust (Mac, Linux, Windows)

## MATLAB

*   [i2Nav-WHU/KF-GINS-Matlab](https://github.com/i2Nav-WHU/KF-GINS-Matlab) - An EKF-based GNSS/INS Integrated Navigation Systems in Matlab (Matlab Version of KF-GINS)

*   [zhao-zhibo/INS](https://github.com/zhao-zhibo/INS) - INS.IMU. Inertial navigation mechanical arrangement algorithm, based on Yan Gongmin's PSINS ÊÉØÂØºÊú∫Ê¢∞ÁºñÊéíÁÆóÊ≥ïÔºå‰ª•‰∏•ÊÅ≠ÊïèÁöÑPSINS‰∏∫Âü∫Á°ÄÔºåÂèØ‰ª•ÂÆåÊàêÊ≠¶Ê±âÂ§ßÂ≠¶ÁöÑÊú∫Ê¢∞ÁºñÊéíËØæÁ®ã‰Ωú‰∏ö.

*   [ShiArthur03/ShiArthur03](https://github.com/ShiArthur03/ShiArthur03) -

## Fortran

*   [PrideLab/PRIDE-PPPAR](https://github.com/PrideLab/PRIDE-PPPAR) - An open‚Äësource software for Multi-GNSS PPP ambiguity resolution

## Matlab

*   [Relja/netvlad](https://github.com/Relja/netvlad) - NetVLAD: CNN architecture for weakly supervised place recognition

## Go

*   [yorukot/superfile](https://github.com/yorukot/superfile) - Pretty fancy and modern terminal file manager

*   [JanDeDobbeleer/oh-my-posh](https://github.com/JanDeDobbeleer/oh-my-posh) - The most customisable and low-latency cross platform/shell prompt renderer

*   [sourcegraph/sourcegraph-public-snapshot](https://github.com/sourcegraph/sourcegraph-public-snapshot) - Code AI platform with Code Search & Cody

## Cython

*   [stereolabs/zed-python-api](https://github.com/stereolabs/zed-python-api) - Python API for the ZED SDK

## TeX

*   [lliei0x/Moderncv-LateX](https://github.com/lliei0x/Moderncv-LateX) - LaTeXÁÆÄÂéÜÊ®°ÁâàüëÄüìë

*   [HouJP/resume](https://github.com/HouJP/resume) - ‰ΩøÁî®LaTeXÁºñËØëÁîüÊàêÁöÑ‰∏≠Ëã±Êñá‰∏™‰∫∫ÁÆÄÂéÜ

*   [whutug/whu-thesis](https://github.com/whutug/whu-thesis) - Ê≠¶Ê±âÂ§ßÂ≠¶ÊØï‰∏öËÆ∫Êñá LaTeX Ê®°Áâà 2025

## C

*   [MrNeRF/gaussian-splatting-cuda](https://github.com/MrNeRF/gaussian-splatting-cuda) - 3D Gaussian Splatting, reimagined: Unleashing unmatched speed with C++ and CUDA from the ground up!

*   [0voice/algorithm-structure](https://github.com/0voice/algorithm-structure) - 2021Âπ¥ÊúÄÊñ∞ÊÄªÁªì 500‰∏™Â∏∏Áî®Êï∞ÊçÆÁªìÊûÑÔºåÁÆóÊ≥ïÔºåÁÆóÊ≥ïÂØºËÆ∫ÔºåÈù¢ËØïÂ∏∏Áî®ÔºåÂ§ßÂéÇÈ´òÁ∫ßÂ∑•Á®ãÂ∏àÊï¥ÁêÜÊÄªÁªì

## CMake

*   [xieyuser/GS-LIVM](https://github.com/xieyuser/GS-LIVM) - GS-LIVM: Real-Time Photo-Realistic LiDAR-Inertial-Visual Mapping with Gaussian Splatting

## Lua

*   [gaboolic/rime-shuangpin-fuzhuma](https://github.com/gaboolic/rime-shuangpin-fuzhuma) - Â¢®Â•áÈü≥ÂΩ¢ÔºåÊâìÈÄ†ÊúÄÂº∫ÂèåÊãºËæÖÂä©Á†ÅrimeËæìÂÖ•ÊñπÊ°àÔºåËÆ©Â§©‰∏ãÂèåÊãºÁî®Êà∑‰∫∫‰∫∫Áî®Âæó‰∏äËæÖÂä©Á†Å„ÄÇÂü∫‰∫éÈõæÂáá-ÁôΩÈúúËØçÂ∫ìÔºåÊîØÊåÅÂ∞èÈπ§ÂèåÊãº„ÄÅËá™ÁÑ∂Á†ÅÂèåÊãº„ÄÅÊêúÁãóÂèåÊãº„ÄÅÂæÆËΩØÂèåÊãºÁ≠âÂ§öÁßçÂèåÊãºÔºåËæÖÂä©Á†ÅÊîØÊåÅÂ¢®Â•áÁ†ÅÔºàÂéüÂàõÊãÜÂàÜÂºÄÊ∫êÊîØÊåÅ4‰∏áÂ≠óÔºâ„ÄÅËá™ÁÑ∂Á†ÅÈÉ®È¶ñËæÖ„ÄÅÂ∞èÈπ§Èü≥ÂΩ¢ÔºàÈπ§ÂΩ¢ËæÖÔºâÁ≠âÔºåÊîØÊåÅÂèåÊãºÂíåËæÖÂä©Á†Å‰πãÈó¥ÊéíÂàóÁªÑÂêàÔºåÊîØÊåÅÊï¥Âè•/Â≠óËØçËæìÂÖ•„ÄÇ‰∏çËÆ§ËØÜÁöÑÂ≠óÂèØ‰ª•Á¨îÁîª„ÄÅÈÉ®‰ª∂ÊãÜÂ≠ó„ÄÅ‰ªìÈ¢âÁ†ÅÂèçÊü•„ÄÇÊîØÊåÅaw„ÄÅajÊ®°ÂºèËæìÂÖ•Ëã±Êñá„ÄÅÊó•ÊñáÔºåÊîØÊåÅÂèåÊãºÂπ∂ÂáªËæìÂÖ•„ÄÅemoji„ÄÅÂø´Á¨¶„ÄÅÊó•Êúü„ÄÅÂ§ßÂÜôÊï∞Â≠ó„ÄÅËÆ°ÁÆóÂô®Á≠âÈ´òÁ∫ßÂäüËÉΩ„ÄÇÈõæÂááÈπ§|ÈõæÂááËá™ÁÑ∂|Â¢®Â•áÁ†Å|Â¢®Â•áÈü≥ÂΩ¢

## SCSS

*   [RayeRen/acad-homepage.github.io](https://github.com/RayeRen/acad-homepage.github.io) - AcadHomepage: A Modern and Responsive Academic Personal Homepage

*   [mcdviral/mcdviral.github.io](https://github.com/mcdviral/mcdviral.github.io) -

## Dart

*   [localsend/localsend](https://github.com/localsend/localsend) - An open-source cross-platform alternative to AirDrop

*   [chen08209/FlClash](https://github.com/chen08209/FlClash) - A multi-platform proxy client based on ClashMeta,simple and easy to use, open-source and ad-free.

## Markdown

*   [labuladong/fucking-algorithm](https://github.com/labuladong/fucking-algorithm) - Âà∑ÁÆóÊ≥ïÂÖ®Èù†Â•óË∑ØÔºåËÆ§ÂáÜ labuladong Â∞±Â§ü‰∫ÜÔºÅEnglish version supported! Crack LeetCode, not only how, but also why.

*   [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) - Master programming by recreating your favorite technologies from scratch.

## Clojure

*   [tonsky/FiraCode](https://github.com/tonsky/FiraCode) - Free monospaced font with programming ligatures

## Java

*   [krahets/hello-algo](https://github.com/krahets/hello-algo) - „ÄäHello ÁÆóÊ≥ï„ÄãÔºöÂä®ÁîªÂõæËß£„ÄÅ‰∏ÄÈîÆËøêË°åÁöÑÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ïÊïôÁ®ã„ÄÇÊîØÊåÅ Python, Java, C++, C, C#, JS, Go, Swift, Rust, Ruby, Kotlin, TS, Dart ‰ª£Á†Å„ÄÇÁÆÄ‰ΩìÁâàÂíåÁπÅ‰ΩìÁâàÂêåÊ≠•Êõ¥Êñ∞ÔºåEnglish version ongoing

## Vim Script

*   [amix/vimrc](https://github.com/amix/vimrc) - The ultimate Vim configuration (vimrc)

*   [vim/vim](https://github.com/vim/vim) - The official Vim repository

*   [linrongbin16/lin.vim](https://github.com/linrongbin16/lin.vim) - Lin Rongbin's (Neo)Vim Distribution
